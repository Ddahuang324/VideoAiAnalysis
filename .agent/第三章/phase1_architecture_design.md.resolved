# ç¬¬ä¸€é˜¶æ®µ:åŸºç¡€è®¾æ–½ä¸æ¨¡å‹ç®¡ç†å±‚ - æ¶æ„è®¾è®¡æ–‡æ¡£

> **é˜¶æ®µç›®æ ‡**:å»ºç«‹ç»Ÿä¸€çš„ AI æ¨¡å‹åŠ è½½ã€æ¨ç†ä¸èµ„æºç®¡ç†åŸºç¡€è®¾æ–½,ä¸ºåç»­ä¸‰ä¸ªæ£€æµ‹å™¨(åœºæ™¯å˜åŒ–ã€è¿åŠ¨æ£€æµ‹ã€æ–‡å­—è¯†åˆ«)æä¾›ç¨³å®šé«˜æ•ˆçš„åº•å±‚æ”¯æ’‘ã€‚

---

## ğŸ“‹ è®¾è®¡æ¦‚è§ˆ

ç¬¬ä¸€é˜¶æ®µæ˜¯æ•´ä¸ªå…³é”®å¸§æ™ºèƒ½é€‰æ‹©ç³»ç»Ÿçš„**åŸºçŸ³**,è´Ÿè´£æ„å»ºä¸€ä¸ªé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„æ¨¡å‹æ¨ç†åŸºç¡€è®¾æ–½ã€‚è¯¥é˜¶æ®µçš„æ ¸å¿ƒä»»åŠ¡æ˜¯:

```mermaid
mindmap
  root((åŸºç¡€è®¾æ–½å±‚))
    ONNX Runtimeç»Ÿä¸€æ¨ç†
      MobileNetV3-Small
      YOLOv8n
      PP-OCRv4 Det ONNX
      PP-OCRv4 Rec ONNX
    ç»Ÿä¸€æ¨¡å‹ç®¡ç†
      ModelManager å•ä¾‹
      ONNXSession ä¼šè¯
      æ¨¡å‹é¢„çƒ­æœºåˆ¶
    æ•°æ®è½¬æ¢å·¥å…·
      OpenCV Mat â†’ Tensor
      HWC â†’ NCHW è½¬æ¢
      é›¶æ‹·è´ä¼˜åŒ–
    æ€§èƒ½ä¼˜åŒ–
      å†…å­˜æ± ç®¡ç†
      çº¿ç¨‹å®‰å…¨ä¿è¯
      æ‰¹é‡æ¨ç†æ”¯æŒ
```

> [!IMPORTANT]
> **ç»Ÿä¸€æ¨ç†å¼•æ“**: æœ¬é˜¶æ®µé‡‡ç”¨**ONNX Runtime**ä½œä¸ºå”¯ä¸€æ¨ç†å¼•æ“,æ‰€æœ‰æ¨¡å‹(åŒ…æ‹¬PaddleOCR)å‡è½¬æ¢ä¸ºONNXæ ¼å¼,ç®€åŒ–ä¾èµ–ç®¡ç†,æå‡è·¨å¹³å°å…¼å®¹æ€§ã€‚

---

## ä¸€ã€ç³»ç»Ÿæ¶æ„è®¾è®¡

### 1.1 æ•´ä½“åˆ†å±‚æ¶æ„

åŸºç¡€è®¾æ–½å±‚é‡‡ç”¨ç»å…¸çš„**ä¸‰å±‚æ¶æ„**,ä»ä¸‹è‡³ä¸Šä¾æ¬¡ä¸º:

```mermaid
flowchart TB
    subgraph Application["åº”ç”¨å±‚ - æ£€æµ‹å™¨"]
        SceneDetector["åœºæ™¯å˜åŒ–æ£€æµ‹å™¨"]
        MotionDetector["è¿åŠ¨æ£€æµ‹å™¨"]
        TextDetector["æ–‡å­—æ£€æµ‹å™¨"]
    end
    
    subgraph Foundation["åŸºç¡€è®¾æ–½å±‚ - æœ¬é˜¶æ®µå®ç°"]
        ModelManager["ModelManager<br/>å•ä¾‹ç®¡ç†å™¨"]
        ONNXSession["ONNXSession<br/>ONNXæ¨ç†ä¼šè¯"]
        DataConverter["DataConverter<br/>æ•°æ®è½¬æ¢"]
        TensorBuffer["TensorBuffer<br/>å†…å­˜ç®¡ç†"]
    end
    
    subgraph Runtime["æ¨ç†å¼•æ“å±‚"]
        ONNX["ONNX Runtime<br/>ç»Ÿä¸€æ¨ç†å¼•æ“"]
    end
    
    SceneDetector --> ModelManager
    MotionDetector --> ModelManager
    TextDetector --> ModelManager
    ModelManager --> ONNXSession
    ONNXSession --> DataConverter
    ONNXSession --> TensorBuffer
    ONNXSession --> ONNX
    
    style Foundation fill:#fff3e0
    style Application fill:#e3f2fd
    style Runtime fill:#c8e6c9
```

**è®¾è®¡åŸåˆ™**:

1. **ç»Ÿä¸€æ¨ç†å¼•æ“**:æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ONNX Runtime,ç®€åŒ–æ¶æ„
2. **å•ä¸€èŒè´£**:æ¯ä¸ªç±»åªè´Ÿè´£ä¸€ä¸ªæ˜ç¡®çš„åŠŸèƒ½
3. **æ˜“äºæ‰©å±•**:æœªæ¥å¯æ‰©å±•GPUåŠ é€Ÿ(CUDA/TensorRT)è€Œæ— éœ€ä¿®æ”¹ä¸Šå±‚ä»£ç 

---

### 1.2 æ ¸å¿ƒç»„ä»¶å…³ç³»

```mermaid
classDiagram
    class ONNXSession {
        -unique_ptr~Ort::Session~ session_
        -Ort::Env* env_
        -SessionOptions options_
        -MemoryInfo memoryInfo_
        -vector~string~ inputNames_
        -vector~string~ outputNames_
        +run(inputs) vector~vector~float~~
        +getInputShape(index) vector~int64_t~
        +getOutputShape(index) vector~int64_t~
        +warmUp() void
        +getName() string
    }
    
    class ModelManager {
        -static ModelManager instance_
        -unique_ptr~Ort::Env~ env_
        -map~string, unique_ptr~ONNXSession~~ sessions_
        -mutex mutex_
        +getInstance() ModelManager&
        +loadModel(name, path) void
        +getSession(name) ONNXSession*
        +warmUpAll() void
        +hasModel(name) bool
    }
    
    class DataConverter {
        +matToTensor(mat, size) vector~float~
        +hwcToNchw(data, H, W, C) vector~float~
        +preprocessImage(mat, size) Mat
        +standardize(mat, mean, std) void
    }
    
    class TensorBuffer {
        -vector~float~ buffer_
        -size_t capacity_
        +allocate(size) float*
        +resize(newSize) void
        +clear() void
        +capacity() size_t
    }
    
    ModelManager o-- ONNXSession
    ONNXSession ..> DataConverter
    ONNXSession ..> TensorBuffer
```

---

## äºŒã€æ ¸å¿ƒæ¨¡å—è¯¦ç»†è®¾è®¡

### 2.1 ONNXSession - ONNX Runtime æ¨ç†ä¼šè¯

#### è®¾è®¡ç›®æ ‡

å°è£…ONNX Runtime API,ä¸ºæ‰€æœ‰æ¨¡å‹æä¾›ç»Ÿä¸€çš„æ¨ç†èƒ½åŠ›ã€‚

> [!NOTE]
> ç”±äºé‡‡ç”¨ONNXç»Ÿä¸€ç®¡ç†æ–¹æ¡ˆ,æ‰€æœ‰æ¨¡å‹(MobileNetV3ã€YOLOv8nã€PP-OCRv4)å‡ä½¿ç”¨ONNXSessionè¿›è¡Œæ¨ç†,æ— éœ€æŠ½è±¡æ¥å£å±‚ã€‚

#### æ ¸å¿ƒèŒè´£

1. å°è£… ONNX Runtime API
2. ç®¡ç†æ¨¡å‹ä¼šè¯ç”Ÿå‘½å‘¨æœŸ
3. å¤„ç†è¾“å…¥è¾“å‡ºå¼ é‡è½¬æ¢

#### å®Œæ•´å®ç°

```cpp
// ONNXSession.h
#pragma once
#include "ISession.h"
#include <onnxruntime_cxx_api.h>
#include <memory>
#include <vector>
#include <string>

namespace KeyFrame::Foundation {

class ONNXSession : public ISession {
public:
    struct Config {
        int intraOpNumThreads = 4;      // ç®—å­å†…å¹¶è¡Œçº¿ç¨‹æ•°
        int interOpNumThreads = 2;      // ç®—å­é—´å¹¶è¡Œçº¿ç¨‹æ•°
        bool enableCUDA = false;        // æ˜¯å¦å¯ç”¨ CUDA åŠ é€Ÿ
        int cudaDeviceId = 0;           // CUDA è®¾å¤‡ ID
        
        GraphOptimizationLevel optimizationLevel = 
            GraphOptimizationLevel::ORT_ENABLE_ALL;
    };
    
    /**
     * @brief æ„é€ å‡½æ•°
     * @param env ONNX Runtime å…¨å±€ç¯å¢ƒ(ç”± ModelManager æä¾›)
     * @param modelPath æ¨¡å‹æ–‡ä»¶è·¯å¾„(.onnx)
     * @param config ä¼šè¯é…ç½®
     */
    ONNXSession(
        Ort::Env* env,
        const std::string& modelPath,
        const Config& config = Config{}
    );
    
    ~ONNXSession() override = default;
    
    // å®ç° ISession æ¥å£
    std::vector<std::vector<float>> run(
        const std::vector<std::vector<float>>& inputs
    ) override;
    
    std::vector<int64_t> getInputShape(size_t index = 0) const override;
    std::vector<int64_t> getOutputShape(size_t index = 0) const override;
    void warmUp() override;
    std::string getName() const override { return modelName_; }
    
private:
    /**
     * @brief åˆ›å»ºè¾“å…¥å¼ é‡
     */
    std::vector<Ort::Value> createInputTensors(
        const std::vector<std::vector<float>>& inputs
    );
    
    /**
     * @brief æå–è¾“å‡ºæ•°æ®
     */
    std::vector<std::vector<float>> extractOutputs(
        std::vector<Ort::Value>& outputTensors
    );
    
    Ort::Env* env_;                                  // å…¨å±€ç¯å¢ƒ(ä¸æ‹¥æœ‰)
    std::unique_ptr<Ort::Session> session_;          // æ¨ç†ä¼šè¯
    Ort::SessionOptions sessionOptions_;             // ä¼šè¯é…ç½®
    Ort::MemoryInfo memoryInfo_;                     // å†…å­˜ä¿¡æ¯
    
    std::vector<std::string> inputNames_;            // è¾“å…¥èŠ‚ç‚¹åç§°
    std::vector<std::string> outputNames_;           // è¾“å‡ºèŠ‚ç‚¹åç§°
    std::vector<std::vector<int64_t>> inputShapes_;  // è¾“å…¥å½¢çŠ¶
    std::vector<std::vector<int64_t>> outputShapes_; // è¾“å‡ºå½¢çŠ¶
    
    std::string modelName_;                          // æ¨¡å‹åç§°
    Config config_;                                  // é…ç½®
};

} // namespace KeyFrame::Foundation
```

#### æ¨ç†æµç¨‹è¯¦è§£

```mermaid
sequenceDiagram
    participant Detector as æ£€æµ‹å™¨
    participant Session as ONNXSession
    participant ONNX as ONNX Runtime
    participant GPU as CPU/GPU
    
    Detector->>Session: run(inputs)
    
    Session->>Session: 1. createInputTensors()
    Note over Session: å°† vector<float> è½¬ä¸º Ort::Value
    
    Session->>ONNX: 2. session->Run()
    Note over ONNX: æ‰§è¡Œè®¡ç®—å›¾
    
    ONNX->>GPU: 3. è°ƒç”¨ç¡¬ä»¶åç«¯
    GPU-->>ONNX: è®¡ç®—ç»“æœ
    
    ONNX-->>Session: vector<Ort::Value>
    
    Session->>Session: 4. extractOutputs()
    Note over Session: æå–ä¸º vector<float>
    
    Session-->>Detector: vector<vector<float>>
```

#### å…³é”®å®ç°ç»†èŠ‚

**1. ä¼šè¯åˆå§‹åŒ–**

```cpp
ONNXSession::ONNXSession(
    Ort::Env* env,
    const std::string& modelPath,
    const Config& config
) : env_(env), 
    config_(config),
    memoryInfo_(Ort::MemoryInfo::CreateCpu(
        OrtArenaAllocator, OrtMemTypeDefault
    )) {
    
    // 1. é…ç½®ä¼šè¯é€‰é¡¹
    sessionOptions_.SetIntraOpNumThreads(config.intraOpNumThreads);
    sessionOptions_.SetInterOpNumThreads(config.interOpNumThreads);
    sessionOptions_.SetGraphOptimizationLevel(config.optimizationLevel);
    
    // 2. å¯é€‰:å¯ç”¨ CUDA åŠ é€Ÿ
    if (config.enableCUDA) {
        OrtCUDAProviderOptions cudaOptions;
        cudaOptions.device_id = config.cudaDeviceId;
        sessionOptions_.AppendExecutionProvider_CUDA(cudaOptions);
    }
    
    // 3. åˆ›å»ºä¼šè¯
    session_ = std::make_unique<Ort::Session>(
        *env_, modelPath.c_str(), sessionOptions_
    );
    
    // 4. æå–è¾“å…¥è¾“å‡ºå…ƒä¿¡æ¯
    extractMetadata();
    
    modelName_ = extractModelName(modelPath);
}

void ONNXSession::extractMetadata() {
    // è¾“å…¥ä¿¡æ¯
    size_t numInputs = session_->GetInputCount();
    for (size_t i = 0; i < numInputs; ++i) {
        auto name = session_->GetInputNameAllocated(
            i, Ort::AllocatorWithDefaultOptions()
        );
        inputNames_.push_back(name.get());
        
        auto shape = session_->GetInputTypeInfo(i)
            .GetTensorTypeAndShapeInfo()
            .GetShape();
        inputShapes_.push_back(shape);
    }
    
    // è¾“å‡ºä¿¡æ¯(ç±»ä¼¼å¤„ç†)
    // ...
}
```

**2. æ¨ç†æ‰§è¡Œ**

```cpp
std::vector<std::vector<float>> ONNXSession::run(
    const std::vector<std::vector<float>>& inputs
) {
    // 1. åˆ›å»ºè¾“å…¥å¼ é‡
    auto inputTensors = createInputTensors(inputs);
    
    // 2. å‡†å¤‡è¾“å…¥è¾“å‡ºåç§°
    std::vector<const char*> inputNamePtrs;
    for (const auto& name : inputNames_) {
        inputNamePtrs.push_back(name.c_str());
    }
    
    std::vector<const char*> outputNamePtrs;
    for (const auto& name : outputNames_) {
        outputNamePtrs.push_back(name.c_str());
    }
    
    // 3. æ‰§è¡Œæ¨ç†
    auto outputTensors = session_->Run(
        Ort::RunOptions{nullptr},
        inputNamePtrs.data(), inputTensors.data(), inputTensors.size(),
        outputNamePtrs.data(), outputNamePtrs.size()
    );
    
    // 4. æå–è¾“å‡º
    return extractOutputs(outputTensors);
}
```

> [!TIP]
> **æ€§èƒ½ä¼˜åŒ–ç‚¹**:
> - ä½¿ç”¨ `Ort::MemoryInfo::CreateCpu()` åˆ›å»ºçš„å†…å­˜ä¿¡æ¯å¯å¤ç”¨,é¿å…æ¯æ¬¡æ¨ç†éƒ½åˆ›å»º
> - è¾“å…¥è¾“å‡ºåç§°æŒ‡é’ˆå¯ç¼“å­˜,å‡å°‘å­—ç¬¦ä¸²æ“ä½œå¼€é”€

---

### 2.2 ModelManager - ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨

#### è®¾è®¡ç›®æ ‡

1. **å•ä¾‹æ¨¡å¼**:å…¨å±€å”¯ä¸€å®ä¾‹,é¿å…é‡å¤åŠ è½½æ¨¡å‹
2. **ç»Ÿä¸€ç®¡ç†**:é›†ä¸­ç®¡ç†æ‰€æœ‰æ¨¡å‹ä¼šè¯
3. **çº¿ç¨‹å®‰å…¨**:æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘è®¿é—®
4. **é¢„çƒ­æœºåˆ¶**:åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½å¹¶é¢„çƒ­æ¨¡å‹

#### å®Œæ•´å®ç°

```cpp
// ModelManager.h
#pragma once
#include "ISession.h"
#include <onnxruntime_cxx_api.h>
#include <memory>
#include <unordered_map>
#include <mutex>
#include <string>

namespace KeyFrame::Foundation {

/**
 * @brief æ¨¡å‹ç®¡ç†å™¨(å•ä¾‹)
 * 
 * è´Ÿè´£åŠ è½½ã€ç®¡ç†æ‰€æœ‰ AI æ¨¡å‹çš„æ¨ç†ä¼šè¯,æä¾›çº¿ç¨‹å®‰å…¨çš„è®¿é—®æ¥å£ã€‚
 */
class ModelManager {
public:
    enum class FrameworkType {
        ONNX,       // ONNX Runtime
        Paddle      // PaddleInference
    };
    
    /**
     * @brief è·å–å•ä¾‹å®ä¾‹
     */
    static ModelManager& getInstance() {
        static ModelManager instance;
        return instance;
    }
    
    /**
     * @brief åŠ è½½æ¨¡å‹
     * @param name æ¨¡å‹åç§°(å”¯ä¸€æ ‡è¯†)
     * @param modelPath æ¨¡å‹æ–‡ä»¶è·¯å¾„
     * @param type æ¨ç†æ¡†æ¶ç±»å‹
     * @param paramsPath å‚æ•°æ–‡ä»¶è·¯å¾„(ä»… Paddle éœ€è¦)
     */
    void loadModel(
        const std::string& name,
        const std::string& modelPath,
        FrameworkType type,
        const std::string& paramsPath = ""
    );
    
    /**
     * @brief è·å–æ¨¡å‹ä¼šè¯
     * @param name æ¨¡å‹åç§°
     * @return ä¼šè¯æŒ‡é’ˆ(ä¸æ‹¥æœ‰æ‰€æœ‰æƒ)
     * @throws std::runtime_error å¦‚æœæ¨¡å‹æœªåŠ è½½
     */
    ISession* getSession(const std::string& name);
    
    /**
     * @brief é¢„çƒ­æ‰€æœ‰å·²åŠ è½½çš„æ¨¡å‹
     */
    void warmUpAll();
    
    /**
     * @brief æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
     */
    bool hasModel(const std::string& name) const;
    
    /**
     * @brief è·å–å·²åŠ è½½æ¨¡å‹åˆ—è¡¨
     */
    std::vector<std::string> getLoadedModels() const;
    
    // ç¦ç”¨æ‹·è´å’Œèµ‹å€¼
    ModelManager(const ModelManager&) = delete;
    ModelManager& operator=(const ModelManager&) = delete;
    
private:
    ModelManager();
    ~ModelManager() = default;
    
    std::unique_ptr<Ort::Env> env_;                              // ONNX å…¨å±€ç¯å¢ƒ
    std::unordered_map<std::string, 
                       std::unique_ptr<ISession>> sessions_;     // ä¼šè¯æ˜ å°„
    mutable std::mutex mutex_;                                   // ä¿æŠ¤å¹¶å‘è®¿é—®
};

} // namespace KeyFrame::Foundation
```

#### çº¿ç¨‹å®‰å…¨ä¿è¯

```mermaid
sequenceDiagram
    participant T1 as çº¿ç¨‹1
    participant T2 as çº¿ç¨‹2
    participant Manager as ModelManager
    participant Mutex as mutex_
    
    T1->>Manager: getSession("mobilenet")
    Manager->>Mutex: lock()
    Note over Manager: ä¸´ç•ŒåŒºå¼€å§‹
    Manager->>Manager: æŸ¥æ‰¾ sessions_["mobilenet"]
    Manager->>Mutex: unlock()
    Note over Manager: ä¸´ç•ŒåŒºç»“æŸ
    Manager-->>T1: ONNXSession*
    
    T2->>Manager: getSession("yolov8n")
    Manager->>Mutex: lock()
    Manager->>Manager: æŸ¥æ‰¾ sessions_["yolov8n"]
    Manager->>Mutex: unlock()
    Manager-->>T2: ONNXSession*
```

> [!IMPORTANT]
> **çº¿ç¨‹å®‰å…¨ç­–ç•¥**:
> - ä½¿ç”¨ `std::mutex` ä¿æŠ¤å…±äº«èµ„æº `sessions_`
> - è¯»å†™æ“ä½œéƒ½éœ€è¦åŠ é”(è¯»å¤šå†™å°‘åœºæ™¯å¯è€ƒè™‘ `std::shared_mutex`)
> - è¿”å›çš„ `ONNXSession*` æŒ‡é’ˆæœ¬èº«æ˜¯çº¿ç¨‹å®‰å…¨çš„(åªè¯»è®¿é—®)

#### å®ç°ç»†èŠ‚

```cpp
// ModelManager.cpp
#include "DataConverter.h"
#include "ModelManager.h"
#include "ONNXSession.h"
#include <iostream>

namespace KeyFrame::Foundation {

ModelManager::ModelManager() {
    // åˆå§‹åŒ– ONNX Runtime å…¨å±€ç¯å¢ƒ
    env_ = std::make_unique<Ort::Env>(
        ORT_LOGGING_LEVEL_WARNING,
        "KeyFrameSelector"
    );
    
    std::cout << "[ModelManager] Initialized" << std::endl;
}

void ModelManager::loadModel(
    const std::string& name,
    const std::string& modelPath
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // 1. æ£€æŸ¥æ˜¯å¦å·²åŠ è½½
    if (sessions_.find(name) != sessions_.end()) {
        std::cout << "[ModelManager] Model already loaded: " 
                  << name << std::endl;
        return;
    }
    
    // 2. åˆ›å»ºONNXä¼šè¯
    ONNXSession::Config config;
    config.intraOpNumThreads = 4;
    config.optimizationLevel = GraphOptimizationLevel::ORT_ENABLE_ALL;
    
    auto session = std::make_unique<ONNXSession>(
        env_.get(), modelPath, config
    );
    
    // 3. å­˜å‚¨ä¼šè¯
    sessions_[name] = std::move(session);
    
    std::cout << "[ModelManager] Loaded model: " << name 
              << " (" << modelPath << ")" << std::endl;
}

ONNXSession* ModelManager::getSession(const std::string& name) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    auto it = sessions_.find(name);
    if (it == sessions_.end()) {
        throw std::runtime_error("Model not found: " + name);
    }
    
    return it->second.get();
}

void ModelManager::warmUpAll() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::cout << "[ModelManager] Warming up all models..." << std::endl;
    
    for (auto& [name, session] : sessions_) {
        session->warmUp();
        std::cout << "  âœ“ " << name << std::endl;
    }
    
    std::cout << "[ModelManager] Warm-up complete" << std::endl;
}

bool ModelManager::hasModel(const std::string& name) const {
    std::lock_guard<std::mutex> lock(mutex_);
    return sessions_.find(name) != sessions_.end();
}

std::vector<std::string> ModelManager::getLoadedModels() const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> names;
    for (const auto& [name, _] : sessions_) {
        names.push_back(name);
    }
    return names;
}

} // namespace KeyFrame::Foundation
```

---

### 2.5 DataConverter - æ•°æ®è½¬æ¢å·¥å…·

#### æ ¸å¿ƒåŠŸèƒ½

1. **OpenCV Mat â†’ Tensor**:å°†å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
2. **HWC â†’ NCHW**:å¸ƒå±€è½¬æ¢
3. **å½’ä¸€åŒ–**:åƒç´ å€¼å½’ä¸€åŒ–åˆ° [0, 1] æˆ– [-1, 1]
4. **Resize**:è°ƒæ•´å›¾åƒå°ºå¯¸

#### å†…å­˜å¸ƒå±€è½¬æ¢åŸç†

```mermaid
flowchart TB
    subgraph OpenCV[OpenCV Mat - HWC]
        direction LR
        H1["Row 0: R G B | R G B | R G B"]
        H2["Row 1: R G B | R G B | R G B"]
        H3["Row 2: R G B | R G B | R G B"]
    end
    
    subgraph Transform[è½¬æ¢è¿‡ç¨‹]
        Split[é€šé“åˆ†ç¦»]
        Concat[æŒ‰é€šé“æ‹¼æ¥]
    end
    
    subgraph Tensor[Tensor - NCHW]
        direction LR
        C1["Channel R: R R R R R R R R R"]
        C2["Channel G: G G G G G G G G G"]
        C3["Channel B: B B B B B B B B B"]
    end
    
    OpenCV --> Split --> Concat --> Tensor
    
    style OpenCV fill:#ffcdd2
    style Tensor fill:#c8e6c9
```

#### å®Œæ•´å®ç°

```cpp
// DataConverter.h
#pragma once
#include <opencv2/opencv.hpp>
#include <vector>
#include <cstdint>

namespace KeyFrame::Foundation {

/**
 * @brief æ•°æ®è½¬æ¢å·¥å…·ç±»
 * 
 * æä¾› OpenCV Mat ä¸æ·±åº¦å­¦ä¹  Tensor ä¹‹é—´çš„é«˜æ•ˆè½¬æ¢ã€‚
 */
class DataConverter {
public:
    /**
     * @brief å°† OpenCV Mat è½¬æ¢ä¸º NCHW æ ¼å¼çš„ Tensor
     * @param image è¾“å…¥å›¾åƒ(BGR æ ¼å¼)
     * @param targetSize ç›®æ ‡å°ºå¯¸(width, height)
     * @param normalize æ˜¯å¦å½’ä¸€åŒ–åˆ° [0, 1]
     * @param mean å‡å€¼(ç”¨äºæ ‡å‡†åŒ–)
     * @param std æ ‡å‡†å·®(ç”¨äºæ ‡å‡†åŒ–)
     * @return NCHW æ ¼å¼çš„æµ®ç‚¹æ•°å‘é‡ [1, C, H, W]
     */
    static std::vector<float> matToTensor(
        const cv::Mat& image,
        const cv::Size& targetSize,
        bool normalize = true,
        const std::vector<float>& mean = {0.0f, 0.0f, 0.0f},
        const std::vector<float>& std = {1.0f, 1.0f, 1.0f}
    );
    
    /**
     * @brief HWC â†’ NCHW è½¬æ¢(æ‰‹åŠ¨å®ç°,æ€§èƒ½ä¼˜åŒ–ç‰ˆ)
     * @param hwcData HWC æ ¼å¼æ•°æ®
     * @param H é«˜åº¦
     * @param W å®½åº¦
     * @param C é€šé“æ•°
     * @return NCHW æ ¼å¼æ•°æ®
     */
    static std::vector<float> hwcToNchw(
        const std::vector<float>& hwcData,
        int H, int W, int C
    );
    
    /**
     * @brief å›¾åƒé¢„å¤„ç†(Resize + å½’ä¸€åŒ–)
     * @param image è¾“å…¥å›¾åƒ
     * @param targetSize ç›®æ ‡å°ºå¯¸
     * @param normalize æ˜¯å¦å½’ä¸€åŒ–
     * @return é¢„å¤„ç†åçš„å›¾åƒ
     */
    static cv::Mat preprocessImage(
        const cv::Mat& image,
        const cv::Size& targetSize,
        bool normalize = true
    );
    
    /**
     * @brief æ ‡å‡†åŒ–(å‡å‡å€¼é™¤æ ‡å‡†å·®)
     * @param image è¾“å…¥å›¾åƒ(æµ®ç‚¹å‹)
     * @param mean å‡å€¼å‘é‡
     * @param std æ ‡å‡†å·®å‘é‡
     */
    static void standardize(
        cv::Mat& image,
        const std::vector<float>& mean,
        const std::vector<float>& std
    );
};

} // namespace KeyFrame::Foundation
```

**å®ç°ä»£ç **:

```cpp
// DataConverter.cpp
#include "DataConverter.h"
#include <stdexcept>

namespace KeyFrame::Foundation {

std::vector<float> DataConverter::matToTensor(
    const cv::Mat& image,
    const cv::Size& targetSize,
    bool normalize,
    const std::vector<float>& mean,
    const std::vector<float>& std
) {
    // 1. Resize
    cv::Mat resized;
    cv::resize(image, resized, targetSize);
    
    // 2. è½¬æ¢ä¸ºæµ®ç‚¹å‹
    cv::Mat floatImage;
    resized.convertTo(floatImage, CV_32FC3);
    
    // 3. å½’ä¸€åŒ–
    if (normalize) {
        floatImage /= 255.0f;
    }
    
    // 4. æ ‡å‡†åŒ–
    if (mean.size() == 3 && std.size() == 3) {
        standardize(floatImage, mean, std);
    }
    
    // 5. HWC â†’ NCHW
    const int H = floatImage.rows;
    const int W = floatImage.cols;
    const int C = floatImage.channels();
    
    std::vector<float> tensor(C * H * W);
    
    // æ‰‹åŠ¨é‡æ’(æ€§èƒ½ä¼˜åŒ–)
    for (int h = 0; h < H; ++h) {
        const float* row = floatImage.ptr<float>(h);
        for (int w = 0; w < W; ++w) {
            for (int c = 0; c < C; ++c) {
                // HWC: row[w*C + c]
                // NCHW: tensor[c*H*W + h*W + w]
                tensor[c * H * W + h * W + w] = row[w * C + c];
            }
        }
    }
    
    return tensor;
}

std::vector<float> DataConverter::hwcToNchw(
    const std::vector<float>& hwcData,
    int H, int W, int C
) {
    std::vector<float> nchwData(C * H * W);
    
    for (int h = 0; h < H; ++h) {
        for (int w = 0; w < W; ++w) {
            for (int c = 0; c < C; ++c) {
                int hwcIndex = h * W * C + w * C + c;
                int nchwIndex = c * H * W + h * W + w;
                nchwData[nchwIndex] = hwcData[hwcIndex];
            }
        }
    }
    
    return nchwData;
}

cv::Mat DataConverter::preprocessImage(
    const cv::Mat& image,
    const cv::Size& targetSize,
    bool normalize
) {
    cv::Mat resized;
    cv::resize(image, resized, targetSize);
    
    cv::Mat floatImage;
    resized.convertTo(floatImage, CV_32FC3);
    
    if (normalize) {
        floatImage /= 255.0f;
    }
    
    return floatImage;
}

void DataConverter::standardize(
    cv::Mat& image,
    const std::vector<float>& mean,
    const std::vector<float>& std
) {
    if (mean.size() != 3 || std.size() != 3) {
        throw std::invalid_argument("mean and std must have 3 elements");
    }
    
    // åˆ†ç¦»é€šé“
    std::vector<cv::Mat> channels(3);
    cv::split(image, channels);
    
    // æ ‡å‡†åŒ–æ¯ä¸ªé€šé“
    for (int c = 0; c < 3; ++c) {
        channels[c] = (channels[c] - mean[c]) / std[c];
    }
    
    // åˆå¹¶é€šé“
    cv::merge(channels, image);
}

} // namespace KeyFrame::Foundation
```

#### æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | 224Ã—224 | 640Ã—640 | ä¼˜åŠ¿ |
|:----:|:-------:|:-------:|:----:|
| **OpenCV split** | ~0.8ms | ~6ms | ä»£ç ç®€æ´ |
| **æ‰‹åŠ¨è½¬æ¢** | ~0.5ms | ~4ms | **æ€§èƒ½æ›´ä¼˜** âœ… |

---

### 2.6 TensorBuffer - å†…å­˜æ± ç®¡ç†

#### è®¾è®¡ç›®æ ‡

é¿å…é¢‘ç¹çš„å†…å­˜åˆ†é…/é‡Šæ”¾,æå‡æ¨ç†æ€§èƒ½ã€‚

#### å®ç°

```cpp
// TensorBuffer.h
#pragma once
#include <vector>
#include <cstddef>

namespace KeyFrame::Foundation {

/**
 * @brief å¼ é‡å†…å­˜ç¼“å†²æ± 
 * 
 * å¤ç”¨å†…å­˜,å‡å°‘æ¨ç†è¿‡ç¨‹ä¸­çš„åŠ¨æ€åˆ†é…å¼€é”€ã€‚
 */
class TensorBuffer {
public:
    explicit TensorBuffer(size_t initialCapacity = 1024 * 1024);
    
    /**
     * @brief åˆ†é…æŒ‡å®šå¤§å°çš„å†…å­˜
     * @param size æ‰€éœ€å…ƒç´ æ•°é‡
     * @return å†…å­˜æŒ‡é’ˆ(ä¸æ‹¥æœ‰æ‰€æœ‰æƒ)
     */
    float* allocate(size_t size);
    
    /**
     * @brief è°ƒæ•´ç¼“å†²åŒºå¤§å°
     */
    void resize(size_t newSize);
    
    /**
     * @brief æ¸…ç©ºç¼“å†²åŒº(ä¸é‡Šæ”¾å†…å­˜)
     */
    void clear();
    
    /**
     * @brief è·å–å½“å‰å®¹é‡
     */
    size_t capacity() const { return buffer_.capacity(); }
    
private:
    std::vector<float> buffer_;
};

} // namespace KeyFrame::Foundation
```

**ä½¿ç”¨ç¤ºä¾‹**:

```cpp
TensorBuffer buffer(3 * 224 * 224);  // é¢„åˆ†é…

// æ¨ç†å¾ªç¯
for (const auto& frame : frames) {
    float* tensorData = buffer.allocate(3 * 224 * 224);
    
    // ç›´æ¥å†™å…¥ tensorData,é¿å…é¢å¤–æ‹·è´
    convertImageToTensor(frame, tensorData);
    
    // æ¨ç†...
}
```

---

## ä¸‰ã€æ¨¡å‹è§„æ ¼ä¸é…ç½®

### 3.1 æ¨¡å‹æ¸…å•

| æ¨¡å‹ | æ¡†æ¶ | è¾“å…¥å°ºå¯¸ | è¾“å‡ºç»´åº¦ | æ–‡ä»¶å¤§å° | ç”¨é€” |
|:----:|:----:|:--------:|:--------:|:--------:|:----:|
| **MobileNetV3-Small** | ONNX | [1,3,224,224] | [1,1280] | ~2.5 MB | åœºæ™¯å˜åŒ–æ£€æµ‹ |
| **YOLOv8n** | ONNX | [1,3,640,640] | å¤šè¾“å‡º | ~6.3 MB | è¿åŠ¨æ£€æµ‹ |
| **PP-OCRv4 Det** | Paddle | åŠ¨æ€ | åŠ¨æ€ | ~4.4 MB | æ–‡å­—æ£€æµ‹ |
| **PP-OCRv4 Rec** | Paddle | åŠ¨æ€ | åŠ¨æ€ | ~10.5 MB | æ–‡å­—è¯†åˆ« |

### 3.2 åˆå§‹åŒ–é…ç½®

```cpp
// åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–ä»£ç 
void initializeModels() {
    auto& manager = ModelManager::getInstance();
    
    // 1. åŠ è½½ MobileNetV3-Small (ONNX)
    manager.loadModel(
        "mobilenet_v3_small",
        "models/mobilenetv3_small.onnx",
        ModelManager::FrameworkType::ONNX
    );
    
    // 2. åŠ è½½ YOLOv8n (ONNX)
    manager.loadModel(
        "yolov8n",
        "models/yolov8n.onnx",
        ModelManager::FrameworkType::ONNX
    );
    
    // 3. åŠ è½½ PP-OCRv4 æ£€æµ‹æ¨¡å‹ (Paddle)
    manager.loadModel(
        "ppocr_det",
        "models/ch_PP-OCRv4_det_infer.pdmodel",
        ModelManager::FrameworkType::Paddle,
        "models/ch_PP-OCRv4_det_infer.pdiparams"
    );
    
    // 4. åŠ è½½ PP-OCRv4 è¯†åˆ«æ¨¡å‹ (Paddle)
    manager.loadModel(
        "ppocr_rec",
        "models/ch_PP-OCRv4_rec_infer.pdmodel",
        ModelManager::FrameworkType::Paddle,
        "models/ch_PP-OCRv4_rec_infer.pdiparams"
    );
    
    // 5. é¢„çƒ­æ‰€æœ‰æ¨¡å‹
    manager.warmUpAll();
}
```

---

## å››ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 4.1 å†…å­˜ä¼˜åŒ–

```mermaid
flowchart LR
    subgraph Before[ä¼˜åŒ–å‰]
        B1[æ¯æ¬¡æ¨ç†<br/>åˆ†é…å†…å­˜]
        B2[é¢‘ç¹ malloc/free]
        B3[å†…å­˜ç¢ç‰‡]
    end
    
    subgraph After[ä¼˜åŒ–å]
        A1[Arena Allocator<br/>å†…å­˜æ± ]
        A2[å¤ç”¨ç¼“å†²åŒº]
        A3[å‡å°‘ç¢ç‰‡]
    end
    
    Before --> After
    
    style Before fill:#ffcdd2
    style After fill:#c8e6c9
```

**ä¼˜åŒ–æªæ–½**:

1. **ONNX Runtime Arena Allocator**:è‡ªåŠ¨å¯ç”¨,å¤ç”¨æ¨ç†ç¼“å†²åŒº
2. **TensorBuffer**:åº”ç”¨å±‚å†…å­˜æ± ,å‡å°‘æ•°æ®è½¬æ¢å¼€é”€
3. **é¢„åˆ†é…**:å¯åŠ¨æ—¶åˆ†é…æ‰€æœ‰å¿…éœ€å†…å­˜

### 4.2 çº¿ç¨‹é…ç½®

```cpp
// æ¨èé…ç½®(4æ ¸CPU)
ONNXSession::Config config;
config.intraOpNumThreads = 4;  // å•ä¸ªç®—å­å†…å¹¶è¡Œ
config.interOpNumThreads = 1;  // ç®—å­é—´ä¸²è¡Œ(å‡å°‘è°ƒåº¦å¼€é”€)
```

**åŸåˆ™**:

- **CPU å¯†é›†å‹**:è®¾ç½® `intraOpNumThreads = ç‰©ç†æ ¸å¿ƒæ•°`
- **ä½å»¶è¿Ÿä¼˜å…ˆ**:è®¾ç½® `interOpNumThreads = 1`(é¡ºåºæ‰§è¡Œ)
- **é«˜ååä¼˜å…ˆ**:è®¾ç½® `interOpNumThreads = 2`(å¹¶è¡Œæ‰§è¡Œ)

### 4.3 æ¨¡å‹é¢„çƒ­

```mermaid
sequenceDiagram
    participant App as åº”ç”¨å¯åŠ¨
    participant Manager as ModelManager
    participant Session as ONNXSession
    participant Runtime as ONNX Runtime
    
    App->>Manager: warmUpAll()
    
    loop æ¯ä¸ªæ¨¡å‹
        Manager->>Session: warmUp()
        Session->>Runtime: æ‰§è¡Œå‡æ¨ç†
        Note over Runtime: åˆ†é…å†…å­˜<br/>ä¼˜åŒ–è®¡ç®—å›¾<br/>åˆå§‹åŒ– CUDA
        Runtime-->>Session: å®Œæˆ
    end
    
    Manager-->>App: é¢„çƒ­å®Œæˆ
    
    Note over App: åç»­æ¨ç†<br/>å»¶è¿Ÿç¨³å®š
```

**æ•ˆæœ**:

| åœºæ™¯ | æœªé¢„çƒ­ | å·²é¢„çƒ­ | æ”¹å–„ |
|:----:|:------:|:------:|:----:|
| **é¦–æ¬¡æ¨ç†** | ~100ms | ~10ms | **10x** âœ… |
| **åç»­æ¨ç†** | ~10ms | ~10ms | æ— å·®å¼‚ |

---

## äº”ã€ä½¿ç”¨ç¤ºä¾‹

### 5.1 å®Œæ•´å·¥ä½œæµç¨‹

```cpp
#include "ModelManager.h"
#include "DataConverter.h"
#include <opencv2/opencv.hpp>
#include <iostream>

int main() {
    // 1. åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
    auto& manager = ModelManager::getInstance();
    
    // 2. åŠ è½½ONNXæ¨¡å‹
    manager.loadModel(
        "mobilenet",
        "models/mobilenetv3_small.onnx"
    );
    
    // 3. é¢„çƒ­
    manager.warmUpAll();
    
    // 4. è¯»å–å›¾åƒ
    cv::Mat image = cv::imread("test.jpg");
    
    // 5. æ•°æ®è½¬æ¢
    auto tensorData = DataConverter::matToTensor(
        image,
        cv::Size(224, 224),
        true  // å½’ä¸€åŒ–
    );
    
    // 6. æ‰§è¡Œæ¨ç†
    auto* session = manager.getSession("mobilenet");
    auto outputs = session->run({tensorData});
    
    // 7. å¤„ç†ç»“æœ
    std::cout << "Feature vector size: " << outputs[0].size() << std::endl;
    // è¾“å‡º: Feature vector size: 1280
    
    return 0;
}
```

### 5.2 æ‰¹é‡æ¨ç†ç¤ºä¾‹

```cpp
void processVideoFrames(const std::vector<cv::Mat>& frames) {
    auto& manager = ModelManager::getInstance();
    auto* session = manager.getSession("mobilenet");
    
    TensorBuffer buffer(3 * 224 * 224);  // å¤ç”¨ç¼“å†²åŒº
    
    for (const auto& frame : frames) {
        // è½¬æ¢
        auto tensorData = DataConverter::matToTensor(
            frame, cv::Size(224, 224)
        );
        
        // æ¨ç†
        auto outputs = session->run({tensorData});
        
        // å¤„ç†ç»“æœ...
    }
}
```

---

## å…­ã€ç›®å½•ç»“æ„

```
cpp/
â”œâ”€â”€ include/
â”‚   â””â”€â”€ core/
â”‚       â””â”€â”€ KeyFrame/
â”‚           â””â”€â”€ Foundation/
â”‚               â”œâ”€â”€ ONNXSession.h           # ONNX æ¨ç†ä¼šè¯
â”‚               â”œâ”€â”€ ModelManager.h          # æ¨¡å‹ç®¡ç†å™¨
â”‚               â”œâ”€â”€ DataConverter.h         # æ•°æ®è½¬æ¢
â”‚               â””â”€â”€ TensorBuffer.h          # å†…å­˜æ± 
â”‚
â””â”€â”€ src/
    â””â”€â”€ core/
        â””â”€â”€ KeyFrame/
            â””â”€â”€ Foundation/
                â”œâ”€â”€ ONNXSession.cpp
                â”œâ”€â”€ ModelManager.cpp
                â”œâ”€â”€ DataConverter.cpp
                â””â”€â”€ TensorBuffer.cpp
```

---

## ä¸ƒã€ä¾èµ–é¡¹ä¸æ„å»ºé…ç½®

### 7.1 ä¾èµ–åº“

```cmake
# CMakeLists.txt
find_package(OpenCV REQUIRED)
find_package(onnxruntime REQUIRED)

add_library(KeyFrameFoundation
    src/core/KeyFrame/Foundation/ONNXSession.cpp
    src/core/KeyFrame/Foundation/ModelManager.cpp
    src/core/KeyFrame/Foundation/DataConverter.cpp
    src/core/KeyFrame/Foundation/TensorBuffer.cpp
)

target_link_libraries(KeyFrameFoundation
    PUBLIC
        ${OpenCV_LIBS}
        onnxruntime::onnxruntime
)

target_include_directories(KeyFrameFoundation
    PUBLIC
        ${CMAKE_CURRENT_SOURCE_DIR}/include
)
```

### 7.2 ç‰ˆæœ¬è¦æ±‚

| åº“ | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ |
|:--:|:--------:|:--------:|
| **OpenCV** | 4.5.0 | 4.8.0+ |
| **ONNX Runtime** | 1.15.0 | 1.17.0+ |
| **C++ æ ‡å‡†** | C++17 | C++20 |

---

## å…«ã€æµ‹è¯•ä¸éªŒè¯

### 8.1 å•å…ƒæµ‹è¯•

```cpp
// tests/Foundation/ModelManagerTest.cpp
#include <gtest/gtest.h>
#include "ModelManager.h"

TEST(ModelManagerTest, Singleton) {
    auto& m1 = ModelManager::getInstance();
    auto& m2 = ModelManager::getInstance();
    
    EXPECT_EQ(&m1, &m2);  // åŒä¸€å®ä¾‹
}

TEST(ModelManagerTest, LoadAndGetSession) {
    auto& manager = ModelManager::getInstance();
    
    manager.loadModel(
        "test_model",
        "models/mobilenetv3_small.onnx"
    );
    
    EXPECT_TRUE(manager.hasModel("test_model"));
    
    auto* session = manager.getSession("test_model");
    EXPECT_NE(session, nullptr);
}

TEST(DataConverterTest, MatToTensor) {
    cv::Mat image(224, 224, CV_8UC3, cv::Scalar(128, 128, 128));
    
    auto tensor = DataConverter::matToTensor(
        image, cv::Size(224, 224), true
    );
    
    EXPECT_EQ(tensor.size(), 3 * 224 * 224);
    
    // éªŒè¯å½’ä¸€åŒ–
    EXPECT_NEAR(tensor[0], 128.0f / 255.0f, 1e-5);
}
```

### 8.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

```cpp
// benchmarks/InferenceBenchmark.cpp
#include <benchmark/benchmark.h>
#include "ModelManager.h"

static void BM_MobileNetInference(benchmark::State& state) {
    auto& manager = ModelManager::getInstance();
    manager.loadModel(
        "mobilenet",
        "models/mobilenetv3_small.onnx",
        ModelManager::FrameworkType::ONNX
    );
    
    cv::Mat image = cv::imread("test.jpg");
    auto tensorData = DataConverter::matToTensor(
        image, cv::Size(224, 224)
    );
    
    auto* session = manager.getSession("mobilenet");
    
    for (auto _ : state) {
        auto outputs = session->run({tensorData});
        benchmark::DoNotOptimize(outputs);
    }
}

BENCHMARK(BM_MobileNetInference)->Unit(benchmark::kMillisecond);
```

**é¢„æœŸæ€§èƒ½**:

| æ¨¡å‹ | CPU (4æ ¸) | GPU (CUDA) |
|:----:|:---------:|:----------:|
| **MobileNetV3-Small** | 5-10ms | 2-3ms |
| **YOLOv8n** | 15-30ms | 5-10ms |
| **PP-OCRv4 Det** | 20-40ms | 8-15ms |

---

## ä¹ã€é£é™©ä¸ç¼“è§£æªæ–½

> [!WARNING]
> ä»¥ä¸‹é£é™©éœ€è¦åœ¨å®ç°è¿‡ç¨‹ä¸­é‡ç‚¹å…³æ³¨ã€‚

| é£é™©é¡¹ | ä¸¥é‡ç¨‹åº¦ | ç¼“è§£æªæ–½ |
|:------:|:--------:|:---------|
| **æ¨¡å‹æ–‡ä»¶ç¼ºå¤±** | ğŸ”´ é«˜ | å¯åŠ¨æ—¶æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§,æä¾›æ¸…æ™°é”™è¯¯æç¤º |
| **å†…å­˜æ³„æ¼** | ğŸ”´ é«˜ | ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆ,å®šæœŸè¿è¡Œ Valgrind æ£€æµ‹ |
| **çº¿ç¨‹å®‰å…¨é—®é¢˜** | ğŸ”´ é«˜ | ä¸¥æ ¼ä½¿ç”¨äº’æ–¥é”,ç¼–å†™å¹¶å‘æµ‹è¯• |
| **æ¨ç†æ€§èƒ½ä¸è¾¾æ ‡** | ğŸŸ¡ ä¸­ | é¢„çƒ­æœºåˆ¶ + æ€§èƒ½åŸºå‡†æµ‹è¯• + ä¼˜åŒ–é…ç½® |
| **è·¨å¹³å°å…¼å®¹æ€§** | ğŸŸ¡ ä¸­ | CI/CD å¤šå¹³å°æµ‹è¯•(Windows/Linux/macOS) |

---

## åã€æ€»ç»“ä¸ä¸‹ä¸€æ­¥

### 10.1 æœ¬é˜¶æ®µäº¤ä»˜ç‰©

````carousel
### æ ¸å¿ƒç±»å®ç°

- âœ… `ISession` - ç»Ÿä¸€æ¨ç†æ¥å£
- âœ… `ONNXSession` - ONNX Runtime å°è£…
- âœ… `PaddleSession` - PaddleInference å°è£…
- âœ… `ModelManager` - å•ä¾‹æ¨¡å‹ç®¡ç†å™¨
- âœ… `DataConverter` - æ•°æ®è½¬æ¢å·¥å…·
- âœ… `TensorBuffer` - å†…å­˜æ± ç®¡ç†

<!-- slide -->

### æµ‹è¯•è¦†ç›–

- âœ… å•å…ƒæµ‹è¯•(GTest)
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•(Google Benchmark)
- âœ… å†…å­˜æ³„æ¼æ£€æµ‹(Valgrind)
- âœ… çº¿ç¨‹å®‰å…¨æµ‹è¯•

<!-- slide -->

### æ–‡æ¡£è¾“å‡º

- âœ… æ¶æ„è®¾è®¡æ–‡æ¡£(æœ¬æ–‡æ¡£)
- âœ… API ä½¿ç”¨æ‰‹å†Œ
- âœ… æ€§èƒ½ä¼˜åŒ–æŒ‡å—
````

### 10.2 ä¸ç¬¬äºŒé˜¶æ®µçš„è¡”æ¥

```mermaid
flowchart LR
    subgraph Phase1[ç¬¬ä¸€é˜¶æ®µ - åŸºç¡€è®¾æ–½]
        ModelManager
        ISession
        DataConverter
    end
    
    subgraph Phase2[ç¬¬äºŒé˜¶æ®µ - æ£€æµ‹å™¨å®ç°]
        SceneDetector[åœºæ™¯å˜åŒ–æ£€æµ‹å™¨]
        MotionDetector[è¿åŠ¨æ£€æµ‹å™¨]
        TextDetector[æ–‡å­—æ£€æµ‹å™¨]
    end
    
    ModelManager --> SceneDetector
    ModelManager --> MotionDetector
    ModelManager --> TextDetector
    
    ISession --> SceneDetector
    ISession --> MotionDetector
    ISession --> TextDetector
    
    DataConverter --> SceneDetector
    DataConverter --> MotionDetector
    DataConverter --> TextDetector
    
    style Phase1 fill:#fff3e0
    style Phase2 fill:#e3f2fd
```

**ç¬¬äºŒé˜¶æ®µå°†åŸºäºæœ¬é˜¶æ®µçš„åŸºç¡€è®¾æ–½,å®ç°**:

1. **åœºæ™¯å˜åŒ–æ£€æµ‹å™¨**:è°ƒç”¨ MobileNetV3-Small æå–ç‰¹å¾
2. **è¿åŠ¨æ£€æµ‹å™¨**:è°ƒç”¨ YOLOv8n + ByteTrack è·Ÿè¸ªç›®æ ‡
3. **æ–‡å­—æ£€æµ‹å™¨**:è°ƒç”¨ PP-OCRv4 è¯†åˆ«æ–‡å­—

> [!IMPORTANT]
> **éªŒæ”¶æ ‡å‡†**:
> - âœ… æ‰€æœ‰æ¨¡å‹èƒ½æˆåŠŸåŠ è½½å¹¶æ¨ç†
> - âœ… å•æ¬¡æ¨ç†å»¶è¿Ÿæ»¡è¶³å®æ—¶æ€§è¦æ±‚(< 50ms)
> - âœ… å†…å­˜å ç”¨ç¨³å®š(æ— æ³„æ¼)
> - âœ… çº¿ç¨‹å®‰å…¨(é€šè¿‡å¹¶å‘æµ‹è¯•)

---

## é™„å½•:å…³é”®æŠ€æœ¯å‚è€ƒ

### A. ONNX Runtime å®˜æ–¹æ–‡æ¡£

- [C++ API Reference](https://onnxruntime.ai/docs/api/c/)
- [Performance Tuning](https://onnxruntime.ai/docs/performance/tune-performance.html)

### B. PaddleInference æ–‡æ¡£

- [C++ API](https://www.paddlepaddle.org.cn/inference/master/api_reference/cxx_api_index.html)
- [æ€§èƒ½ä¼˜åŒ–](https://www.paddlepaddle.org.cn/inference/master/optimize/paddle_trt.html)

### C. æ•°æ®å¸ƒå±€è½¬æ¢

```cpp
// NCHW â†’ NHWC (åå‘è½¬æ¢)
std::vector<float> nchwToHwc(
    const std::vector<float>& nchwData,
    int N, int C, int H, int W
) {
    std::vector<float> hwcData(N * H * W * C);
    
    for (int n = 0; n < N; ++n) {
        for (int h = 0; h < H; ++h) {
            for (int w = 0; w < W; ++w) {
                for (int c = 0; c < C; ++c) {
                    int nchwIndex = n * C * H * W + c * H * W + h * W + w;
                    int hwcIndex = n * H * W * C + h * W * C + w * C + c;
                    hwcData[hwcIndex] = nchwData[nchwIndex];
                }
            }
        }
    }
    
    return hwcData;
}
```
