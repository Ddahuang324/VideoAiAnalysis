# 第三章核心知识点详解

> 本文档详细讲解屏幕录制引擎实现所需的核心知识点,包括 FFmpeg 编程基础、平台 API(DXGI/X11)以及相关 C++ 设计模式。

---

## 目录

1. [FFmpeg 编程基础](#一ffmpeg-编程基础)
2. [Windows DXGI 桌面捕获](#二windows-dxgi-桌面捕获)
3. [Linux X11 屏幕捕获](#三linux-x11-屏幕捕获)
4. [C++ 设计模式应用](#四c-设计模式应用)
5. [多线程编程实践](#五多线程编程实践)

---

## 一、FFmpeg 编程基础

### 1.1 FFmpeg 架构概览

FFmpeg 是一个完整的音视频处理框架,由多个库组成:

```mermaid
graph TB
    A[FFmpeg 架构] --> B[libavformat]
    A --> C[libavcodec]
    A --> D[libavutil]
    A --> E[libswscale]
    A --> F[libswresample]
    
    B --> B1["容器格式封装/解封装<br/>MP4, MKV, AVI..."]
    C --> C1["编解码器<br/>H.264, HEVC, VP9..."]
    D --> D1["工具函数<br/>内存管理, 数学运算..."]
    E --> E1["图像缩放/格式转换<br/>RGB ↔ YUV"]
    F --> F1[音频重采样]
    
    style A fill:#FFD700
    style B fill:#87CEEB
    style C fill:#87CEEB
    style D fill:#87CEEB
    style E fill:#87CEEB
    style F fill:#87CEEB
```

### 1.2 核心数据结构

#### AVFormatContext - 格式上下文

**作用**: 管理整个媒体文件的容器格式信息

```cpp
AVFormatContext* format_ctx = nullptr;

// 分配上下文
format_ctx = avformat_alloc_context();

// 打开输出文件
avformat_alloc_output_context2(&format_ctx, nullptr, "mp4", "output.mp4");

// 添加视频流
AVStream* stream = avformat_new_stream(format_ctx, nullptr);

// 写入文件头
avformat_write_header(format_ctx, nullptr);

// 写入数据包
av_interleaved_write_frame(format_ctx, &packet);

// 写入文件尾
av_write_trailer(format_ctx);

// 释放资源
avformat_free_context(format_ctx);
```

**关键字段**:

| 字段 | 类型 | 说明 |
|------|------|------|
| `nb_streams` | `unsigned int` | 流的数量 |
| `streams` | `AVStream**` | 流数组 |
| `duration` | `int64_t` | 总时长(微秒) |
| `bit_rate` | `int64_t` | 总码率 |
| `pb` | `AVIOContext*` | I/O 上下文 |

#### AVCodecContext - 编解码器上下文

**作用**: 管理编解码器的配置和状态

```cpp
// 1. 查找编码器
const AVCodec* codec = avcodec_find_encoder(AV_CODEC_ID_H264);

// 2. 分配编码器上下文
AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);

// 3. 配置编码参数
codec_ctx->width = 1920;
codec_ctx->height = 1080;
codec_ctx->time_base = {1, 60};  // 60 fps
codec_ctx->framerate = {60, 1};
codec_ctx->bit_rate = 5000000;   // 5 Mbps
codec_ctx->gop_size = 60;        // 每秒一个关键帧
codec_ctx->max_b_frames = 0;     // 不使用 B 帧
codec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;

// 4. 打开编码器
avcodec_open2(codec_ctx, codec, nullptr);

// 5. 编码帧
avcodec_send_frame(codec_ctx, frame);
avcodec_receive_packet(codec_ctx, packet);

// 6. 释放资源
avcodec_free_context(&codec_ctx);
```

**关键参数详解**:

```mermaid
graph LR
    A[编码参数] --> B["分辨率<br/>width/height"]
    A --> C["帧率<br/>framerate"]
    A --> D["码率<br/>bit_rate"]
    A --> E["GOP 大小<br/>gop_size"]
    A --> F["像素格式<br/>pix_fmt"]
    
    B --> B1[影响: 文件大小, 清晰度]
    C --> C1[影响: 流畅度, 文件大小]
    D --> D1[影响: 画质, 文件大小]
    E --> E1[影响: 随机访问, 压缩率]
    F --> F1[影响: 兼容性, 压缩效率]
```

> [!IMPORTANT]
> **屏幕录制的最佳实践**:
> - `pix_fmt = AV_PIX_FMT_YUV420P`: 兼容性最好
> - `max_b_frames = 0`: 屏幕内容变化大,B 帧收益低
> - `preset = ultrafast`: 降低编码延迟
> - `tune = zerolatency`: 优化实时性

#### AVFrame - 原始帧数据

**作用**: 存储未压缩的音视频数据

```cpp
// 分配帧
AVFrame* frame = av_frame_alloc();

// 设置帧参数
frame->format = AV_PIX_FMT_YUV420P;
frame->width = 1920;
frame->height = 1080;

// 分配缓冲区
av_frame_get_buffer(frame, 0);

// 填充数据 (例如从屏幕捕获)
// frame->data[0] = Y 平面
// frame->data[1] = U 平面
// frame->data[2] = V 平面

// 设置时间戳
frame->pts = frame_number;

// 释放资源
av_frame_free(&frame);
```

**YUV420P 格式详解**:

```
原始 RGB 图像 (1920x1080)
┌─────────────────────┐
│                     │
│    RGB 像素数据      │  每像素 3 字节 (R, G, B)
│                     │  总大小: 1920 × 1080 × 3 = 6,220,800 字节
└─────────────────────┘

转换为 YUV420P
┌─────────────────────┐
│   Y 平面 (亮度)      │  1920 × 1080 = 2,073,600 字节
└─────────────────────┘
┌──────────┐
│ U 平面   │  960 × 540 = 518,400 字节 (1/4 采样)
└──────────┘
┌──────────┐
│ V 平面   │  960 × 540 = 518,400 字节 (1/4 采样)
└──────────┘

总大小: 3,110,400 字节 (节省 50%)
```

> [!TIP]
> **为什么使用 YUV420P?**
> 1. **压缩效率高**: 人眼对色度不敏感,可以降采样
> 2. **兼容性好**: 几乎所有编码器都支持
> 3. **硬件加速**: GPU 通常原生支持 YUV 格式

### 1.3 完整编码流程

```mermaid
sequenceDiagram
    participant App as 应用程序
    participant Fmt as AVFormatContext
    participant Codec as AVCodecContext
    participant Frame as AVFrame
    participant Packet as AVPacket
    participant File as 输出文件
    
    App->>Fmt: avformat_alloc_output_context2()
    App->>Fmt: avformat_new_stream()
    App->>Codec: avcodec_find_encoder()
    App->>Codec: avcodec_alloc_context3()
    App->>Codec: 配置编码参数
    App->>Codec: avcodec_open2()
    App->>Fmt: avformat_write_header()
    
    loop 每一帧
        App->>Frame: 填充原始数据
        App->>Codec: avcodec_send_frame(frame)
        
        loop 获取所有输出包
            Codec->>Packet: avcodec_receive_packet(packet)
            Packet->>Fmt: av_interleaved_write_frame()
            Fmt->>File: 写入磁盘
        end
    end
    
    App->>Codec: "avcodec_send_frame(NULL) [冲刷]"
    App->>Fmt: av_write_trailer()
    App->>Codec: avcodec_free_context()
    App->>Fmt: avformat_free_context()
```

### 1.4 资源管理最佳实践 - RAII 封装

#### 问题: 手动管理容易泄漏

```cpp
// ❌ 错误示例: 容易忘记释放
AVFormatContext* fmt_ctx = avformat_alloc_context();
AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);
// ... 如果中间抛出异常,资源泄漏!
avformat_free_context(fmt_ctx);
avcodec_free_context(&codec_ctx);
```

#### 解决方案: 使用智能指针 + 自定义删除器

```cpp
// ✅ 正确示例: RAII 封装
template<typename T>
struct AVDeleter;

template<>
struct AVDeleter<AVFormatContext> {
    void operator()(AVFormatContext* ctx) {
        if (ctx) avformat_free_context(ctx);
    }
};

template<>
struct AVDeleter<AVCodecContext> {
    void operator()(AVCodecContext* ctx) {
        if (ctx) avcodec_free_context(&ctx);
    }
};

// 定义智能指针类型
using AVFormatContextPtr = std::unique_ptr<AVFormatContext, AVDeleter<AVFormatContext>>;
using AVCodecContextPtr = std::unique_ptr<AVCodecContext, AVDeleter<AVCodecContext>>;

// 使用示例
class VideoEncoder {
private:
    AVFormatContextPtr format_ctx_;
    AVCodecContextPtr codec_ctx_;
    
public:
    bool initialize() {
        AVFormatContext* raw_fmt = nullptr;
        avformat_alloc_output_context2(&raw_fmt, nullptr, "mp4", "output.mp4");
        format_ctx_.reset(raw_fmt);
        
        const AVCodec* codec = avcodec_find_encoder(AV_CODEC_ID_H264);
        codec_ctx_.reset(avcodec_alloc_context3(codec));
        
        return true;
    }
    // 析构时自动释放所有资源!
};
```

### 1.5 像素格式转换 - libswscale

屏幕捕获通常得到 RGB/BGRA 格式,需要转换为 YUV420P:

```cpp
#include <libswscale/swscale.h>

class PixelFormatConverter {
public:
    PixelFormatConverter(int width, int height, 
                        AVPixelFormat src_fmt, 
                        AVPixelFormat dst_fmt) {
        sws_ctx_ = sws_getContext(
            width, height, src_fmt,
            width, height, dst_fmt,
            SWS_BILINEAR, nullptr, nullptr, nullptr
        );
    }
    
    ~PixelFormatConverter() {
        if (sws_ctx_) sws_freeContext(sws_ctx_);
    }
    
    void convert(AVFrame* src, AVFrame* dst) {
        sws_scale(sws_ctx_, src->data, src->linesize, 0, src->height,
                  dst->data, dst->linesize);
    }
    
private:
    SwsContext* sws_ctx_ = nullptr;
};
```

---

## 二、Windows DXGI 桌面捕获

### 2.1 DXGI 简介

**DXGI** (DirectX Graphics Infrastructure) 是 Windows 的图形基础设施,提供了高效的桌面复制 API。

**优势**:
- ✅ **性能极高**: 直接访问 GPU 帧缓冲,零拷贝
- ✅ **CPU 占用低**: 利用 GPU 完成大部分工作
- ✅ **支持多显示器**: 可以选择特定显示器
- ✅ **捕获鼠标指针**: 包含指针形状和位置信息

**限制**:
- ❌ 仅支持 Windows 8+
- ❌ 需要 DirectX 11 支持
- ❌ 不支持跨会话捕获 (如远程桌面)

### 2.2 DXGI 核心概念

```mermaid
graph TD
    A[IDXGIFactory] --> B[IDXGIAdapter]
    B --> C[IDXGIOutput]
    C --> D[IDXGIOutputDuplication]
    
    A1["工厂对象<br/>创建其他 DXGI 对象"] --> A
    B1["显卡适配器<br/>代表物理 GPU"] --> B
    C1["显示器输出<br/>代表物理显示器"] --> C
    D1["桌面复制接口<br/>捕获屏幕帧"] --> D
    
    style A fill:#FFD700
    style B fill:#87CEEB
    style C fill:#90EE90
    style D fill:#FFA500
```

### 2.3 DXGI 捕获流程

```cpp
#include <d3d11.h>
#include <dxgi1_2.h>

class DXGIScreenCapture {
public:
    bool initialize() {
        // 1. 创建 D3D11 设备
        D3D_FEATURE_LEVEL featureLevel;
        HRESULT hr = D3D11CreateDevice(
            nullptr, D3D_DRIVER_TYPE_HARDWARE, nullptr,
            0, nullptr, 0, D3D11_SDK_VERSION,
            &device_, &featureLevel, &context_
        );
        
        // 2. 获取 DXGI 设备
        IDXGIDevice* dxgiDevice = nullptr;
        device_->QueryInterface(__uuidof(IDXGIDevice), (void**)&dxgiDevice);
        
        // 3. 获取适配器
        IDXGIAdapter* adapter = nullptr;
        dxgiDevice->GetAdapter(&adapter);
        
        // 4. 枚举输出 (显示器)
        IDXGIOutput* output = nullptr;
        adapter->EnumOutputs(0, &output);  // 0 = 主显示器
        
        // 5. 获取 Output1 接口
        IDXGIOutput1* output1 = nullptr;
        output->QueryInterface(__uuidof(IDXGIOutput1), (void**)&output1);
        
        // 6. 创建桌面复制接口
        output1->DuplicateOutput(device_, &duplication_);
        
        return duplication_ != nullptr;
    }
    
    bool captureFrame(uint8_t** data, int* width, int* height) {
        IDXGIResource* desktopResource = nullptr;
        DXGI_OUTDUPL_FRAME_INFO frameInfo;
        
        // 获取下一帧
        HRESULT hr = duplication_->AcquireNextFrame(
            100,  // 超时 100ms
            &frameInfo,
            &desktopResource
        );
        
        if (FAILED(hr)) {
            return false;  // 超时或错误
        }
        
        // 查询 ID3D11Texture2D 接口
        ID3D11Texture2D* texture = nullptr;
        desktopResource->QueryInterface(__uuidof(ID3D11Texture2D), (void**)&texture);
        
        // 获取纹理描述
        D3D11_TEXTURE2D_DESC desc;
        texture->GetDesc(&desc);
        *width = desc.Width;
        *height = desc.Height;
        
        // 创建可读取的暂存纹理
        D3D11_TEXTURE2D_DESC stagingDesc = desc;
        stagingDesc.Usage = D3D11_USAGE_STAGING;
        stagingDesc.CPUAccessFlags = D3D11_CPU_ACCESS_READ;
        stagingDesc.BindFlags = 0;
        
        ID3D11Texture2D* stagingTexture = nullptr;
        device_->CreateTexture2D(&stagingDesc, nullptr, &stagingTexture);
        
        // 复制纹理到暂存区
        context_->CopyResource(stagingTexture, texture);
        
        // 映射内存
        D3D11_MAPPED_SUBRESOURCE mapped;
        context_->Map(stagingTexture, 0, D3D11_MAP_READ, 0, &mapped);
        
        // 复制数据
        int dataSize = desc.Width * desc.Height * 4;  // BGRA
        *data = new uint8_t[dataSize];
        memcpy(*data, mapped.pData, dataSize);
        
        // 取消映射
        context_->Unmap(stagingTexture, 0);
        
        // 释放资源
        stagingTexture->Release();
        texture->Release();
        desktopResource->Release();
        
        // 释放帧
        duplication_->ReleaseFrame();
        
        return true;
    }
    
private:
    ID3D11Device* device_ = nullptr;
    ID3D11DeviceContext* context_ = nullptr;
    IDXGIOutputDuplication* duplication_ = nullptr;
};
```

### 2.4 DXGI 性能优化

> [!TIP]
> **零拷贝优化**:
> 
> 不要将纹理数据复制到 CPU 内存,而是直接在 GPU 上进行格式转换和编码:
> 
> 1. 使用 NVIDIA NVENC 或 AMD VCE 硬件编码器
> 2. 直接传递 `ID3D11Texture2D` 给编码器
> 3. 避免 GPU → CPU → GPU 的往返

---

## 三、Linux X11 屏幕捕获

### 3.1 X11 简介

**X11** (X Window System) 是 Linux/Unix 的传统图形系统。

**优势**:
- ✅ **兼容性好**: 几乎所有 Linux 发行版都支持
- ✅ **API 成熟**: 文档丰富,示例多
- ✅ **跨平台**: 也支持 BSD, Solaris 等

**劣势**:
- ❌ **性能一般**: 需要从 X Server 复制帧缓冲
- ❌ **不支持 Wayland**: 现代 Linux 桌面正在迁移到 Wayland

### 3.2 X11 捕获流程

```cpp
#include <X11/Xlib.h>
#include <X11/Xutil.h>
#include <X11/extensions/XShm.h>
#include <sys/ipc.h>
#include <sys/shm.h>

class X11ScreenCapture {
public:
    bool initialize() {
        // 1. 打开显示连接
        display_ = XOpenDisplay(nullptr);
        if (!display_) return false;
        
        // 2. 获取根窗口 (整个屏幕)
        root_ = DefaultRootWindow(display_);
        
        // 3. 获取屏幕尺寸
        XWindowAttributes attrs;
        XGetWindowAttributes(display_, root_, &attrs);
        width_ = attrs.width;
        height_ = attrs.height;
        
        // 4. 创建共享内存段 (优化性能)
        shminfo_.shmid = shmget(IPC_PRIVATE, 
                                width_ * height_ * 4, 
                                IPC_CREAT | 0777);
        shminfo_.shmaddr = (char*)shmat(shminfo_.shmid, 0, 0);
        shminfo_.readOnly = False;
        
        // 5. 附加到 X Server
        XShmAttach(display_, &shminfo_);
        
        // 6. 创建 XImage
        image_ = XShmCreateImage(
            display_, DefaultVisual(display_, DefaultScreen(display_)),
            24, ZPixmap, shminfo_.shmaddr, &shminfo_,
            width_, height_
        );
        
        return true;
    }
    
    bool captureFrame(uint8_t** data, int* width, int* height) {
        // 使用共享内存捕获屏幕
        XShmGetImage(display_, root_, image_, 0, 0, AllPlanes);
        
        // 数据已在 shminfo_.shmaddr 中
        *data = (uint8_t*)shminfo_.shmaddr;
        *width = width_;
        *height = height_;
        
        return true;
    }
    
    ~X11ScreenCapture() {
        if (image_) XDestroyImage(image_);
        if (shminfo_.shmaddr) {
            XShmDetach(display_, &shminfo_);
            shmdt(shminfo_.shmaddr);
            shmctl(shminfo_.shmid, IPC_RMID, 0);
        }
        if (display_) XCloseDisplay(display_);
    }
    
private:
    Display* display_ = nullptr;
    Window root_;
    XImage* image_ = nullptr;
    XShmSegmentInfo shminfo_;
    int width_, height_;
};
```

### 3.3 Wayland 支持 (PipeWire)

现代 Linux 桌面使用 Wayland,需要通过 **PipeWire** 捕获屏幕:

```cpp
// PipeWire 捕获示例 (简化版)
#include <pipewire/pipewire.h>

class PipeWireCapture {
public:
    bool initialize() {
        pw_init(nullptr, nullptr);
        
        // 创建主循环
        loop_ = pw_main_loop_new(nullptr);
        
        // 创建流
        stream_ = pw_stream_new_simple(
            pw_main_loop_get_loop(loop_),
            "screen-capture",
            pw_properties_new(
                PW_KEY_MEDIA_TYPE, "Video",
                PW_KEY_MEDIA_CATEGORY, "Capture",
                nullptr
            ),
            &stream_events_,
            this
        );
        
        return stream_ != nullptr;
    }
    
private:
    pw_main_loop* loop_ = nullptr;
    pw_stream* stream_ = nullptr;
    static const pw_stream_events stream_events_;
};
```

---

## 四、C++ 设计模式应用

### 4.1 策略模式 (Strategy Pattern)

**问题**: 不同平台的屏幕捕获 API 不同,如何统一接口?

**解决方案**: 定义通用接口,平台特定实现

```mermaid
classDiagram
    class IScreenGrabber {
        <<interface>>
        +start() bool
        +stop() void
        +captureFrame() FrameData
        +getWidth() int
        +getHeight() int
    }
    
    class DXGIGrabber {
        -IDXGIOutputDuplication* duplication_
        -ID3D11Device* device_
        +start() bool
        +captureFrame() FrameData
    }
    
    class X11Grabber {
        -Display* display_
        -XImage* image_
        +start() bool
        +captureFrame() FrameData
    }
    
    class GrabberFactory {
        +createGrabber() IScreenGrabber*
    }
    
    IScreenGrabber <|-- DXGIGrabber
    IScreenGrabber <|-- X11Grabber
    GrabberFactory ..> IScreenGrabber
```

**代码实现**:

```cpp
// 接口定义
class IScreenGrabber {
public:
    virtual ~IScreenGrabber() = default;
    
    virtual bool start() = 0;
    virtual void stop() = 0;
    virtual bool captureFrame(uint8_t** data, int* width, int* height) = 0;
};

// 工厂类
class GrabberFactory {
public:
    static std::unique_ptr<IScreenGrabber> create() {
#ifdef _WIN32
        return std::make_unique<DXGIGrabber>();
#elif defined(__linux__)
        return std::make_unique<X11Grabber>();
#else
        return nullptr;
#endif
    }
};

// 使用示例
auto grabber = GrabberFactory::create();
if (grabber && grabber->start()) {
    uint8_t* data;
    int width, height;
    grabber->captureFrame(&data, &width, &height);
}
```

### 4.2 RAII 模式 (Resource Acquisition Is Initialization)

**核心思想**: 资源的生命周期与对象的生命周期绑定

```cpp
class FFmpegEncoder {
public:
    FFmpegEncoder(const std::string& output_path) {
        // 构造时获取资源
        avformat_alloc_output_context2(&fmt_ctx_, nullptr, "mp4", output_path.c_str());
        codec_ctx_ = avcodec_alloc_context3(avcodec_find_encoder(AV_CODEC_ID_H264));
    }
    
    ~FFmpegEncoder() {
        // 析构时自动释放资源
        if (codec_ctx_) avcodec_free_context(&codec_ctx_);
        if (fmt_ctx_) avformat_free_context(fmt_ctx_);
    }
    
    // 禁止拷贝
    FFmpegEncoder(const FFmpegEncoder&) = delete;
    FFmpegEncoder& operator=(const FFmpegEncoder&) = delete;
    
    // 允许移动
    FFmpegEncoder(FFmpegEncoder&& other) noexcept {
        fmt_ctx_ = other.fmt_ctx_;
        codec_ctx_ = other.codec_ctx_;
        other.fmt_ctx_ = nullptr;
        other.codec_ctx_ = nullptr;
    }
    
private:
    AVFormatContext* fmt_ctx_ = nullptr;
    AVCodecContext* codec_ctx_ = nullptr;
};
```

### 4.3 生产者-消费者模式

**问题**: 采集线程和编码线程如何协作?

**解决方案**: 使用线程安全队列解耦

```mermaid
sequenceDiagram
    participant P as 生产者线程<br/>(屏幕采集)
    participant Q as 线程安全队列
    participant C as 消费者线程<br/>(编码器)
    
    loop 每 16ms
        P->>P: 捕获屏幕
        P->>Q: push(frame)
        Note over Q: 队列缓冲
    end
    
    loop 持续运行
        C->>Q: pop(frame)
        alt 队列非空
            Q-->>C: 返回帧
            C->>C: 编码帧
        else 队列为空
            Q-->>C: 等待或超时
        end
    end
```

**代码实现**:

```cpp
template<typename T>
class ThreadSafeQueue {
public:
    void push(T value) {
        std::lock_guard<std::mutex> lock(mutex_);
        queue_.push(std::move(value));
        cond_.notify_one();
    }
    
    bool pop(T& value, std::chrono::milliseconds timeout) {
        std::unique_lock<std::mutex> lock(mutex_);
        if (!cond_.wait_for(lock, timeout, [this] { return !queue_.empty(); })) {
            return false;  // 超时
        }
        value = std::move(queue_.front());
        queue_.pop();
        return true;
    }
    
    size_t size() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return queue_.size();
    }
    
private:
    mutable std::mutex mutex_;
    std::condition_variable cond_;
    std::queue<T> queue_;
};
```

---

## 五、多线程编程实践

### 5.1 线程模型设计

```mermaid
graph TB
    UI[UI 线程<br/>Qt 主线程] --> |信号槽| Controller[录制控制器]
    
    Controller --> |启动| Grabber[采集线程]
    Controller --> |启动| Encoder[编码线程]
    
    Grabber --> |帧数据| Queue[线程安全队列]
    Queue --> Encoder
    
    Encoder --> |进度信号| Controller
    Controller --> |更新 UI| UI
    
    style UI fill:#FFD700
    style Grabber fill:#87CEEB
    style Encoder fill:#90EE90
    style Queue fill:#FFA500
```

### 5.2 Qt 线程集成

```cpp
class CaptureWorker : public QObject {
    Q_OBJECT
    
public:
    CaptureWorker(IScreenGrabber* grabber, ThreadSafeQueue<FrameData>* queue)
        : grabber_(grabber), queue_(queue) {}
    
public slots:
    void start() {
        running_ = true;
        
        while (running_) {
            uint8_t* data;
            int width, height;
            
            if (grabber_->captureFrame(&data, &width, &height)) {
                FrameData frame{data, width, height};
                queue_->push(std::move(frame));
                
                emit framesCaptured(queue_->size());
            }
            
            QThread::msleep(16);  // 60 fps
        }
        
        emit finished();
    }
    
    void stop() {
        running_ = false;
    }
    
signals:
    void framesCaptured(int queueSize);
    void finished();
    
private:
    IScreenGrabber* grabber_;
    ThreadSafeQueue<FrameData>* queue_;
    std::atomic<bool> running_{false};
};

// 使用示例
QThread* captureThread = new QThread;
CaptureWorker* worker = new CaptureWorker(grabber.get(), &frameQueue);
worker->moveToThread(captureThread);

connect(captureThread, &QThread::started, worker, &CaptureWorker::start);
connect(worker, &CaptureWorker::finished, captureThread, &QThread::quit);

captureThread->start();
```

### 5.3 线程同步与数据竞争

> [!CAUTION]
> **常见错误: 未加锁访问共享变量**

```cpp
// ❌ 错误示例
class RecordingController {
public:
    void startRecording() {
        isRecording_ = true;  // 数据竞争!
    }
    
    bool isRecording() const {
        return isRecording_;  // 数据竞争!
    }
    
private:
    bool isRecording_ = false;  // 多线程访问
};
```

```cpp
// ✅ 正确示例
class RecordingController {
public:
    void startRecording() {
        isRecording_.store(true, std::memory_order_release);
    }
    
    bool isRecording() const {
        return isRecording_.load(std::memory_order_acquire);
    }
    
private:
    std::atomic<bool> isRecording_{false};
};
```

---

## 六、综合实践示例

### 6.1 完整的屏幕录制器架构

```cpp
class ScreenRecorder : public QObject {
    Q_OBJECT
    
public:
    ScreenRecorder() {
        // 创建采集器
        grabber_ = GrabberFactory::create();
        
        // 创建工作线程
        captureThread_ = new QThread(this);
        encodeThread_ = new QThread(this);
        
        // 创建工作对象
        captureWorker_ = new CaptureWorker(grabber_.get(), &frameQueue_);
        encodeWorker_ = new EncodeWorker(&frameQueue_, "output.mp4");
        
        // 移动到线程
        captureWorker_->moveToThread(captureThread_);
        encodeWorker_->moveToThread(encodeThread_);
        
        // 连接信号
        connect(captureThread_, &QThread::started, captureWorker_, &CaptureWorker::start);
        connect(encodeThread_, &QThread::started, encodeWorker_, &EncodeWorker::start);
    }
    
    void startRecording() {
        if (grabber_->start()) {
            captureThread_->start();
            encodeThread_->start();
            emit recordingStarted();
        }
    }
    
    void stopRecording() {
        captureWorker_->stop();
        encodeWorker_->stop();
        
        captureThread_->quit();
        encodeThread_->quit();
        
        captureThread_->wait();
        encodeThread_->wait();
        
        emit recordingStopped();
    }
    
signals:
    void recordingStarted();
    void recordingStopped();
    void progressUpdated(int frameCount);
    
private:
    std::unique_ptr<IScreenGrabber> grabber_;
    ThreadSafeQueue<FrameData> frameQueue_;
    
    QThread* captureThread_;
    QThread* encodeThread_;
    
    CaptureWorker* captureWorker_;
    EncodeWorker* encodeWorker_;
};
```

---

## 七、学习检查清单

完成本章学习后,你应该能够:

- [ ] 理解 FFmpeg 的核心数据结构 (`AVFormatContext`, `AVCodecContext`, `AVFrame`, `AVPacket`)
- [ ] 使用 RAII 模式管理 FFmpeg 资源
- [ ] 配置 H.264 编码器参数
- [ ] 使用 libswscale 进行像素格式转换
- [ ] 在 Windows 上使用 DXGI 捕获屏幕
- [ ] 在 Linux 上使用 X11 捕获屏幕
- [ ] 应用策略模式实现跨平台抽象
- [ ] 实现线程安全队列
- [ ] 使用 Qt 线程进行异步处理
- [ ] 避免常见的多线程数据竞争问题

---

## 八、参考资源

### FFmpeg
- [FFmpeg 官方文档](https://ffmpeg.org/documentation.html)
- [FFmpeg libav 教程](https://github.com/leandromoreira/ffmpeg-libav-tutorial)

### DXGI
- [DXGI Desktop Duplication API](https://docs.microsoft.com/en-us/windows/win32/direct3ddxgi/desktop-dup-api)

### X11
- [Xlib Programming Manual](https://www.x.org/releases/X11R7.7/doc/libX11/libX11/libX11.html)

### 设计模式
- 《设计模式: 可复用面向对象软件的基础》
- 《C++ Concurrency in Action》
