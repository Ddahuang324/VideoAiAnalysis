# 第三章：屏幕录制引擎架构设计

> **文档概述**  
> 本文档是第三章三个子节（3.1 采集器架构设计、3.2 视频流处理设计、3.3 写入控制）的框架性汇总，全面阐述 C++ 核心屏幕录制引擎的完整架构设计。

---

## 目录

1. [总体架构概览](#一总体架构概览)
2. [采集器架构设计](#二采集器架构设计)
3. [视频流处理设计](#三视频流处理设计)
4. [写入控制设计](#四写入控制设计)
5. [模块协作机制](#五模块协作机制)
6. [性能优化策略](#六性能优化策略)
7. [错误处理与容错](#七错误处理与容错)

---

## 一、总体架构概览

### 1.1 设计目标

屏幕录制引擎是整个 AI 视频分析系统的核心基础设施，其设计目标包括：

| 目标维度 | 具体要求 | 技术实现 |
|---------|---------|---------|
| **跨平台性** | 支持 Windows/Linux 双平台 | 接口抽象 + 平台实现分离 |
| **高性能** | 60fps 稳定录制，CPU 占用 < 15% | 多线程 + 零拷贝 + 硬件加速 |
| **资源安全** | 无内存泄漏，异常安全 | RAII + 智能指针 + 异常处理 |
| **可扩展性** | 易于添加新捕获源/编码器 | 工厂模式 + 策略模式 |
| **可靠性** | 长时间录制不崩溃 | 分片策略 + 磁盘监控 |

### 1.2 整体架构图

```mermaid
graph TB
    subgraph "UI 层 (QML)"
        UI[RecordingController<br/>录制控制器]
    end
    
    subgraph "采集层 (Capture Layer)"
        Factory[GrabberFactory<br/>采集器工厂]
        IGrabber[IScreenGrabber<br/>采集器接口]
        DXGI[DXGIGrabber<br/>Windows 实现]
        X11[X11Grabber<br/>Linux 实现]
        FFmpegW[FFmpegWrapper<br/>FFmpeg 封装]
    end
    
    subgraph "处理层 (Processing Layer)"
        GrabberThread[FrameGrabberThread<br/>采集线程]
        Queue[ThreadSafeQueue<br/>线程安全队列<br/>容量: 30 帧]
        EncoderThread[FrameEncoder<br/>编码线程]
    end
    
    subgraph "存储层 (Storage Layer)"
        Writer[MediaWriter<br/>媒体写入器]
        PathMgr[PathManager<br/>路径管理器]
        Metadata[MetadataManager<br/>元数据管理]
    end
    
    subgraph "文件系统"
        TempFiles[临时分片<br/>temp/chunk_*.mp4]
        FinalFile[最终文件<br/>records/*.mp4]
        MetaJSON[元数据<br/>metadata/*.json]
    end
    
    UI --> Factory
    Factory -.创建.-> IGrabber
    IGrabber <|.. DXGI
    IGrabber <|.. X11
    
    UI --> GrabberThread
    UI --> EncoderThread
    
    GrabberThread --> IGrabber
    GrabberThread --> Queue
    Queue --> EncoderThread
    EncoderThread --> FFmpegW
    EncoderThread --> Writer
    
    Writer --> PathMgr
    Writer --> TempFiles
    Writer --> FinalFile
    Writer --> Metadata
    Metadata --> MetaJSON
    
    style UI fill:#FFD700
    style Queue fill:#FFA500
    style Writer fill:#87CEEB
    style FinalFile fill:#90EE90
```

### 1.3 核心模块职责

```mermaid
graph LR
    A[采集器模块] -->|原始帧数据| B[处理模块]
    B -->|编码包| C[写入模块]
    C -->|视频文件| D[AI 分析模块]
    
    A1[跨平台抽象<br/>资源管理] -.-> A
    B1[线程调度<br/>队列管理<br/>像素转换] -.-> B
    C1[分片策略<br/>磁盘管理<br/>元数据] -.-> C
    
    style A fill:#FFB6C1
    style B fill:#87CEEB
    style C fill:#98FB98
    style D fill:#DDA0DD
```

| 模块 | 核心职责 | 关键类 | 依赖 |
|------|---------|--------|------|
| **采集器** | 屏幕捕获、资源管理 | `IScreenGrabber`, `FFmpegWrapper` | DirectX/X11, FFmpeg |
| **处理器** | 异步采集、编码、队列管理 | `FrameGrabberThread`, `FrameEncoder` | Qt 线程、采集器 |
| **写入器** | 文件写入、分片、元数据 | `MediaWriter`, `PathManager` | FFmpeg, 文件系统 |

---

## 二、采集器架构设计

### 2.1 设计原则

采集器架构遵循 **SOLID 原则**，实现跨平台抽象和资源安全管理：

```mermaid
classDiagram
    class IScreenGrabber {
        <<interface>>
        +start() bool
        +stop() void
        +pause() void
        +resume() void
        +captureFrame(timeout_ms) FrameData
        +getWidth() int
        +getHeight() int
        +getFrameRate() int
        +isRunning() bool
    }
    
    class DXGIGrabber {
        -ID3D11Device* device_
        -IDXGIOutputDuplication* duplication_
        -int monitor_index_
        +start() bool
        +captureFrame() FrameData
        -initializeD3D11() bool
        -createDuplication() bool
    }
    
    class X11Grabber {
        -Display* display_
        -XImage* image_
        -XShmSegmentInfo shminfo_
        +start() bool
        +captureFrame() FrameData
        -initializeShm() bool
    }
    
    class GrabberFactory {
        +createGrabber(type) unique_ptr~IScreenGrabber~
        +getAvailableGrabbers() vector~GrabberType~
        -detectBestGrabber() GrabberType
    }
    
    class FFmpegWrapper {
        -AVFormatContextPtr format_ctx_
        -AVCodecContextPtr codec_ctx_
        -AVFramePtr yuv_frame_
        -SwsContextPtr sws_ctx_
        +initialize(config) bool
        +encodeFrame(frame_data) bool
        +finalize() void
        -configureEncoder() bool
    }
    
    IScreenGrabber <|-- DXGIGrabber : 实现
    IScreenGrabber <|-- X11Grabber : 实现
    GrabberFactory ..> IScreenGrabber : 创建
    FFmpegWrapper ..> IScreenGrabber : 使用
```

> [!IMPORTANT]
> **依赖倒置原则 (DIP)**  
> 高层模块（`ScreenRecorder`）依赖抽象接口（`IScreenGrabber`），而不依赖具体实现（`DXGIGrabber`）。这使得添加新平台（如 macOS）只需实现接口，无需修改现有代码。

### 2.2 核心接口设计

#### FrameData 结构

```cpp
struct FrameData {
    uint8_t* data;                          // 像素数据指针
    int width, height, stride;              // 尺寸和行字节数
    PixelFormat format;                     // 像素格式 (BGRA/RGBA/YUV420P)
    int64_t timestamp_us;                   // 时间戳 (微秒)
    std::shared_ptr<uint8_t> data_holder;   // RAII 内存管理
};
```

**设计亮点**：
- ✅ **自动内存管理**：使用 `shared_ptr` 防止内存泄漏
- ✅ **零拷贝友好**：原始指针 `data` 方便直接访问
- ✅ **线程安全**：引用计数保证多线程共享安全

#### IScreenGrabber 接口

```cpp
class IScreenGrabber {
public:
    virtual ~IScreenGrabber() = default;
    
    // 生命周期管理
    virtual bool start() = 0;
    virtual void stop() = 0;
    virtual void pause() = 0;
    virtual void resume() = 0;
    
    // 核心功能
    virtual FrameData captureFrame(int timeout_ms = 100) = 0;
    
    // 属性查询
    virtual int getWidth() const = 0;
    virtual int getHeight() const = 0;
    virtual int getFrameRate() const = 0;
    virtual PixelFormat getPixelFormat() const = 0;
    
    // 状态查询
    virtual bool isRunning() const = 0;
    virtual bool isPaused() const = 0;
    virtual std::string getLastError() const = 0;
};
```

### 2.3 平台实现要点

#### Windows DXGI 实现

```mermaid
sequenceDiagram
    participant App as 应用程序
    participant DXGI as DXGIGrabber
    participant D3D as D3D11 Device
    participant Dup as OutputDuplication
    
    App->>DXGI: start()
    activate DXGI
    
    DXGI->>D3D: D3D11CreateDevice()
    D3D-->>DXGI: device, context
    
    DXGI->>D3D: GetAdapter()
    D3D-->>DXGI: adapter
    
    DXGI->>Dup: DuplicateOutput()
    Dup-->>DXGI: duplication
    
    DXGI-->>App: true (成功)
    deactivate DXGI
    
    loop 每帧
        App->>DXGI: captureFrame()
        activate DXGI
        DXGI->>Dup: AcquireNextFrame()
        Dup-->>DXGI: desktop_resource
        DXGI->>DXGI: MapTexture()
        DXGI-->>App: FrameData
        deactivate DXGI
    end
```

**关键技术点**：
1. **Desktop Duplication API**：Windows 8+ 官方桌面捕获 API
2. **零拷贝优化**：直接映射 GPU 纹理到 CPU 内存
3. **超时处理**：`AcquireNextFrame` 支持超时，避免阻塞

#### Linux X11 实现

```cpp
bool X11Grabber::start() {
    // 1. 打开 X11 显示
    display_ = XOpenDisplay(nullptr);
    if (!display_) return false;
    
    // 2. 获取根窗口
    root_ = DefaultRootWindow(display_);
    
    // 3. 初始化共享内存 (XShm)
    if (!initializeShm()) {
        cleanup();
        return false;
    }
    
    running_ = true;
    return true;
}

FrameData X11Grabber::captureFrame(int timeout_ms) {
    // 使用 XShmGetImage 零拷贝捕获
    XShmGetImage(display_, root_, image_, 0, 0, AllPlanes);
    
    FrameData frame;
    frame.data = reinterpret_cast<uint8_t*>(image_->data);
    frame.width = width_;
    frame.height = height_;
    frame.stride = image_->bytes_per_line;
    frame.format = PixelFormat::BGRA;
    
    return frame;
}
```

### 2.4 FFmpegWrapper RAII 封装

```mermaid
graph TB
    subgraph "RAII 资源管理"
        A[FFmpegWrapper 构造] --> B[分配资源]
        B --> C[AVFormatContext]
        B --> D[AVCodecContext]
        B --> E[AVFrame]
        B --> F[SwsContext]
        
        G[FFmpegWrapper 析构] --> H[自动释放]
        H --> I[自定义删除器]
        I --> J[avio_closep]
        I --> K[avcodec_free_context]
        I --> L[av_frame_free]
        I --> M[sws_freeContext]
    end
    
    style A fill:#90EE90
    style G fill:#FFB6C1
    style I fill:#87CEEB
```

**自定义删除器示例**：

```cpp
struct AVFormatContextDeleter {
    void operator()(AVFormatContext* ctx) {
        if (ctx) {
            // 关键：先关闭 I/O，再释放上下文
            if (ctx->pb) avio_closep(&ctx->pb);
            avformat_free_context(ctx);
        }
    }
};

using AVFormatContextPtr = std::unique_ptr<AVFormatContext, AVFormatContextDeleter>;
```

> [!WARNING]
> **资源释放顺序很重要！**  
> 必须先关闭 I/O (`avio_closep`)，再释放格式上下文 (`avformat_free_context`)，否则会导致文件损坏或内存泄漏。

---

## 三、视频流处理设计

### 3.1 生产者-消费者架构

视频流处理采用经典的 **生产者-消费者模式**，通过线程安全队列解耦采集和编码：

```mermaid
graph TB
    subgraph "采集线程 (生产者)"
        GT[FrameGrabberThread]
        Grabber[IScreenGrabber]
        Timer[帧率控制器<br/>16.67ms @ 60fps]
    end
    
    subgraph "共享队列"
        Q[ThreadSafeQueue<br/>容量: 30 帧<br/>~240MB @ 1080p]
    end
    
    subgraph "编码线程 (消费者)"
        ET[FrameEncoder]
        Converter[像素格式转换<br/>BGRA → YUV420P]
        Encoder[FFmpegWrapper]
    end
    
    GT --> Grabber
    Grabber -->|FrameData| GT
    GT --> Timer
    Timer -->|控制帧率| GT
    GT -->|push| Q
    
    Q -->|pop| ET
    ET --> Converter
    Converter --> Encoder
    Encoder -->|AVPacket| Writer[MediaWriter]
    
    style Q fill:#FFA500
    style GT fill:#87CEEB
    style ET fill:#90EE90
```

### 3.2 线程安全队列设计

#### 核心实现

```cpp
template<typename T>
class ThreadSafeQueue {
public:
    explicit ThreadSafeQueue(size_t max_size = 0) : max_size_(max_size) {}
    
    // 阻塞式 push
    bool push(T value, std::chrono::milliseconds timeout = std::chrono::milliseconds::max()) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 等待队列有空间
        if (max_size_ > 0) {
            if (!not_full_.wait_for(lock, timeout, [this] { 
                return queue_.size() < max_size_ || stopped_; 
            })) {
                return false;  // 超时
            }
        }
        
        if (stopped_) return false;
        
        queue_.push(std::move(value));
        not_empty_.notify_one();  // 唤醒消费者
        return true;
    }
    
    // 阻塞式 pop
    bool pop(T& value, std::chrono::milliseconds timeout = std::chrono::milliseconds(100)) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 等待队列非空
        if (!not_empty_.wait_for(lock, timeout, [this] { 
            return !queue_.empty() || stopped_; 
        })) {
            return false;  // 超时
        }
        
        if (stopped_ && queue_.empty()) return false;
        
        value = std::move(queue_.front());
        queue_.pop();
        not_full_.notify_one();  // 唤醒生产者
        return true;
    }
    
private:
    std::queue<T> queue_;
    mutable std::mutex mutex_;
    std::condition_variable not_empty_;  // 队列非空条件
    std::condition_variable not_full_;   // 队列未满条件
    size_t max_size_;
    bool stopped_ = false;
};
```

#### 队列容量设计

```mermaid
graph LR
    A[队列容量选择] --> B[太小 < 10 帧]
    A --> C[适中 20-30 帧]
    A --> D[太大 > 100 帧]
    
    B --> B1[✅ 低延迟<br/>❌ 易丢帧]
    C --> C1[✅ 平衡性能和延迟<br/>✅ 推荐方案]
    D --> D1[✅ 不易丢帧<br/>❌ 高延迟, 高内存]
    
    style C fill:#90EE90
    style C1 fill:#90EE90
```

> [!TIP]
> **推荐配置：30 帧 (0.5 秒 @ 60fps)**  
> - 1920×1080 BGRA：每帧 ~8MB  
> - 30 帧总内存：~240MB  
> - 延迟：最大 0.5 秒  
> 
> 这个配置在性能和延迟之间取得了良好平衡。

### 3.3 FrameGrabberThread 实现

#### 采集循环

```cpp
void FrameGrabberThread::captureLoop() {
    start_time_ = std::chrono::steady_clock::now();
    last_frame_time_ = start_time_;
    
    emit started();
    
    while (running_) {
        if (paused_) {
            QThread::msleep(10);
            continue;
        }
        
        // 1. 捕获帧
        auto capture_start = std::chrono::steady_clock::now();
        FrameData frame = grabber_->captureFrame(100);
        
        if (!frame.data) continue;  // 捕获失败
        
        // 2. 设置时间戳
        frame.timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
            capture_start - start_time_
        ).count();
        
        // 3. 推送到队列
        if (!queue_->push(std::move(frame), std::chrono::milliseconds(100))) {
            dropped_count_++;
            emit framesDropped(dropped_count_);
        } else {
            frame_count_++;
            updateFPS();
            
            // 每 30 帧发送一次进度信号
            if (frame_count_ % 30 == 0) {
                emit frameCaptured(frame_count_, queue_->size(), current_fps_);
            }
        }
        
        // 4. 帧率控制
        waitForNextFrame();
    }
    
    emit stopped();
}
```

#### 精确帧率控制

```cpp
void FrameGrabberThread::waitForNextFrame() {
    auto now = std::chrono::steady_clock::now();
    auto elapsed = now - last_frame_time_;
    
    if (elapsed < frame_interval_) {
        auto sleep_duration = frame_interval_ - elapsed;
        std::this_thread::sleep_for(sleep_duration);  // 高精度睡眠
    }
    
    last_frame_time_ = std::chrono::steady_clock::now();
}
```

> [!IMPORTANT]
> **帧率控制的重要性**  
> 如果不控制帧率，采集线程会以最快速度运行：
> - CPU 占用 100%
> - 队列快速填满
> - 编码器跟不上，大量丢帧
> 
> 精确的帧率控制确保稳定的 60fps 输出。

### 3.4 FrameEncoder 实现

#### 编码循环

```cpp
void FrameEncoder::encodeLoop() {
    // 初始化编码器
    if (!encoder_->initialize(config_)) {
        emit errorOccurred(QString::fromStdString(encoder_->getLastError()));
        return;
    }
    
    emit started();
    
    while (running_) {
        FrameData frame;
        
        // 从队列取帧 (超时 100ms)
        if (!queue_->pop(frame, std::chrono::milliseconds(100))) {
            continue;  // 超时，继续等待
        }
        
        // 处理帧
        if (!processFrame(frame)) {
            emit errorOccurred(QString::fromStdString(encoder_->getLastError()));
            break;
        }
        
        encoded_count_++;
        
        // 每 30 帧发送一次进度信号
        if (encoded_count_ % 30 == 0) {
            emit frameEncoded(encoded_count_, encoder_->getOutputFileSize());
        }
    }
    
    // 完成编码
    encoder_->finalize();
    emit encodingFinished(encoded_count_, QString::fromStdString(config_.output_path));
    emit stopped();
}
```

#### 像素格式转换

```cpp
bool FFmpegWrapper::convertPixelFormat(const FrameData& src, AVFrame* dst) {
    const uint8_t* src_data[1] = { src.data };
    int src_linesize[1] = { src.stride > 0 ? src.stride : src.width * 4 };
    
    // 使用 swscale 进行 BGRA → YUV420P 转换
    int ret = sws_scale(
        sws_ctx_.get(),
        src_data,
        src_linesize,
        0,
        src.height,
        dst->data,
        dst->linesize
    );
    
    return ret > 0;
}
```

### 3.5 完整数据流

```mermaid
sequenceDiagram
    participant UI as RecordingController
    participant GT as FrameGrabberThread
    participant Q as ThreadSafeQueue
    participant ET as FrameEncoder
    participant File as 输出文件
    
    UI->>GT: start()
    UI->>ET: start()
    
    activate GT
    activate ET
    
    par 采集线程
        loop 每 16.67ms (60fps)
            GT->>GT: captureFrame()
            GT->>Q: push(frame)
            
            alt 队列已满
                Note over GT,Q: 阻塞等待或丢帧
            end
            
            GT->>GT: waitForNextFrame()
        end
    and 编码线程
        loop 持续运行
            ET->>Q: pop(frame, 100ms)
            
            alt 队列非空
                Q-->>ET: 返回帧
                ET->>ET: convertPixelFormat()
                ET->>ET: encodeFrame()
                ET->>File: write(packet)
                ET-->>UI: frameEncoded(count, size)
            else 超时
                Note over ET: 继续等待
            end
        end
    end
    
    UI->>GT: stop()
    UI->>ET: stop()
    
    deactivate GT
    deactivate ET
    
    ET-->>UI: encodingFinished()
```

---

## 四、写入控制设计

### 4.1 MediaWriter 架构

```mermaid
classDiagram
    class MediaWriter {
        -WriterConfig config_
        -AVFormatContext* format_ctx_
        -vector~string~ chunk_paths_
        -int current_chunk_index_
        -int64_t bytes_written_
        +initialize(config) bool
        +writePacket(packet) bool
        +finalize() string
        -shouldCreateNewChunk() bool
        -createNewChunk() bool
        -finalizeCurrentChunk() bool
        -mergeChunks() bool
        -checkDiskSpace() bool
    }
    
    class WriterConfig {
        +string output_path
        +string temp_dir
        +bool enable_chunking
        +int64_t chunk_duration_sec
        +int64_t chunk_size_mb
        +int64_t min_free_space_mb
        +bool auto_stop_on_low_space
    }
    
    class PathManager {
        +initialize(base_dir) bool
        +generateOutputPath() string
        +getTempDir() string
        +getRecordsDir() string
        +getMetadataDir() string
        +cleanupOldFiles(days) void
    }
    
    class MetadataManager {
        +saveMetadata(video_path, metadata) bool
        +loadMetadata(video_path) Metadata
        +generateThumbnail(video_path) string
    }
    
    MediaWriter --> WriterConfig : 使用
    MediaWriter --> PathManager : 依赖
    MediaWriter --> MetadataManager : 依赖
```

### 4.2 视频分片策略

#### 分片方案对比

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **不分片** | 简单，一个文件 | 大文件难处理，失败全丢 | 短时录制 (< 10 分钟) |
| **按时长分片** | 固定时长，易管理 | 文件大小不均 | 长时录制，AI 分析 ✅ |
| **按大小分片** | 文件大小均匀 | 时长不固定 | 存储管理优先 |
| **混合分片** | 兼顾时长和大小 | 逻辑复杂 | 生产环境 |

> [!TIP]
> **推荐方案：按时长分片，每 5 分钟一个分片**  
> 理由：
> 1. AI 分析通常按时间段进行
> 2. 5 分钟 @ 1080p60fps ≈ 300-500MB，大小适中
> 3. 失败时只丢失最后一个分片

#### 分片判断逻辑

```cpp
bool MediaWriter::shouldCreateNewChunk() {
    // 1. 按时长分片
    auto now = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::seconds>(
        now - chunk_start_time_
    ).count();
    
    if (duration >= config_.chunk_duration_sec) {
        return true;
    }
    
    // 2. 按大小分片
    int64_t chunk_size_bytes = config_.chunk_size_mb * 1024 * 1024;
    if (chunk_bytes_written_ >= chunk_size_bytes) {
        return true;
    }
    
    return false;
}
```

### 4.3 写入流程

```mermaid
sequenceDiagram
    participant Encoder as FrameEncoder
    participant Writer as MediaWriter
    participant Disk as 磁盘
    participant PathMgr as PathManager
    
    Encoder->>Writer: initialize(config)
    activate Writer
    
    Writer->>PathMgr: getTempDir()
    PathMgr-->>Writer: "temp/"
    
    Writer->>Writer: checkDiskSpace()
    
    Writer->>Writer: createNewChunk()
    Writer->>Disk: 创建 chunk_0.mp4
    Writer->>Disk: avformat_write_header()
    
    Writer-->>Encoder: true (成功)
    deactivate Writer
    
    loop 每个编码包
        Encoder->>Writer: writePacket(packet)
        activate Writer
        
        Writer->>Writer: checkDiskSpace()
        
        alt 需要分片
            Writer->>Writer: shouldCreateNewChunk()
            Writer->>Writer: finalizeCurrentChunk()
            Writer->>Disk: av_write_trailer()
            Writer->>Writer: createNewChunk()
            Writer->>Disk: 创建 chunk_1.mp4
        end
        
        Writer->>Disk: av_interleaved_write_frame()
        Writer-->>Encoder: true
        deactivate Writer
    end
    
    Encoder->>Writer: finalize()
    activate Writer
    
    Writer->>Writer: finalizeCurrentChunk()
    Writer->>Writer: mergeChunks()
    Writer->>Disk: ffmpeg -f concat
    Writer->>Disk: 生成最终文件
    Writer->>Writer: cleanupTempFiles()
    
    Writer-->>Encoder: output_path
    deactivate Writer
```

### 4.4 分片合并实现

```cpp
bool MediaWriter::mergeChunks() {
    if (chunk_paths_.size() == 1) {
        // 只有一个分片，直接移动
        std::filesystem::rename(chunk_paths_[0], config_.output_path);
        return true;
    }
    
    // 生成 concat 列表文件
    std::string concat_file = config_.temp_dir + "/concat_list.txt";
    std::ofstream ofs(concat_file);
    
    for (const auto& path : chunk_paths_) {
        ofs << "file '" << std::filesystem::absolute(path).string() << "'\n";
    }
    ofs.close();
    
    // 使用 FFmpeg concat demuxer 合并
    std::string cmd = "ffmpeg -f concat -safe 0 -i " + concat_file +
                      " -c copy " + config_.output_path;
    
    int ret = std::system(cmd.c_str());
    if (ret != 0) {
        last_error_ = "合并分片失败";
        return false;
    }
    
    // 验证输出文件
    if (!std::filesystem::exists(config_.output_path)) {
        last_error_ = "输出文件不存在";
        return false;
    }
    
    return true;
}
```

### 4.5 文件管理系统

#### 目录结构

```
project_root/
├── temp/                      # 临时目录
│   ├── chunk_0.mp4           # 分片 0
│   ├── chunk_1.mp4           # 分片 1
│   ├── chunk_N.mp4           # 分片 N
│   └── concat_list.txt       # 合并列表
├── records/                   # 输出目录
│   ├── 2024-12-11_20-30-00.mp4
│   ├── 2024-12-11_21-00-00.mp4
│   └── metadata/             # 元数据目录
│       ├── 2024-12-11_20-30-00.json
│       └── 2024-12-11_21-00-00.json
└── logs/                      # 日志目录
    └── recording.log
```

#### PathManager 实现

```cpp
class PathManager {
public:
    static PathManager& instance() {
        static PathManager instance;
        return instance;
    }
    
    bool initialize(const std::string& base_dir) {
        base_dir_ = base_dir;
        
        // 创建必要目录
        std::filesystem::create_directories(getTempDir());
        std::filesystem::create_directories(getRecordsDir());
        std::filesystem::create_directories(getMetadataDir());
        std::filesystem::create_directories(getLogsDir());
        
        return true;
    }
    
    std::string generateOutputPath() {
        auto now = std::chrono::system_clock::now();
        auto time_t = std::chrono::system_clock::to_time_t(now);
        
        std::stringstream ss;
        ss << std::put_time(std::localtime(&time_t), "%Y-%m-%d_%H-%M-%S");
        
        return getRecordsDir() + "/" + ss.str() + ".mp4";
    }
    
    std::string getTempDir() const { return base_dir_ + "/temp"; }
    std::string getRecordsDir() const { return base_dir_ + "/records"; }
    std::string getMetadataDir() const { return base_dir_ + "/records/metadata"; }
    std::string getLogsDir() const { return base_dir_ + "/logs"; }
    
private:
    std::string base_dir_;
};
```

### 4.6 元数据管理

#### 元数据结构

```cpp
struct VideoMetadata {
    std::string video_path;
    int64_t file_size_bytes;
    int64_t duration_ms;
    int width;
    int height;
    int fps;
    std::string codec;
    int64_t bitrate;
    std::chrono::system_clock::time_point recording_time;
    std::vector<std::string> chunk_paths;  // 原始分片路径
};
```

#### 元数据保存

```cpp
void MetadataManager::saveMetadata(const std::string& video_path, 
                                   const VideoMetadata& metadata) {
    // 生成 JSON
    nlohmann::json j;
    j["video_path"] = metadata.video_path;
    j["file_size_bytes"] = metadata.file_size_bytes;
    j["duration_ms"] = metadata.duration_ms;
    j["width"] = metadata.width;
    j["height"] = metadata.height;
    j["fps"] = metadata.fps;
    j["codec"] = metadata.codec;
    j["bitrate"] = metadata.bitrate;
    j["recording_time"] = std::chrono::system_clock::to_time_t(metadata.recording_time);
    j["chunk_paths"] = metadata.chunk_paths;
    
    // 写入文件
    std::string metadata_path = PathManager::instance().getMetadataDir() + "/" +
                                std::filesystem::path(video_path).stem().string() + ".json";
    
    std::ofstream ofs(metadata_path);
    ofs << j.dump(4);  // 格式化输出
}
```

---

## 五、模块协作机制

### 5.1 完整录制流程

```mermaid
sequenceDiagram
    participant UI as RecordingController
    participant Factory as GrabberFactory
    participant Grabber as IScreenGrabber
    participant GT as FrameGrabberThread
    participant Q as ThreadSafeQueue
    participant ET as FrameEncoder
    participant Writer as MediaWriter
    participant File as 文件系统
    
    UI->>Factory: createGrabber(AUTO)
    Factory-->>UI: unique_ptr<IScreenGrabber>
    
    UI->>UI: 创建队列和线程
    UI->>GT: moveToThread(grabberThread)
    UI->>ET: moveToThread(encoderThread)
    
    UI->>Writer: initialize(config)
    Writer->>File: 创建临时目录
    Writer->>File: 创建 chunk_0.mp4
    Writer-->>UI: true
    
    UI->>GT: start()
    UI->>ET: start()
    
    activate GT
    activate ET
    
    par 采集线程
        loop 每 16.67ms
            GT->>Grabber: captureFrame()
            Grabber-->>GT: FrameData
            GT->>Q: push(frame)
            GT->>GT: waitForNextFrame()
            GT-->>UI: frameCaptured(count, fps)
        end
    and 编码线程
        loop 持续运行
            ET->>Q: pop(frame)
            Q-->>ET: FrameData
            ET->>ET: convertPixelFormat()
            ET->>ET: encodeFrame()
            ET->>Writer: writePacket(packet)
            
            alt 需要分片
                Writer->>Writer: finalizeCurrentChunk()
                Writer->>File: 完成 chunk_N.mp4
                Writer->>Writer: createNewChunk()
                Writer->>File: 创建 chunk_N+1.mp4
            end
            
            Writer->>File: 写入数据包
            ET-->>UI: frameEncoded(count, size)
        end
    end
    
    UI->>GT: stop()
    UI->>ET: stop()
    
    deactivate GT
    deactivate ET
    
    ET->>Writer: finalize()
    Writer->>Writer: finalizeCurrentChunk()
    Writer->>Writer: mergeChunks()
    Writer->>File: ffmpeg -f concat
    Writer->>File: 生成最终文件
    Writer->>Writer: saveMetadata()
    Writer->>Writer: cleanupTempFiles()
    Writer-->>ET: output_path
    
    ET-->>UI: encodingFinished(path)
```

### 5.2 Qt 线程集成

```cpp
class RecordingController : public QObject {
    Q_OBJECT
    
public:
    RecordingController() {
        // 1. 创建采集器
        grabber_ = GrabberFactory::create(GrabberType::AUTO);
        
        // 2. 创建队列
        frame_queue_ = std::make_shared<ThreadSafeQueue<FrameData>>(30);
        
        // 3. 创建采集线程
        grabber_thread_ = std::make_unique<FrameGrabberThread>(
            grabber_, frame_queue_, 60
        );
        
        // 4. 创建编码线程
        EncoderConfig config;
        config.output_path = PathManager::instance().generateOutputPath();
        config.width = 1920;
        config.height = 1080;
        config.fps = 60;
        
        encoder_thread_ = std::make_unique<FrameEncoder>(frame_queue_, config);
        
        // 5. 移动到独立线程
        grabber_thread_->moveToThread(&grabber_qt_thread_);
        encoder_thread_->moveToThread(&encoder_qt_thread_);
        
        // 6. 连接信号
        connect(grabber_thread_.get(), &FrameGrabberThread::frameCaptured,
                this, &RecordingController::onFrameCaptured);
        connect(encoder_thread_.get(), &FrameEncoder::frameEncoded,
                this, &RecordingController::onFrameEncoded);
        
        // 7. 启动线程
        grabber_qt_thread_.start();
        encoder_qt_thread_.start();
    }
    
    ~RecordingController() {
        grabber_qt_thread_.quit();
        encoder_qt_thread_.quit();
        grabber_qt_thread_.wait();
        encoder_qt_thread_.wait();
    }
    
public slots:
    void startRecording() {
        QMetaObject::invokeMethod(grabber_thread_.get(), "start");
        QMetaObject::invokeMethod(encoder_thread_.get(), "start");
    }
    
    void stopRecording() {
        QMetaObject::invokeMethod(grabber_thread_.get(), "stop");
        QMetaObject::invokeMethod(encoder_thread_.get(), "stop");
    }
    
private:
    std::shared_ptr<IScreenGrabber> grabber_;
    std::shared_ptr<ThreadSafeQueue<FrameData>> frame_queue_;
    std::unique_ptr<FrameGrabberThread> grabber_thread_;
    std::unique_ptr<FrameEncoder> encoder_thread_;
    QThread grabber_qt_thread_;
    QThread encoder_qt_thread_;
};
```

---

## 六、性能优化策略

### 6.1 零拷贝优化

```mermaid
graph TB
    subgraph "传统方式 (多次拷贝)"
        A1[GPU 内存] -->|拷贝 1| B1[临时缓冲区]
        B1 -->|拷贝 2| C1[FrameData]
        C1 -->|拷贝 3| D1[编码器]
    end
    
    subgraph "零拷贝优化"
        A2[GPU 内存] -->|直接映射| B2[FrameData.data]
        B2 -->|shared_ptr 共享| C2[编码器]
    end
    
    style A2 fill:#90EE90
    style B2 fill:#90EE90
    style C2 fill:#90EE90
```

**实现要点**：
1. **DXGI**：使用 `ID3D11Texture2D::Map` 直接映射 GPU 纹理
2. **X11**：使用 `XShmGetImage` 共享内存扩展
3. **FrameData**：使用 `shared_ptr` 避免数据拷贝

### 6.2 硬件加速编码

```cpp
struct EncoderConfig {
    bool use_hardware = false;
    std::string hw_device = "";  // "cuda", "qsv", "vaapi"
};

bool FFmpegWrapper::configureEncoder(const EncoderConfig& config) {
    if (config.use_hardware) {
        // 查找硬件编码器
        const AVCodec* codec = nullptr;
        if (config.hw_device == "cuda") {
            codec = avcodec_find_encoder_by_name("h264_nvenc");
        } else if (config.hw_device == "qsv") {
            codec = avcodec_find_encoder_by_name("h264_qsv");
        } else if (config.hw_device == "vaapi") {
            codec = avcodec_find_encoder_by_name("h264_vaapi");
        }
        
        if (codec) {
            // 配置硬件加速
            // ...
        }
    }
}
```

### 6.3 内存池优化

```cpp
class FramePool {
public:
    FramePool(size_t frame_size, size_t pool_size) {
        for (size_t i = 0; i < pool_size; ++i) {
            auto buffer = std::make_shared<uint8_t[]>(frame_size);
            free_buffers_.push(buffer);
        }
    }
    
    std::shared_ptr<uint8_t> acquire() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (free_buffers_.empty()) {
            // 池已空，分配新缓冲区
            return std::make_shared<uint8_t[]>(frame_size_);
        }
        
        auto buffer = free_buffers_.front();
        free_buffers_.pop();
        return buffer;
    }
    
    void release(std::shared_ptr<uint8_t> buffer) {
        std::lock_guard<std::mutex> lock(mutex_);
        free_buffers_.push(buffer);
    }
    
private:
    size_t frame_size_;
    std::queue<std::shared_ptr<uint8_t>> free_buffers_;
    std::mutex mutex_;
};
```

### 6.4 性能指标

| 指标 | 目标值 | 优化手段 |
|------|--------|---------|
| **帧率稳定性** | 60fps ± 1fps | 精确帧率控制 |
| **CPU 占用** | < 15% | 硬件加速 + 零拷贝 |
| **内存占用** | < 500MB | 内存池 + 队列限制 |
| **延迟** | < 500ms | 队列大小控制 |
| **丢帧率** | < 0.1% | 队列缓冲 + 性能监控 |

---

## 七、错误处理与容错

### 7.1 错误分类

```mermaid
graph TB
    A[错误类型] --> B[可恢复错误]
    A --> C[不可恢复错误]
    
    B --> B1[单帧捕获失败]
    B --> B2[队列超时]
    B --> B3[临时磁盘空间不足]
    
    C --> C1[采集器初始化失败]
    C --> C2[编码器初始化失败]
    C --> C3[文件写入失败]
    
    B1 --> D1[跳过该帧，继续]
    B2 --> D2[丢帧警告]
    B3 --> D3[自动清理临时文件]
    
    C1 --> E1[停止录制，通知用户]
    C2 --> E2[停止录制，保存已有数据]
    C3 --> E3[停止录制，保留分片]
    
    style B fill:#90EE90
    style C fill:#FFB6C1
```

### 7.2 异常处理策略

```cpp
class FrameGrabberThread : public QObject {
private:
    void captureLoop() {
        try {
            while (running_) {
                try {
                    FrameData frame = grabber_->captureFrame(100);
                    
                    if (!frame.data) {
                        // 可恢复错误：单帧捕获失败
                        continue;
                    }
                    
                    if (!queue_->push(std::move(frame), std::chrono::milliseconds(100))) {
                        // 可恢复错误：队列已满
                        dropped_count_++;
                        emit framesDropped(dropped_count_);
                    }
                    
                } catch (const std::exception& e) {
                    // 可恢复错误：记录日志，继续
                    qWarning() << "Frame capture error:" << e.what();
                }
            }
            
        } catch (const std::exception& e) {
            // 不可恢复错误：停止采集
            emit errorOccurred(QString::fromStdString(e.what()));
            running_ = false;
        }
    }
};
```

### 7.3 磁盘空间监控

```cpp
bool MediaWriter::checkDiskSpace() {
    auto space_info = std::filesystem::space(config_.output_path);
    int64_t free_mb = space_info.available / (1024 * 1024);
    
    if (free_mb < config_.min_free_space_mb) {
        if (config_.auto_stop_on_low_space) {
            last_error_ = "磁盘空间不足，自动停止录制";
            return false;
        } else {
            // 发出警告但继续
            qWarning() << "Low disk space:" << free_mb << "MB";
        }
    }
    
    return true;
}
```

### 7.4 崩溃恢复

```cpp
class CrashRecovery {
public:
    static void saveRecoveryInfo(const std::string& video_path,
                                 const std::vector<std::string>& chunk_paths) {
        nlohmann::json j;
        j["video_path"] = video_path;
        j["chunk_paths"] = chunk_paths;
        j["timestamp"] = std::time(nullptr);
        
        std::ofstream ofs(PathManager::instance().getTempDir() + "/recovery.json");
        ofs << j.dump();
    }
    
    static bool hasRecoveryInfo() {
        return std::filesystem::exists(
            PathManager::instance().getTempDir() + "/recovery.json"
        );
    }
    
    static void recoverFromCrash() {
        std::ifstream ifs(PathManager::instance().getTempDir() + "/recovery.json");
        nlohmann::json j;
        ifs >> j;
        
        std::vector<std::string> chunk_paths = j["chunk_paths"];
        std::string video_path = j["video_path"];
        
        // 尝试合并分片
        MediaWriter writer;
        WriterConfig config;
        config.output_path = video_path;
        writer.initialize(config);
        // ... 合并逻辑
    }
};
```

---

## 总结

本文档详细阐述了屏幕录制引擎的三大核心模块：

1. **采集器架构**：通过接口抽象和 RAII 封装，实现跨平台屏幕捕获和资源安全管理
2. **视频流处理**：采用生产者-消费者模式，通过线程安全队列实现高效的异步采集和编码
3. **写入控制**：支持视频分片、磁盘监控和元数据管理，确保长时间录制的可靠性

这三个模块通过精心设计的接口和协作机制，构成了一个高性能、高可靠性的屏幕录制引擎，为后续的 AI 视频分析提供了坚实的基础。

> [!NOTE]
> **下一步工作**  
> 在完成屏幕录制引擎后，第四章将实现录制控制器与状态机，连接 UI 与 C++ 引擎，管理"空闲-倒计时-录制-处理"的状态流转。
