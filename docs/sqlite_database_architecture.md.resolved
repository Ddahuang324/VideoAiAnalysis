# å…³é”®å¸§å½•åˆ¶ç³»ç»Ÿ SQLite æ•°æ®åº“æ¶æ„è®¾è®¡æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†å…³é”®å¸§å½•åˆ¶ç³»ç»Ÿçš„ SQLite æ•°æ®åº“æ¶æ„è®¾è®¡,ç”¨äºå­˜å‚¨å½•åˆ¶è§†é¢‘ã€å…³é”®å¸§åˆ†æã€AI è¾“å‡ºç»“æœç­‰æ ¸å¿ƒæ•°æ®ã€‚

---

## ğŸ¯ è®¾è®¡ç›®æ ‡

### æ ¸å¿ƒéœ€æ±‚
1. **å…³é”®å¸§è§†é¢‘ç®¡ç†**: å­˜å‚¨å…³é”®å¸§è§†é¢‘çš„å…ƒæ•°æ®ã€è·¯å¾„ã€æ—¶é•¿ç­‰ä¿¡æ¯
2. **AI åˆ†æç»“æœ**: å­˜å‚¨ AI å¯¹è§†é¢‘/éŸ³é¢‘çš„åˆ†æè¾“å‡º(æ”¯æŒ Markdown æ ¼å¼)
3. **æ—¶é—´æˆ³æ ‡è®°**: è®°å½•å…³é”®æ—¶åˆ»åŠå…¶å¯¹åº”çš„äº‹ä»¶æè¿°
4. **å…³é”®è¦ç‚¹æå–**: å­˜å‚¨ AI å½’çº³çš„è§†é¢‘é‡ç‚¹(Keys)
5. **åŸè§†é¢‘å…³è”**: ç»´æŠ¤å…³é”®å¸§è§†é¢‘ä¸åŸå§‹å½•åˆ¶è§†é¢‘çš„å…³è”å…³ç³»
6. **å¯æ‰©å±•æ€§**: ä¸ºæœªæ¥çš„ AI åŠŸèƒ½é¢„ç•™æ‰©å±•ç©ºé—´

---

## ğŸ—‚ï¸ æ•°æ®åº“æ¶æ„è®¾è®¡

### æ¶æ„å›¾

```mermaid
erDiagram
    RECORDING ||--o{ KEYFRAME_VIDEO : "generates"
    KEYFRAME_VIDEO ||--o{ AI_ANALYSIS : "analyzed_by"
    PROMPT_TEMPLATE ||--o{ AI_ANALYSIS : "guides"
    AI_ANALYSIS ||--o{ TIMESTAMP_EVENT : "contains"
    AI_ANALYSIS ||--o{ KEY_FINDING : "extracts"
    AI_ANALYSIS ||--o{ ANALYSIS_METADATA : "has"
    
    RECORDING {
        TEXT record_id PK "UUID"
        TEXT original_video_path "åŸè§†é¢‘è·¯å¾„"
        TEXT title "è§†é¢‘æ ‡é¢˜"
        TEXT description "è§†é¢‘æè¿°"
        INTEGER duration_seconds "æ—¶é•¿(ç§’)"
        INTEGER file_size_bytes "æ–‡ä»¶å¤§å°"
        TEXT thumbnail_path "ç¼©ç•¥å›¾è·¯å¾„"
        TEXT created_at "åˆ›å»ºæ—¶é—´"
        TEXT updated_at "æ›´æ–°æ—¶é—´"
        TEXT tags "æ ‡ç­¾(JSONæ•°ç»„)"
        TEXT metadata "æ‰©å±•å…ƒæ•°æ®(JSON)"
    }
    
    KEYFRAME_VIDEO {
        TEXT keyframe_id PK "UUID"
        TEXT recording_id FK "å…³è”å½•åˆ¶ID"
        TEXT keyframe_video_path "å…³é”®å¸§è§†é¢‘è·¯å¾„"
        TEXT keyframe_audio_path "å…³é”®å¸§éŸ³é¢‘è·¯å¾„"
        INTEGER keyframe_count "å…³é”®å¸§æ•°é‡"
        INTEGER duration_seconds "æ—¶é•¿(ç§’)"
        INTEGER file_size_bytes "æ–‡ä»¶å¤§å°"
        REAL compression_ratio "å‹ç¼©ç‡"
        TEXT created_at "åˆ›å»ºæ—¶é—´"
        TEXT extraction_config "æå–é…ç½®(JSON)"
    }
    
    PROMPT_TEMPLATE {
        TEXT prompt_id PK "UUID"
        TEXT name "æç¤ºè¯åç§°"
        TEXT description "æç¤ºè¯æè¿°"
        TEXT prompt_content "æç¤ºè¯å†…å®¹"
        TEXT category "åˆ†ç±»"
        INTEGER is_default "æ˜¯å¦é»˜è®¤"
        TEXT created_at "åˆ›å»ºæ—¶é—´"
        TEXT updated_at "æ›´æ–°æ—¶é—´"
        TEXT tags "æ ‡ç­¾(JSONæ•°ç»„)"
        TEXT variables "å˜é‡å®šä¹‰(JSON)"
    }
    
    AI_ANALYSIS {
        TEXT analysis_id PK "UUID"
        TEXT keyframe_id FK "å…³è”å…³é”®å¸§è§†é¢‘ID"
        TEXT prompt_id FK "ä½¿ç”¨çš„æç¤ºè¯ID"
        TEXT analysis_type "åˆ†æç±»å‹"
        TEXT model_name "AIæ¨¡å‹åç§°"
        TEXT model_version "æ¨¡å‹ç‰ˆæœ¬"
        TEXT status "åˆ†æçŠ¶æ€"
        TEXT video_analysis_md "è§†é¢‘åˆ†æ(Markdown)"
        TEXT audio_analysis_md "éŸ³é¢‘åˆ†æ(Markdown)"
        TEXT summary_md "ç»¼åˆæ‘˜è¦(Markdown)"
        TEXT started_at "å¼€å§‹æ—¶é—´"
        TEXT completed_at "å®Œæˆæ—¶é—´"
        INTEGER processing_time_ms "å¤„ç†è€—æ—¶(æ¯«ç§’)"
        TEXT error_message "é”™è¯¯ä¿¡æ¯"
    }
    
    TIMESTAMP_EVENT {
        TEXT event_id PK "UUID"
        TEXT analysis_id FK "å…³è”åˆ†æID"
        REAL timestamp_seconds "æ—¶é—´æˆ³(ç§’)"
        TEXT event_type "äº‹ä»¶ç±»å‹"
        TEXT title "äº‹ä»¶æ ‡é¢˜"
        TEXT description "äº‹ä»¶æè¿°"
        TEXT thumbnail_path "äº‹ä»¶ç¼©ç•¥å›¾"
        INTEGER importance_score "é‡è¦æ€§è¯„åˆ†(1-10)"
        TEXT metadata "æ‰©å±•æ•°æ®(JSON)"
    }
    
    KEY_FINDING {
        TEXT finding_id PK "UUID"
        TEXT analysis_id FK "å…³è”åˆ†æID"
        INTEGER sequence_order "æ’åºåºå·"
        TEXT category "åˆ†ç±»"
        TEXT title "è¦ç‚¹æ ‡é¢˜"
        TEXT content "è¦ç‚¹å†…å®¹"
        TEXT related_timestamps "ç›¸å…³æ—¶é—´æˆ³(JSONæ•°ç»„)"
        INTEGER confidence_score "ç½®ä¿¡åº¦(0-100)"
    }
    
    ANALYSIS_METADATA {
        TEXT metadata_id PK "UUID"
        TEXT analysis_id FK "å…³è”åˆ†æID"
        TEXT key "å…ƒæ•°æ®é”®"
        TEXT value "å…ƒæ•°æ®å€¼"
        TEXT data_type "æ•°æ®ç±»å‹"
    }
```

---

## ğŸ“Š æ•°æ®è¡¨è¯¦ç»†è®¾è®¡

### 1. RECORDING - åŸå§‹å½•åˆ¶è®°å½•è¡¨

å­˜å‚¨åŸå§‹å½•åˆ¶è§†é¢‘çš„åŸºæœ¬ä¿¡æ¯ã€‚

```sql
CREATE TABLE IF NOT EXISTS recording (
    record_id TEXT PRIMARY KEY,                 -- UUID
    original_video_path TEXT NOT NULL UNIQUE,   -- åŸè§†é¢‘æ–‡ä»¶è·¯å¾„
    title TEXT DEFAULT '',                      -- è§†é¢‘æ ‡é¢˜
    description TEXT DEFAULT '',                -- è§†é¢‘æè¿°
    duration_seconds INTEGER DEFAULT 0,         -- è§†é¢‘æ—¶é•¿(ç§’)
    file_size_bytes INTEGER DEFAULT 0,          -- æ–‡ä»¶å¤§å°(å­—èŠ‚)
    thumbnail_path TEXT DEFAULT '',             -- ç¼©ç•¥å›¾è·¯å¾„
    created_at TEXT NOT NULL,                   -- åˆ›å»ºæ—¶é—´ ISO8601
    updated_at TEXT NOT NULL,                   -- æ›´æ–°æ—¶é—´ ISO8601
    tags TEXT DEFAULT '[]',                     -- æ ‡ç­¾ JSONæ•°ç»„ ["tag1", "tag2"]
    metadata TEXT DEFAULT '{}'                  -- æ‰©å±•å…ƒæ•°æ® JSONå¯¹è±¡
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_recording_created_at ON recording(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_recording_title ON recording(title);
```

**å­—æ®µè¯´æ˜**:
- `record_id`: ä¸»é”®,ä½¿ç”¨ UUID ä¿è¯å…¨å±€å”¯ä¸€æ€§
- `original_video_path`: åŸå§‹å½•åˆ¶è§†é¢‘çš„å®Œæ•´è·¯å¾„,è®¾ç½® UNIQUE çº¦æŸé˜²æ­¢é‡å¤
- `tags`: JSON æ•°ç»„æ ¼å¼,æ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»
- `metadata`: JSON å¯¹è±¡,é¢„ç•™æ‰©å±•å­—æ®µ

---

### 2. KEYFRAME_VIDEO - å…³é”®å¸§è§†é¢‘è¡¨

å­˜å‚¨ä»åŸå§‹è§†é¢‘æå–çš„å…³é”®å¸§è§†é¢‘ä¿¡æ¯ã€‚

```sql
CREATE TABLE IF NOT EXISTS keyframe_video (
    keyframe_id TEXT PRIMARY KEY,               -- UUID
    recording_id TEXT NOT NULL,                 -- å…³è”çš„åŸå§‹å½•åˆ¶ID
    keyframe_video_path TEXT NOT NULL UNIQUE,   -- å…³é”®å¸§è§†é¢‘è·¯å¾„
    keyframe_audio_path TEXT DEFAULT '',        -- å…³é”®å¸§éŸ³é¢‘è·¯å¾„(å¯é€‰)
    keyframe_count INTEGER DEFAULT 0,           -- å…³é”®å¸§æ•°é‡
    duration_seconds INTEGER DEFAULT 0,         -- å…³é”®å¸§è§†é¢‘æ—¶é•¿(ç§’)
    file_size_bytes INTEGER DEFAULT 0,          -- æ–‡ä»¶å¤§å°(å­—èŠ‚)
    compression_ratio REAL DEFAULT 0.0,         -- å‹ç¼©ç‡ (å…³é”®å¸§æ—¶é•¿/åŸè§†é¢‘æ—¶é•¿)
    created_at TEXT NOT NULL,                   -- åˆ›å»ºæ—¶é—´ ISO8601
    extraction_config TEXT DEFAULT '{}',        -- æå–é…ç½® JSONå¯¹è±¡
    
    FOREIGN KEY (recording_id) REFERENCES recording(record_id) ON DELETE CASCADE
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_keyframe_recording_id ON keyframe_video(recording_id);
CREATE INDEX IF NOT EXISTS idx_keyframe_created_at ON keyframe_video(created_at DESC);
```

**å­—æ®µè¯´æ˜**:
- `recording_id`: å¤–é”®,å…³è”åŸå§‹å½•åˆ¶è®°å½•,æ”¯æŒçº§è”åˆ é™¤
- `compression_ratio`: å‹ç¼©ç‡,ç”¨äºè¯„ä¼°å…³é”®å¸§æå–æ•ˆæœ
- `extraction_config`: JSON æ ¼å¼,å­˜å‚¨æå–æ—¶çš„é…ç½®å‚æ•°(å¦‚é˜ˆå€¼ã€ç®—æ³•ç­‰)

---

### 3. PROMPT_TEMPLATE - æç¤ºè¯æ¨¡æ¿è¡¨

å­˜å‚¨ç”¨æˆ·è‡ªå®šä¹‰çš„ AI åˆ†ææç¤ºè¯æ¨¡æ¿ã€‚

```sql
CREATE TABLE IF NOT EXISTS prompt_template (
    prompt_id TEXT PRIMARY KEY,                 -- UUID
    name TEXT NOT NULL,                         -- æç¤ºè¯åç§°
    description TEXT DEFAULT '',                -- æç¤ºè¯æè¿°
    prompt_content TEXT NOT NULL,               -- æç¤ºè¯å†…å®¹(æ”¯æŒå˜é‡å ä½ç¬¦)
    category TEXT DEFAULT 'general',            -- åˆ†ç±»: general/meeting/tutorial/gaming
    is_default INTEGER DEFAULT 0,               -- æ˜¯å¦é»˜è®¤æ¨¡æ¿ (0/1)
    created_at TEXT NOT NULL,                   -- åˆ›å»ºæ—¶é—´ ISO8601
    updated_at TEXT NOT NULL,                   -- æ›´æ–°æ—¶é—´ ISO8601
    tags TEXT DEFAULT '[]',                     -- æ ‡ç­¾ JSONæ•°ç»„
    variables TEXT DEFAULT '[]',                -- å˜é‡å®šä¹‰ JSONæ•°ç»„ [{"name": "focus", "default": "æŠ€æœ¯ç»†èŠ‚"}]
    
    CHECK (is_default IN (0, 1))
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_prompt_category ON prompt_template(category);
CREATE INDEX IF NOT EXISTS idx_prompt_is_default ON prompt_template(is_default);
CREATE INDEX IF NOT EXISTS idx_prompt_created_at ON prompt_template(created_at DESC);
```

**å­—æ®µè¯´æ˜**:
- `prompt_id`: ä¸»é”®,ä½¿ç”¨ UUID
- `name`: æç¤ºè¯æ¨¡æ¿åç§°,å¦‚ "ä¼šè®®åˆ†ææ¨¡æ¿"ã€"æ•™ç¨‹è§†é¢‘åˆ†æ"
- `prompt_content`: æç¤ºè¯å†…å®¹,æ”¯æŒå˜é‡å ä½ç¬¦(å¦‚ `{focus}`, `{detail_level}`)
- `category`: åˆ†ç±»,æ–¹ä¾¿æŒ‰åœºæ™¯ç­›é€‰(ä¼šè®®ã€æ•™ç¨‹ã€æ¸¸æˆã€é€šç”¨ç­‰)
- `is_default`: æ˜¯å¦ä¸ºé»˜è®¤æ¨¡æ¿,æ¯ä¸ªåˆ†ç±»å¯ä»¥æœ‰ä¸€ä¸ªé»˜è®¤æ¨¡æ¿
- `variables`: JSON æ•°ç»„,å®šä¹‰æç¤ºè¯ä¸­çš„å˜é‡åŠå…¶é»˜è®¤å€¼

**æç¤ºè¯å˜é‡ç¤ºä¾‹**:
```json
[
  {"name": "focus", "default": "æŠ€æœ¯ç»†èŠ‚", "description": "åˆ†æé‡ç‚¹"},
  {"name": "detail_level", "default": "è¯¦ç»†", "description": "è¯¦ç»†ç¨‹åº¦"},
  {"name": "language", "default": "ä¸­æ–‡", "description": "è¾“å‡ºè¯­è¨€"}
]
```

**æç¤ºè¯å†…å®¹ç¤ºä¾‹**:
```
è¯·åˆ†æè¿™æ®µè§†é¢‘,é‡ç‚¹å…³æ³¨ {focus}ã€‚
åˆ†æè¯¦ç»†ç¨‹åº¦: {detail_level}
è¾“å‡ºè¯­è¨€: {language}

è¯·æä¾›ä»¥ä¸‹å†…å®¹:
1. è§†é¢‘ä¸»è¦å†…å®¹æ¦‚è¿°
2. å…³é”®æ—¶åˆ»åŠæ—¶é—´æˆ³
3. æ ¸å¿ƒè¦ç‚¹æ€»ç»“
```

---

### 4. AI_ANALYSIS - AI åˆ†æç»“æœè¡¨

å­˜å‚¨ AI å¯¹å…³é”®å¸§è§†é¢‘çš„åˆ†æç»“æœã€‚

```sql
CREATE TABLE IF NOT EXISTS ai_analysis (
    analysis_id TEXT PRIMARY KEY,               -- UUID
    keyframe_id TEXT NOT NULL,                  -- å…³è”çš„å…³é”®å¸§è§†é¢‘ID
    prompt_id TEXT,                             -- ä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿ID (å¯é€‰)
    analysis_type TEXT DEFAULT 'general',       -- åˆ†æç±»å‹: general/detailed/custom
    model_name TEXT NOT NULL,                   -- AIæ¨¡å‹åç§° (å¦‚ "gemini-1.5-flash")
    model_version TEXT DEFAULT '',              -- æ¨¡å‹ç‰ˆæœ¬
    status TEXT DEFAULT 'pending',              -- çŠ¶æ€: pending/processing/completed/failed
    video_analysis_md TEXT DEFAULT '',          -- è§†é¢‘å†…å®¹åˆ†æ (Markdownæ ¼å¼)
    audio_analysis_md TEXT DEFAULT '',          -- éŸ³é¢‘/è¯­éŸ³åˆ†æ (Markdownæ ¼å¼)
    summary_md TEXT DEFAULT '',                 -- ç»¼åˆæ‘˜è¦ (Markdownæ ¼å¼)
    started_at TEXT,                            -- åˆ†æå¼€å§‹æ—¶é—´ ISO8601
    completed_at TEXT,                          -- åˆ†æå®Œæˆæ—¶é—´ ISO8601
    processing_time_ms INTEGER DEFAULT 0,       -- å¤„ç†è€—æ—¶(æ¯«ç§’)
    error_message TEXT DEFAULT '',              -- é”™è¯¯ä¿¡æ¯(å¦‚æœå¤±è´¥)
    
    FOREIGN KEY (keyframe_id) REFERENCES keyframe_video(keyframe_id) ON DELETE CASCADE,
    FOREIGN KEY (prompt_id) REFERENCES prompt_template(prompt_id) ON DELETE SET NULL
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_analysis_keyframe_id ON ai_analysis(keyframe_id);
CREATE INDEX IF NOT EXISTS idx_analysis_prompt_id ON ai_analysis(prompt_id);
CREATE INDEX IF NOT EXISTS idx_analysis_status ON ai_analysis(status);
CREATE INDEX IF NOT EXISTS idx_analysis_completed_at ON ai_analysis(completed_at DESC);
CREATE INDEX IF NOT EXISTS idx_analysis_type ON ai_analysis(analysis_type);
```

**å­—æ®µè¯´æ˜**:
- `prompt_id`: å¤–é”®,å…³è”ä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿(å¯é€‰,å…è®¸ NULL)
- åˆ é™¤æç¤ºè¯æ¨¡æ¿æ—¶,åˆ†æè®°å½•çš„ `prompt_id` ä¼šè¢«è®¾ç½®ä¸º NULL(ä¸å½±å“å·²æœ‰åˆ†æ)
- å…¶ä»–å­—æ®µè¯´æ˜åŒä¹‹å‰

---

### 5. TIMESTAMP_EVENT - æ—¶é—´æˆ³äº‹ä»¶è¡¨

å­˜å‚¨è§†é¢‘ä¸­çš„å…³é”®æ—¶åˆ»åŠå…¶æè¿°ã€‚

```sql
CREATE TABLE IF NOT EXISTS ai_analysis (
    analysis_id TEXT PRIMARY KEY,               -- UUID
    keyframe_id TEXT NOT NULL,                  -- å…³è”çš„å…³é”®å¸§è§†é¢‘ID
    analysis_type TEXT DEFAULT 'general',       -- åˆ†æç±»å‹: general/detailed/custom
    model_name TEXT NOT NULL,                   -- AIæ¨¡å‹åç§° (å¦‚ "gemini-1.5-flash")
    model_version TEXT DEFAULT '',              -- æ¨¡å‹ç‰ˆæœ¬
    status TEXT DEFAULT 'pending',              -- çŠ¶æ€: pending/processing/completed/failed
    video_analysis_md TEXT DEFAULT '',          -- è§†é¢‘å†…å®¹åˆ†æ (Markdownæ ¼å¼)
    audio_analysis_md TEXT DEFAULT '',          -- éŸ³é¢‘/è¯­éŸ³åˆ†æ (Markdownæ ¼å¼)
    summary_md TEXT DEFAULT '',                 -- ç»¼åˆæ‘˜è¦ (Markdownæ ¼å¼)
    started_at TEXT,                            -- åˆ†æå¼€å§‹æ—¶é—´ ISO8601
    completed_at TEXT,                          -- åˆ†æå®Œæˆæ—¶é—´ ISO8601
    processing_time_ms INTEGER DEFAULT 0,       -- å¤„ç†è€—æ—¶(æ¯«ç§’)
    error_message TEXT DEFAULT '',              -- é”™è¯¯ä¿¡æ¯(å¦‚æœå¤±è´¥)
    
    FOREIGN KEY (keyframe_id) REFERENCES keyframe_video(keyframe_id) ON DELETE CASCADE
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_analysis_keyframe_id ON ai_analysis(keyframe_id);
CREATE INDEX IF NOT EXISTS idx_analysis_status ON ai_analysis(status);
CREATE INDEX IF NOT EXISTS idx_analysis_completed_at ON ai_analysis(completed_at DESC);
CREATE INDEX IF NOT EXISTS idx_analysis_type ON ai_analysis(analysis_type);
```

**å­—æ®µè¯´æ˜**:
- `analysis_type`: æ”¯æŒä¸åŒç±»å‹çš„åˆ†æ(é€šç”¨ã€è¯¦ç»†ã€è‡ªå®šä¹‰ç­‰)
- `video_analysis_md`/`audio_analysis_md`: ä½¿ç”¨ Markdown æ ¼å¼å­˜å‚¨ AI è¾“å‡º,ä¾¿äºæ¸²æŸ“
- `status`: çŠ¶æ€æœºç®¡ç†åˆ†ææµç¨‹
- `processing_time_ms`: æ€§èƒ½ç›‘æ§æŒ‡æ ‡

---

### 4. TIMESTAMP_EVENT - æ—¶é—´æˆ³äº‹ä»¶è¡¨

å­˜å‚¨è§†é¢‘ä¸­çš„å…³é”®æ—¶åˆ»åŠå…¶æè¿°ã€‚

```sql
CREATE TABLE IF NOT EXISTS timestamp_event (
    event_id TEXT PRIMARY KEY,                  -- UUID
    analysis_id TEXT NOT NULL,                  -- å…³è”çš„åˆ†æID
    timestamp_seconds REAL NOT NULL,            -- æ—¶é—´æˆ³(ç§’,æ”¯æŒå°æ•°)
    event_type TEXT DEFAULT 'highlight',        -- äº‹ä»¶ç±»å‹: highlight/scene_change/action/speech
    title TEXT NOT NULL,                        -- äº‹ä»¶æ ‡é¢˜
    description TEXT DEFAULT '',                -- äº‹ä»¶è¯¦ç»†æè¿°
    thumbnail_path TEXT DEFAULT '',             -- äº‹ä»¶ç¼©ç•¥å›¾è·¯å¾„
    importance_score INTEGER DEFAULT 5,         -- é‡è¦æ€§è¯„åˆ† 1-10
    metadata TEXT DEFAULT '{}',                 -- æ‰©å±•å…ƒæ•°æ® JSON
    
    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
    CHECK (timestamp_seconds >= 0),
    CHECK (importance_score BETWEEN 1 AND 10)
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_event_analysis_id ON timestamp_event(analysis_id);
CREATE INDEX IF NOT EXISTS idx_event_timestamp ON timestamp_event(timestamp_seconds);
CREATE INDEX IF NOT EXISTS idx_event_importance ON timestamp_event(importance_score DESC);
CREATE INDEX IF NOT EXISTS idx_event_type ON timestamp_event(event_type);
```

**å­—æ®µè¯´æ˜**:
- `timestamp_seconds`: ä½¿ç”¨ REAL ç±»å‹æ”¯æŒç²¾ç¡®åˆ°æ¯«ç§’çš„æ—¶é—´æˆ³
- `event_type`: äº‹ä»¶åˆ†ç±»,æ”¯æŒé«˜å…‰æ—¶åˆ»ã€åœºæ™¯åˆ‡æ¢ã€åŠ¨ä½œã€è¯­éŸ³ç­‰
- `importance_score`: AI è¯„ä¼°çš„é‡è¦æ€§,ç”¨äºæ’åºå’Œç­›é€‰
- æ·»åŠ  CHECK çº¦æŸä¿è¯æ•°æ®æœ‰æ•ˆæ€§

---

### 6. KEY_FINDING - å…³é”®è¦ç‚¹è¡¨

å­˜å‚¨ AI å½’çº³çš„è§†é¢‘é‡ç‚¹å†…å®¹ã€‚

```sql
CREATE TABLE IF NOT EXISTS key_finding (
    finding_id TEXT PRIMARY KEY,                -- UUID
    analysis_id TEXT NOT NULL,                  -- å…³è”çš„åˆ†æID
    sequence_order INTEGER NOT NULL,            -- æ’åºåºå·
    category TEXT DEFAULT 'general',            -- åˆ†ç±»: general/technical/summary/insight
    title TEXT NOT NULL,                        -- è¦ç‚¹æ ‡é¢˜
    content TEXT NOT NULL,                      -- è¦ç‚¹å†…å®¹(æ”¯æŒMarkdown)
    related_timestamps TEXT DEFAULT '[]',       -- ç›¸å…³æ—¶é—´æˆ³ JSONæ•°ç»„ [12.5, 45.2, 78.9]
    confidence_score INTEGER DEFAULT 80,        -- AIç½®ä¿¡åº¦ 0-100
    
    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
    CHECK (confidence_score BETWEEN 0 AND 100)
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_finding_analysis_id ON key_finding(analysis_id);
CREATE INDEX IF NOT EXISTS idx_finding_sequence ON key_finding(analysis_id, sequence_order);
CREATE INDEX IF NOT EXISTS idx_finding_category ON key_finding(category);
```

**å­—æ®µè¯´æ˜**:
- `sequence_order`: ä¿è¯è¦ç‚¹çš„æ˜¾ç¤ºé¡ºåº
- `category`: è¦ç‚¹åˆ†ç±»,æ”¯æŒæŠ€æœ¯è¦ç‚¹ã€æ€»ç»“ã€æ´å¯Ÿç­‰
- `related_timestamps`: JSON æ•°ç»„,å…³è”ç›¸å…³çš„æ—¶é—´æˆ³
- `confidence_score`: AI çš„ç½®ä¿¡åº¦è¯„åˆ†

---

### 7. ANALYSIS_METADATA - åˆ†æå…ƒæ•°æ®è¡¨

å­˜å‚¨åˆ†æè¿‡ç¨‹ä¸­çš„é¢å¤–å…ƒæ•°æ®(é”®å€¼å¯¹å½¢å¼)ã€‚

```sql
CREATE TABLE IF NOT EXISTS analysis_metadata (
    metadata_id TEXT PRIMARY KEY,               -- UUID
    analysis_id TEXT NOT NULL,                  -- å…³è”çš„åˆ†æID
    key TEXT NOT NULL,                          -- å…ƒæ•°æ®é”®
    value TEXT NOT NULL,                        -- å…ƒæ•°æ®å€¼
    data_type TEXT DEFAULT 'string',            -- æ•°æ®ç±»å‹: string/number/boolean/json
    
    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
    UNIQUE(analysis_id, key)                    -- åŒä¸€åˆ†æä¸‹é”®å”¯ä¸€
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_metadata_analysis_id ON analysis_metadata(analysis_id);
CREATE INDEX IF NOT EXISTS idx_metadata_key ON analysis_metadata(key);
```

**å­—æ®µè¯´æ˜**:
- çµæ´»çš„é”®å€¼å¯¹å­˜å‚¨,æ”¯æŒæœªæ¥æ‰©å±•
- `data_type`: æ ‡è®°å€¼çš„æ•°æ®ç±»å‹,ä¾¿äºååºåˆ—åŒ–
- UNIQUE çº¦æŸé˜²æ­¢é‡å¤é”®

---

## ğŸ”§ Python å®ç°ä»£ç 

### æ•°æ®åº“ç®¡ç†å™¨ (DatabaseManager)

```python
"""
SQLite æ•°æ®åº“ç®¡ç†å™¨
æä¾›æ•°æ®åº“è¿æ¥ã€åˆå§‹åŒ–ã€äº‹åŠ¡ç®¡ç†ç­‰åŸºç¡€åŠŸèƒ½
"""
import sqlite3
import threading
from pathlib import Path
from typing import Optional, Any, List, Dict
from contextlib import contextmanager
from infrastructure.log_manager import get_logger


class DatabaseManager:
    """SQLite æ•°æ®åº“ç®¡ç†å™¨"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls, *args, **kwargs):
        """å•ä¾‹æ¨¡å¼"""
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, db_path: str = "data/keyframe_analysis.db"):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        if hasattr(self, '_initialized'):
            return
            
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.logger = get_logger("DatabaseManager")
        self._local = threading.local()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._initialize_database()
        self._initialized = True
        
        self.logger.info(f"Database initialized at: {self.db_path}")
    
    def _get_connection(self) -> sqlite3.Connection:
        """è·å–çº¿ç¨‹æœ¬åœ°çš„æ•°æ®åº“è¿æ¥"""
        if not hasattr(self._local, 'connection'):
            self._local.connection = sqlite3.connect(
                str(self.db_path),
                check_same_thread=False,
                timeout=30.0
            )
            # å¯ç”¨å¤–é”®çº¦æŸ
            self._local.connection.execute("PRAGMA foreign_keys = ON")
            # è¿”å›å­—å…¸æ ¼å¼çš„è¡Œ
            self._local.connection.row_factory = sqlite3.Row
            
        return self._local.connection
    
    @contextmanager
    def get_cursor(self):
        """è·å–æ•°æ®åº“æ¸¸æ ‡çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = self._get_connection()
        cursor = conn.cursor()
        try:
            yield cursor
            conn.commit()
        except Exception as e:
            conn.rollback()
            self.logger.error(f"Database error: {e}")
            raise
        finally:
            cursor.close()
    
    @contextmanager
    def transaction(self):
        """äº‹åŠ¡ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = self._get_connection()
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            self.logger.error(f"Transaction error: {e}")
            raise
    
    def _initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with self.get_cursor() as cursor:
            # 1. åˆ›å»º RECORDING è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS recording (
                    record_id TEXT PRIMARY KEY,
                    original_video_path TEXT NOT NULL UNIQUE,
                    title TEXT DEFAULT '',
                    description TEXT DEFAULT '',
                    duration_seconds INTEGER DEFAULT 0,
                    file_size_bytes INTEGER DEFAULT 0,
                    thumbnail_path TEXT DEFAULT '',
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    tags TEXT DEFAULT '[]',
                    metadata TEXT DEFAULT '{}'
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_recording_created_at 
                ON recording(created_at DESC)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_recording_title 
                ON recording(title)
            """)
            
            # 2. åˆ›å»º KEYFRAME_VIDEO è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS keyframe_video (
                    keyframe_id TEXT PRIMARY KEY,
                    recording_id TEXT NOT NULL,
                    keyframe_video_path TEXT NOT NULL UNIQUE,
                    keyframe_audio_path TEXT DEFAULT '',
                    keyframe_count INTEGER DEFAULT 0,
                    duration_seconds INTEGER DEFAULT 0,
                    file_size_bytes INTEGER DEFAULT 0,
                    compression_ratio REAL DEFAULT 0.0,
                    created_at TEXT NOT NULL,
                    extraction_config TEXT DEFAULT '{}',
                    FOREIGN KEY (recording_id) REFERENCES recording(record_id) ON DELETE CASCADE
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_keyframe_recording_id 
                ON keyframe_video(recording_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_keyframe_created_at 
                ON keyframe_video(created_at DESC)
            """)
            
            # 3. åˆ›å»º PROMPT_TEMPLATE è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS prompt_template (
                    prompt_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT DEFAULT '',
                    prompt_content TEXT NOT NULL,
                    category TEXT DEFAULT 'general',
                    is_default INTEGER DEFAULT 0,
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    tags TEXT DEFAULT '[]',
                    variables TEXT DEFAULT '[]',
                    CHECK (is_default IN (0, 1))
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_prompt_category 
                ON prompt_template(category)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_prompt_is_default 
                ON prompt_template(is_default)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_prompt_created_at 
                ON prompt_template(created_at DESC)
            """)
            
            # 4. åˆ›å»º AI_ANALYSIS è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS ai_analysis (
                    analysis_id TEXT PRIMARY KEY,
                    keyframe_id TEXT NOT NULL,
                    prompt_id TEXT,
                    analysis_type TEXT DEFAULT 'general',
                    model_name TEXT NOT NULL,
                    model_version TEXT DEFAULT '',
                    status TEXT DEFAULT 'pending',
                    video_analysis_md TEXT DEFAULT '',
                    audio_analysis_md TEXT DEFAULT '',
                    summary_md TEXT DEFAULT '',
                    started_at TEXT,
                    completed_at TEXT,
                    processing_time_ms INTEGER DEFAULT 0,
                    error_message TEXT DEFAULT '',
                    FOREIGN KEY (keyframe_id) REFERENCES keyframe_video(keyframe_id) ON DELETE CASCADE,
                    FOREIGN KEY (prompt_id) REFERENCES prompt_template(prompt_id) ON DELETE SET NULL
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analysis_keyframe_id 
                ON ai_analysis(keyframe_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analysis_prompt_id 
                ON ai_analysis(prompt_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analysis_status 
                ON ai_analysis(status)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analysis_completed_at 
                ON ai_analysis(completed_at DESC)
            """)
            
            # 5. åˆ›å»º TIMESTAMP_EVENT è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS timestamp_event (
                    event_id TEXT PRIMARY KEY,
                    analysis_id TEXT NOT NULL,
                    timestamp_seconds REAL NOT NULL,
                    event_type TEXT DEFAULT 'highlight',
                    title TEXT NOT NULL,
                    description TEXT DEFAULT '',
                    thumbnail_path TEXT DEFAULT '',
                    importance_score INTEGER DEFAULT 5,
                    metadata TEXT DEFAULT '{}',
                    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
                    CHECK (timestamp_seconds >= 0),
                    CHECK (importance_score BETWEEN 1 AND 10)
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_event_analysis_id 
                ON timestamp_event(analysis_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_event_timestamp 
                ON timestamp_event(timestamp_seconds)
            """)
            
            # 5. åˆ›å»º KEY_FINDING è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS key_finding (
                    finding_id TEXT PRIMARY KEY,
                    analysis_id TEXT NOT NULL,
                    sequence_order INTEGER NOT NULL,
                    category TEXT DEFAULT 'general',
                    title TEXT NOT NULL,
                    content TEXT NOT NULL,
                    related_timestamps TEXT DEFAULT '[]',
                    confidence_score INTEGER DEFAULT 80,
                    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
                    CHECK (confidence_score BETWEEN 0 AND 100)
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_finding_analysis_id 
                ON key_finding(analysis_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_finding_sequence 
                ON key_finding(analysis_id, sequence_order)
            """)
            
            # 6. åˆ›å»º ANALYSIS_METADATA è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS analysis_metadata (
                    metadata_id TEXT PRIMARY KEY,
                    analysis_id TEXT NOT NULL,
                    key TEXT NOT NULL,
                    value TEXT NOT NULL,
                    data_type TEXT DEFAULT 'string',
                    FOREIGN KEY (analysis_id) REFERENCES ai_analysis(analysis_id) ON DELETE CASCADE,
                    UNIQUE(analysis_id, key)
                )
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_metadata_analysis_id 
                ON analysis_metadata(analysis_id)
            """)
    
    def execute_query(self, query: str, params: tuple = ()) -> List[sqlite3.Row]:
        """
        æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœ
        
        Args:
            query: SQL æŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        with self.get_cursor() as cursor:
            cursor.execute(query, params)
            return cursor.fetchall()
    
    def execute_update(self, query: str, params: tuple = ()) -> int:
        """
        æ‰§è¡Œæ›´æ–°æ“ä½œ
        
        Args:
            query: SQL æ›´æ–°è¯­å¥
            params: æ›´æ–°å‚æ•°
            
        Returns:
            å—å½±å“çš„è¡Œæ•°
        """
        with self.get_cursor() as cursor:
            cursor.execute(query, params)
            return cursor.rowcount
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self._local, 'connection'):
            self._local.connection.close()
            delattr(self._local, 'connection')
```

---

### æ•°æ®è®¿é—®å¯¹è±¡ (DAO)

#### RecordingDAO - å½•åˆ¶è®°å½• DAO

```python
"""
å½•åˆ¶è®°å½•æ•°æ®è®¿é—®å¯¹è±¡
"""
import json
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict

from .database_manager import DatabaseManager
from infrastructure.log_manager import get_logger


@dataclass
class Recording:
    """å½•åˆ¶è®°å½•æ•°æ®ç±»"""
    record_id: str
    original_video_path: str
    title: str = ""
    description: str = ""
    duration_seconds: int = 0
    file_size_bytes: int = 0
    thumbnail_path: str = ""
    created_at: str = ""
    updated_at: str = ""
    tags: List[str] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.metadata is None:
            self.metadata = {}


class RecordingDAO:
    """å½•åˆ¶è®°å½•æ•°æ®è®¿é—®å¯¹è±¡"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
        self.logger = get_logger("RecordingDAO")
    
    def create(self, recording: Recording) -> str:
        """
        åˆ›å»ºå½•åˆ¶è®°å½•
        
        Args:
            recording: å½•åˆ¶è®°å½•å¯¹è±¡
            
        Returns:
            è®°å½•ID
        """
        if not recording.record_id:
            recording.record_id = str(uuid.uuid4())
        
        now = datetime.now().isoformat()
        if not recording.created_at:
            recording.created_at = now
        recording.updated_at = now
        
        query = """
            INSERT INTO recording (
                record_id, original_video_path, title, description,
                duration_seconds, file_size_bytes, thumbnail_path,
                created_at, updated_at, tags, metadata
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        params = (
            recording.record_id,
            recording.original_video_path,
            recording.title,
            recording.description,
            recording.duration_seconds,
            recording.file_size_bytes,
            recording.thumbnail_path,
            recording.created_at,
            recording.updated_at,
            json.dumps(recording.tags, ensure_ascii=False),
            json.dumps(recording.metadata, ensure_ascii=False)
        )
        
        self.db.execute_update(query, params)
        self.logger.info(f"Created recording: {recording.record_id}")
        return recording.record_id
    
    def get_by_id(self, record_id: str) -> Optional[Recording]:
        """æ ¹æ®IDè·å–å½•åˆ¶è®°å½•"""
        query = "SELECT * FROM recording WHERE record_id = ?"
        results = self.db.execute_query(query, (record_id,))
        
        if not results:
            return None
        
        return self._row_to_recording(results[0])
    
    def get_by_path(self, video_path: str) -> Optional[Recording]:
        """æ ¹æ®è§†é¢‘è·¯å¾„è·å–å½•åˆ¶è®°å½•"""
        query = "SELECT * FROM recording WHERE original_video_path = ?"
        results = self.db.execute_query(query, (video_path,))
        
        if not results:
            return None
        
        return self._row_to_recording(results[0])
    
    def get_all(self, limit: int = 100, offset: int = 0) -> List[Recording]:
        """è·å–æ‰€æœ‰å½•åˆ¶è®°å½•"""
        query = """
            SELECT * FROM recording 
            ORDER BY created_at DESC 
            LIMIT ? OFFSET ?
        """
        results = self.db.execute_query(query, (limit, offset))
        return [self._row_to_recording(row) for row in results]
    
    def update(self, recording: Recording) -> bool:
        """æ›´æ–°å½•åˆ¶è®°å½•"""
        recording.updated_at = datetime.now().isoformat()
        
        query = """
            UPDATE recording SET
                title = ?, description = ?, duration_seconds = ?,
                file_size_bytes = ?, thumbnail_path = ?, updated_at = ?,
                tags = ?, metadata = ?
            WHERE record_id = ?
        """
        
        params = (
            recording.title,
            recording.description,
            recording.duration_seconds,
            recording.file_size_bytes,
            recording.thumbnail_path,
            recording.updated_at,
            json.dumps(recording.tags, ensure_ascii=False),
            json.dumps(recording.metadata, ensure_ascii=False),
            recording.record_id
        )
        
        affected = self.db.execute_update(query, params)
        return affected > 0
    
    def delete(self, record_id: str) -> bool:
        """åˆ é™¤å½•åˆ¶è®°å½•(çº§è”åˆ é™¤å…³è”æ•°æ®)"""
        query = "DELETE FROM recording WHERE record_id = ?"
        affected = self.db.execute_update(query, (record_id,))
        
        if affected > 0:
            self.logger.info(f"Deleted recording: {record_id}")
        
        return affected > 0
    
    def search_by_title(self, keyword: str) -> List[Recording]:
        """æ ¹æ®æ ‡é¢˜æœç´¢"""
        query = """
            SELECT * FROM recording 
            WHERE title LIKE ? 
            ORDER BY created_at DESC
        """
        results = self.db.execute_query(query, (f"%{keyword}%",))
        return [self._row_to_recording(row) for row in results]
    
    def _row_to_recording(self, row) -> Recording:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºRecordingå¯¹è±¡"""
        return Recording(
            record_id=row['record_id'],
            original_video_path=row['original_video_path'],
            title=row['title'],
            description=row['description'],
            duration_seconds=row['duration_seconds'],
            file_size_bytes=row['file_size_bytes'],
            thumbnail_path=row['thumbnail_path'],
            created_at=row['created_at'],
            updated_at=row['updated_at'],
            tags=json.loads(row['tags']),
            metadata=json.loads(row['metadata'])
        )
```

#### AIAnalysisDAO - AI åˆ†æç»“æœ DAO

```python
"""
AI åˆ†æç»“æœæ•°æ®è®¿é—®å¯¹è±¡
"""
import uuid
from datetime import datetime
from typing import List, Optional
from dataclasses import dataclass

from .database_manager import DatabaseManager
from infrastructure.log_manager import get_logger


@dataclass
class AIAnalysis:
    """AI åˆ†æç»“æœæ•°æ®ç±»"""
    analysis_id: str
    keyframe_id: str
    analysis_type: str = "general"
    model_name: str = ""
    model_version: str = ""
    status: str = "pending"
    video_analysis_md: str = ""
    audio_analysis_md: str = ""
    summary_md: str = ""
    started_at: str = ""
    completed_at: str = ""
    processing_time_ms: int = 0
    error_message: str = ""


class AIAnalysisDAO:
    """AI åˆ†æç»“æœæ•°æ®è®¿é—®å¯¹è±¡"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
        self.logger = get_logger("AIAnalysisDAO")
    
    def create(self, analysis: AIAnalysis) -> str:
        """åˆ›å»ºåˆ†æè®°å½•"""
        if not analysis.analysis_id:
            analysis.analysis_id = str(uuid.uuid4())
        
        if not analysis.started_at:
            analysis.started_at = datetime.now().isoformat()
        
        query = """
            INSERT INTO ai_analysis (
                analysis_id, keyframe_id, analysis_type, model_name,
                model_version, status, video_analysis_md, audio_analysis_md,
                summary_md, started_at, completed_at, processing_time_ms,
                error_message
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        params = (
            analysis.analysis_id,
            analysis.keyframe_id,
            analysis.analysis_type,
            analysis.model_name,
            analysis.model_version,
            analysis.status,
            analysis.video_analysis_md,
            analysis.audio_analysis_md,
            analysis.summary_md,
            analysis.started_at,
            analysis.completed_at,
            analysis.processing_time_ms,
            analysis.error_message
        )
        
        self.db.execute_update(query, params)
        self.logger.info(f"Created AI analysis: {analysis.analysis_id}")
        return analysis.analysis_id
    
    def get_by_id(self, analysis_id: str) -> Optional[AIAnalysis]:
        """æ ¹æ®IDè·å–åˆ†æè®°å½•"""
        query = "SELECT * FROM ai_analysis WHERE analysis_id = ?"
        results = self.db.execute_query(query, (analysis_id,))
        
        if not results:
            return None
        
        return self._row_to_analysis(results[0])
    
    def get_by_keyframe_id(self, keyframe_id: str) -> List[AIAnalysis]:
        """è·å–å…³é”®å¸§çš„æ‰€æœ‰åˆ†æè®°å½•"""
        query = """
            SELECT * FROM ai_analysis 
            WHERE keyframe_id = ? 
            ORDER BY started_at DESC
        """
        results = self.db.execute_query(query, (keyframe_id,))
        return [self._row_to_analysis(row) for row in results]
    
    def update_status(
        self, 
        analysis_id: str, 
        status: str, 
        error_message: str = ""
    ) -> bool:
        """æ›´æ–°åˆ†æçŠ¶æ€"""
        query = """
            UPDATE ai_analysis 
            SET status = ?, error_message = ?, completed_at = ?
            WHERE analysis_id = ?
        """
        
        completed_at = datetime.now().isoformat() if status == "completed" else ""
        params = (status, error_message, completed_at, analysis_id)
        
        affected = self.db.execute_update(query, params)
        return affected > 0
    
    def update_results(
        self,
        analysis_id: str,
        video_analysis_md: str = "",
        audio_analysis_md: str = "",
        summary_md: str = ""
    ) -> bool:
        """æ›´æ–°åˆ†æç»“æœ"""
        query = """
            UPDATE ai_analysis 
            SET video_analysis_md = ?, audio_analysis_md = ?, summary_md = ?
            WHERE analysis_id = ?
        """
        
        params = (video_analysis_md, audio_analysis_md, summary_md, analysis_id)
        affected = self.db.execute_update(query, params)
        return affected > 0
    
    def _row_to_analysis(self, row) -> AIAnalysis:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºAIAnalysiså¯¹è±¡"""
        return AIAnalysis(
            analysis_id=row['analysis_id'],
            keyframe_id=row['keyframe_id'],
            analysis_type=row['analysis_type'],
            model_name=row['model_name'],
            model_version=row['model_version'],
            status=row['status'],
            video_analysis_md=row['video_analysis_md'],
            audio_analysis_md=row['audio_analysis_md'],
            summary_md=row['summary_md'],
            started_at=row['started_at'],
            completed_at=row['completed_at'],
            processing_time_ms=row['processing_time_ms'],
            error_message=row['error_message']
        )
```

---

#### PromptTemplateDAO - æç¤ºè¯æ¨¡æ¿ DAO

```python
"""
æç¤ºè¯æ¨¡æ¿æ•°æ®è®¿é—®å¯¹è±¡
"""
import uuid
import json
from datetime import datetime
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

from .database_manager import DatabaseManager
from infrastructure.log_manager import get_logger


@dataclass
class PromptTemplate:
    """æç¤ºè¯æ¨¡æ¿æ•°æ®ç±»"""
    prompt_id: str
    name: str
    prompt_content: str
    description: str = ""
    category: str = "general"
    is_default: int = 0
    created_at: str = ""
    updated_at: str = ""
    tags: List[str] = None
    variables: List[Dict[str, str]] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.variables is None:
            self.variables = []


class PromptTemplateDAO:
    """æç¤ºè¯æ¨¡æ¿æ•°æ®è®¿é—®å¯¹è±¡"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
        self.logger = get_logger("PromptTemplateDAO")
    
    def create(self, template: PromptTemplate) -> str:
        """åˆ›å»ºæç¤ºè¯æ¨¡æ¿"""
        if not template.prompt_id:
            template.prompt_id = str(uuid.uuid4())
        
        now = datetime.now().isoformat()
        if not template.created_at:
            template.created_at = now
        template.updated_at = now
        
        query = """
            INSERT INTO prompt_template (
                prompt_id, name, description, prompt_content,
                category, is_default, created_at, updated_at,
                tags, variables
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        params = (
            template.prompt_id,
            template.name,
            template.description,
            template.prompt_content,
            template.category,
            template.is_default,
            template.created_at,
            template.updated_at,
            json.dumps(template.tags, ensure_ascii=False),
            json.dumps(template.variables, ensure_ascii=False)
        )
        
        self.db.execute_update(query, params)
        self.logger.info(f"Created prompt template: {template.prompt_id}")
        return template.prompt_id
    
    def get_by_id(self, prompt_id: str) -> Optional[PromptTemplate]:
        """æ ¹æ®IDè·å–æç¤ºè¯æ¨¡æ¿"""
        query = "SELECT * FROM prompt_template WHERE prompt_id = ?"
        results = self.db.execute_query(query, (prompt_id,))
        
        if not results:
            return None
        
        return self._row_to_template(results[0])
    
    def get_all(self, category: str = None) -> List[PromptTemplate]:
        """è·å–æ‰€æœ‰æç¤ºè¯æ¨¡æ¿,å¯æŒ‰åˆ†ç±»ç­›é€‰"""
        if category:
            query = """
                SELECT * FROM prompt_template 
                WHERE category = ? 
                ORDER BY is_default DESC, created_at DESC
            """
            results = self.db.execute_query(query, (category,))
        else:
            query = """
                SELECT * FROM prompt_template 
                ORDER BY category, is_default DESC, created_at DESC
            """
            results = self.db.execute_query(query)
        
        return [self._row_to_template(row) for row in results]
    
    def get_default(self, category: str = "general") -> Optional[PromptTemplate]:
        """è·å–æŒ‡å®šåˆ†ç±»çš„é»˜è®¤æ¨¡æ¿"""
        query = """
            SELECT * FROM prompt_template 
            WHERE category = ? AND is_default = 1 
            LIMIT 1
        """
        results = self.db.execute_query(query, (category,))
        
        if not results:
            return None
        
        return self._row_to_template(results[0])
    
    def update(self, template: PromptTemplate) -> bool:
        """æ›´æ–°æç¤ºè¯æ¨¡æ¿"""
        template.updated_at = datetime.now().isoformat()
        
        query = """
            UPDATE prompt_template SET
                name = ?, description = ?, prompt_content = ?,
                category = ?, is_default = ?, updated_at = ?,
                tags = ?, variables = ?
            WHERE prompt_id = ?
        """
        
        params = (
            template.name,
            template.description,
            template.prompt_content,
            template.category,
            template.is_default,
            template.updated_at,
            json.dumps(template.tags, ensure_ascii=False),
            json.dumps(template.variables, ensure_ascii=False),
            template.prompt_id
        )
        
        affected = self.db.execute_update(query, params)
        return affected > 0
    
    def delete(self, prompt_id: str) -> bool:
        """åˆ é™¤æç¤ºè¯æ¨¡æ¿"""
        query = "DELETE FROM prompt_template WHERE prompt_id = ?"
        affected = self.db.execute_update(query, (prompt_id,))
        
        if affected > 0:
            self.logger.info(f"Deleted prompt template: {prompt_id}")
        
        return affected > 0
    
    def set_as_default(self, prompt_id: str, category: str) -> bool:
        """å°†æŒ‡å®šæ¨¡æ¿è®¾ç½®ä¸ºè¯¥åˆ†ç±»çš„é»˜è®¤æ¨¡æ¿"""
        # å…ˆå–æ¶ˆè¯¥åˆ†ç±»ä¸‹æ‰€æœ‰æ¨¡æ¿çš„é»˜è®¤çŠ¶æ€
        query1 = """
            UPDATE prompt_template 
            SET is_default = 0 
            WHERE category = ?
        """
        self.db.execute_update(query1, (category,))
        
        # è®¾ç½®æŒ‡å®šæ¨¡æ¿ä¸ºé»˜è®¤
        query2 = """
            UPDATE prompt_template 
            SET is_default = 1 
            WHERE prompt_id = ?
        """
        affected = self.db.execute_update(query2, (prompt_id,))
        return affected > 0
    
    def render_prompt(
        self, 
        template: PromptTemplate, 
        variables: Dict[str, str] = None
    ) -> str:
        """
        æ¸²æŸ“æç¤ºè¯æ¨¡æ¿,æ›¿æ¢å˜é‡å ä½ç¬¦
        
        Args:
            template: æç¤ºè¯æ¨¡æ¿
            variables: å˜é‡å€¼å­—å…¸,å¦‚ {"focus": "æ€§èƒ½ä¼˜åŒ–", "detail_level": "è¯¦ç»†"}
        
        Returns:
            æ¸²æŸ“åçš„æç¤ºè¯
        """
        content = template.prompt_content
        
        if not variables:
            variables = {}
        
        # ä½¿ç”¨é»˜è®¤å€¼å¡«å……æœªæä¾›çš„å˜é‡
        for var_def in template.variables:
            var_name = var_def.get("name")
            if var_name and var_name not in variables:
                variables[var_name] = var_def.get("default", "")
        
        # æ›¿æ¢å ä½ç¬¦
        for key, value in variables.items():
            placeholder = f"{{{key}}}"
            content = content.replace(placeholder, value)
        
        return content
    
    def _row_to_template(self, row) -> PromptTemplate:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºPromptTemplateå¯¹è±¡"""
        return PromptTemplate(
            prompt_id=row['prompt_id'],
            name=row['name'],
            description=row['description'],
            prompt_content=row['prompt_content'],
            category=row['category'],
            is_default=row['is_default'],
            created_at=row['created_at'],
            updated_at=row['updated_at'],
            tags=json.loads(row['tags']),
            variables=json.loads(row['variables'])
        )
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å·¥ä½œæµç¤ºä¾‹

```python
"""
å®Œæ•´çš„æ•°æ®åº“ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºä»å½•åˆ¶åˆ°åˆ†æçš„å®Œæ•´æµç¨‹
"""
from datetime import datetime
from pathlib import Path

from database.database_manager import DatabaseManager
from database.recording_dao import RecordingDAO, Recording
from database.keyframe_dao import KeyFrameVideoDAO, KeyFrameVideo
from database.prompt_template_dao import PromptTemplateDAO, PromptTemplate
from database.ai_analysis_dao import AIAnalysisDAO, AIAnalysis
from database.timestamp_event_dao import TimestampEventDAO, TimestampEvent
from database.key_finding_dao import KeyFindingDAO, KeyFinding


def example_workflow():
    """å®Œæ•´å·¥ä½œæµç¤ºä¾‹"""
    
    # 1. åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    db_manager = DatabaseManager("data/keyframe_analysis.db")
    
    # 2. åˆ›å»º DAO å®ä¾‹
    recording_dao = RecordingDAO(db_manager)
    keyframe_dao = KeyFrameVideoDAO(db_manager)
    prompt_dao = PromptTemplateDAO(db_manager)
    analysis_dao = AIAnalysisDAO(db_manager)
    event_dao = TimestampEventDAO(db_manager)
    finding_dao = KeyFindingDAO(db_manager)
    
    # 3. åˆ›å»ºå½•åˆ¶è®°å½•
    recording = Recording(
        record_id="",  # è‡ªåŠ¨ç”Ÿæˆ
        original_video_path="D:/Videos/meeting_2024_01_15.mp4",
        title="å›¢é˜Ÿä¼šè®®å½•åˆ¶ - 2024-01-15",
        description="è®¨è®º Q1 äº§å“è§„åˆ’",
        duration_seconds=3600,
        file_size_bytes=1024 * 1024 * 500,  # 500MB
        thumbnail_path="D:/Thumbnails/meeting_thumb.jpg",
        tags=["ä¼šè®®", "äº§å“è§„åˆ’", "2024Q1"]
    )
    
    record_id = recording_dao.create(recording)
    print(f"âœ… åˆ›å»ºå½•åˆ¶è®°å½•: {record_id}")
    
    # 4. åˆ›å»ºå…³é”®å¸§è§†é¢‘è®°å½•
    keyframe = KeyFrameVideo(
        keyframe_id="",
        recording_id=record_id,
        keyframe_video_path="D:/Videos/meeting_2024_01_15_keyframes.mp4",
        keyframe_audio_path="D:/Videos/meeting_2024_01_15_keyframes.aac",
        keyframe_count=50,
        duration_seconds=360,  # 6åˆ†é’Ÿ
        file_size_bytes=1024 * 1024 * 50,  # 50MB
        compression_ratio=0.1
    )
    
    keyframe_id = keyframe_dao.create(keyframe)
    print(f"âœ… åˆ›å»ºå…³é”®å¸§è§†é¢‘: {keyframe_id}")
    
    # 5. åˆ›å»ºæç¤ºè¯æ¨¡æ¿
    prompt_template = PromptTemplate(
        prompt_id="",
        name="ä¼šè®®åˆ†ææ¨¡æ¿",
        description="ä¸“é—¨ç”¨äºåˆ†æä¼šè®®è§†é¢‘çš„æç¤ºè¯æ¨¡æ¿",
        prompt_content="""è¯·åˆ†æè¿™æ®µä¼šè®®è§†é¢‘,é‡ç‚¹å…³æ³¨ {focus}ã€‚
åˆ†æè¯¦ç»†ç¨‹åº¦: {detail_level}
è¾“å‡ºè¯­è¨€: {language}

è¯·æä¾›ä»¥ä¸‹å†…å®¹:
1. ä¼šè®®ä¸»è¦è®®é¢˜å’Œè®¨è®ºå†…å®¹
2. å…³é”®å†³ç­–å’Œè¡ŒåŠ¨é¡¹
3. é‡è¦æ—¶åˆ»çš„æ—¶é—´æˆ³
4. æ ¸å¿ƒè¦ç‚¹æ€»ç»“""",
        category="meeting",
        is_default=1,
        tags=["ä¼šè®®", "å›¢é˜Ÿåä½œ"],
        variables=[
            {"name": "focus", "default": "å†³ç­–å’Œè¡ŒåŠ¨é¡¹", "description": "åˆ†æé‡ç‚¹"},
            {"name": "detail_level", "default": "è¯¦ç»†", "description": "è¯¦ç»†ç¨‹åº¦"},
            {"name": "language", "default": "ä¸­æ–‡", "description": "è¾“å‡ºè¯­è¨€"}
        ]
    )
    
    prompt_id = prompt_dao.create(prompt_template)
    print(f"âœ… åˆ›å»ºæç¤ºè¯æ¨¡æ¿: {prompt_id}")
    
    # æ¸²æŸ“æç¤ºè¯(ä½¿ç”¨è‡ªå®šä¹‰å˜é‡)
    rendered_prompt = prompt_dao.render_prompt(
        prompt_template,
        variables={"focus": "äº§å“è§„åˆ’å’ŒæŠ€æœ¯å†³ç­–"}
    )
    print(f"ğŸ“ æ¸²æŸ“åçš„æç¤ºè¯:\n{rendered_prompt}\n")
    
    # 6. åˆ›å»º AI åˆ†æä»»åŠ¡(ä½¿ç”¨æç¤ºè¯æ¨¡æ¿)
    analysis = AIAnalysis(
        analysis_id="",
        keyframe_id=keyframe_id,
        prompt_id=prompt_id,  # å…³è”æç¤ºè¯æ¨¡æ¿
        analysis_type="detailed",
        model_name="gemini-1.5-flash",
        model_version="001",
        status="processing"
    )
    
    analysis_id = analysis_dao.create(analysis)
    print(f"âœ… åˆ›å»º AI åˆ†æä»»åŠ¡: {analysis_id}")
    
    # 6. æ¨¡æ‹Ÿ AI åˆ†æå®Œæˆ,æ›´æ–°ç»“æœ
    video_analysis = """
# è§†é¢‘å†…å®¹åˆ†æ

## ä¸»è¦åœºæ™¯
1. **å¼€åœºä»‹ç»** (00:00-02:30)
   - ä¸»æŒäººä»‹ç»ä¼šè®®è®®ç¨‹
   - å‚ä¼šäººå‘˜è‡ªæˆ‘ä»‹ç»
   
2. **äº§å“æ¼”ç¤º** (02:30-15:45)
   - æ¼”ç¤ºæ–°åŠŸèƒ½åŸå‹
   - è®¨è®ºç”¨æˆ·ä½“éªŒä¼˜åŒ–
   
3. **æŠ€æœ¯è®¨è®º** (15:45-28:20)
   - æ¶æ„è®¾è®¡è¯„å®¡
   - æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ
"""
    
    audio_analysis = """
# éŸ³é¢‘/è¯­éŸ³åˆ†æ

## å…³é”®å¯¹è¯
- **å¼ ä¸‰**: "æˆ‘ä»¬éœ€è¦åœ¨ Q1 å®Œæˆæ ¸å¿ƒåŠŸèƒ½å¼€å‘"
- **æå››**: "å»ºè®®é‡‡ç”¨å¾®æœåŠ¡æ¶æ„æå‡å¯æ‰©å±•æ€§"
- **ç‹äº”**: "ç”¨æˆ·åé¦ˆæ˜¾ç¤ºåŠ è½½é€Ÿåº¦éœ€è¦ä¼˜åŒ–"
"""
    
    summary = """
# ä¼šè®®æ‘˜è¦

æœ¬æ¬¡ä¼šè®®ä¸»è¦è®¨è®ºäº† 2024 Q1 äº§å“è§„åˆ’,ç¡®å®šäº†ä»¥ä¸‹å…³é”®å†³ç­–:
1. é‡‡ç”¨å¾®æœåŠ¡æ¶æ„é‡æ„åç«¯ç³»ç»Ÿ
2. ä¼˜å…ˆå¼€å‘ç”¨æˆ·æœ€éœ€è¦çš„ 3 ä¸ªæ ¸å¿ƒåŠŸèƒ½
3. æ€§èƒ½ä¼˜åŒ–ç›®æ ‡: é¡µé¢åŠ è½½æ—¶é—´ < 2ç§’
"""
    
    analysis_dao.update_results(
        analysis_id,
        video_analysis_md=video_analysis,
        audio_analysis_md=audio_analysis,
        summary_md=summary
    )
    
    analysis_dao.update_status(analysis_id, "completed")
    print(f"âœ… AI åˆ†æå®Œæˆ")
    
    # 7. æ·»åŠ æ—¶é—´æˆ³äº‹ä»¶
    events = [
        TimestampEvent(
            event_id="",
            analysis_id=analysis_id,
            timestamp_seconds=150.5,
            event_type="highlight",
            title="äº§å“æ¼”ç¤ºå¼€å§‹",
            description="æ¼”ç¤ºæ–°åŠŸèƒ½åŸå‹ç•Œé¢",
            importance_score=9
        ),
        TimestampEvent(
            event_id="",
            analysis_id=analysis_id,
            timestamp_seconds=945.2,
            event_type="speech",
            title="æ¶æ„è®¾è®¡è®¨è®º",
            description="æå››æå‡ºå¾®æœåŠ¡æ¶æ„æ–¹æ¡ˆ",
            importance_score=10
        )
    ]
    
    for event in events:
        event_dao.create(event)
    
    print(f"âœ… æ·»åŠ  {len(events)} ä¸ªæ—¶é—´æˆ³äº‹ä»¶")
    
    # 8. æ·»åŠ å…³é”®è¦ç‚¹
    findings = [
        KeyFinding(
            finding_id="",
            analysis_id=analysis_id,
            sequence_order=1,
            category="technical",
            title="é‡‡ç”¨å¾®æœåŠ¡æ¶æ„",
            content="å›¢é˜Ÿå†³å®šé‡‡ç”¨å¾®æœåŠ¡æ¶æ„é‡æ„åç«¯ç³»ç»Ÿ,æå‡å¯æ‰©å±•æ€§å’Œç»´æŠ¤æ€§",
            related_timestamps=[945.2, 1120.5],
            confidence_score=95
        ),
        KeyFinding(
            finding_id="",
            analysis_id=analysis_id,
            sequence_order=2,
            category="summary",
            title="Q1 æ ¸å¿ƒç›®æ ‡",
            content="å®Œæˆ 3 ä¸ªæ ¸å¿ƒåŠŸèƒ½å¼€å‘,é¡µé¢åŠ è½½æ—¶é—´ä¼˜åŒ–è‡³ 2 ç§’ä»¥å†…",
            related_timestamps=[150.5, 1800.0],
            confidence_score=90
        )
    ]
    
    for finding in findings:
        finding_dao.create(finding)
    
    print(f"âœ… æ·»åŠ  {len(findings)} ä¸ªå…³é”®è¦ç‚¹")
    
    # 9. æŸ¥è¯¢å®Œæ•´æ•°æ®
    print("\n" + "="*50)
    print("ğŸ“Š æŸ¥è¯¢ç»“æœ:")
    print("="*50)
    
    # æŸ¥è¯¢å½•åˆ¶è®°å½•
    rec = recording_dao.get_by_id(record_id)
    print(f"\nå½•åˆ¶æ ‡é¢˜: {rec.title}")
    print(f"æ—¶é•¿: {rec.duration_seconds}ç§’")
    print(f"æ ‡ç­¾: {', '.join(rec.tags)}")
    
    # æŸ¥è¯¢å…³é”®å¸§
    kf = keyframe_dao.get_by_id(keyframe_id)
    print(f"\nå…³é”®å¸§æ•°é‡: {kf.keyframe_count}")
    print(f"å‹ç¼©ç‡: {kf.compression_ratio * 100:.1f}%")
    
    # æŸ¥è¯¢åˆ†æç»“æœ
    ana = analysis_dao.get_by_id(analysis_id)
    print(f"\nAI æ¨¡å‹: {ana.model_name}")
    print(f"åˆ†æçŠ¶æ€: {ana.status}")
    
    # æŸ¥è¯¢æ—¶é—´æˆ³äº‹ä»¶
    events = event_dao.get_by_analysis_id(analysis_id)
    print(f"\næ—¶é—´æˆ³äº‹ä»¶ ({len(events)} ä¸ª):")
    for evt in events:
        print(f"  - [{evt.timestamp_seconds:.1f}s] {evt.title} (é‡è¦æ€§: {evt.importance_score}/10)")
    
    # æŸ¥è¯¢å…³é”®è¦ç‚¹
    findings = finding_dao.get_by_analysis_id(analysis_id)
    print(f"\nå…³é”®è¦ç‚¹ ({len(findings)} ä¸ª):")
    for find in findings:
        print(f"  {find.sequence_order}. [{find.category}] {find.title}")
        print(f"     ç½®ä¿¡åº¦: {find.confidence_score}%")


if __name__ == "__main__":
    example_workflow()
```

---

## ğŸ¨ æœ€ä½³å®è·µ

### 1. äº‹åŠ¡ç®¡ç†

```python
def batch_insert_events(db_manager, analysis_id, events):
    """æ‰¹é‡æ’å…¥äº‹ä»¶(ä½¿ç”¨äº‹åŠ¡)"""
    with db_manager.transaction() as conn:
        cursor = conn.cursor()
        
        for event in events:
            cursor.execute("""
                INSERT INTO timestamp_event (
                    event_id, analysis_id, timestamp_seconds,
                    event_type, title, description, importance_score
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                str(uuid.uuid4()),
                analysis_id,
                event.timestamp,
                event.type,
                event.title,
                event.description,
                event.importance
            ))
```

### 2. è¿æ¥æ± ç®¡ç†

```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†è¿æ¥
with db_manager.get_cursor() as cursor:
    cursor.execute("SELECT * FROM recording")
    results = cursor.fetchall()
# è‡ªåŠ¨æäº¤/å›æ»š
```

### 3. æ•°æ®éªŒè¯

```python
def validate_recording(recording: Recording) -> bool:
    """éªŒè¯å½•åˆ¶è®°å½•æ•°æ®"""
    if not recording.original_video_path:
        raise ValueError("è§†é¢‘è·¯å¾„ä¸èƒ½ä¸ºç©º")
    
    if not Path(recording.original_video_path).exists():
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {recording.original_video_path}")
    
    if recording.duration_seconds < 0:
        raise ValueError("æ—¶é•¿ä¸èƒ½ä¸ºè´Ÿæ•°")
    
    return True
```

### 4. æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨ç´¢å¼•åŠ é€ŸæŸ¥è¯¢
def get_recent_analyses(db_manager, days=7):
    """è·å–æœ€è¿‘Nå¤©çš„åˆ†æè®°å½•(åˆ©ç”¨ç´¢å¼•)"""
    cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
    
    query = """
        SELECT * FROM ai_analysis 
        WHERE completed_at >= ? 
        ORDER BY completed_at DESC
    """
    # åˆ©ç”¨ idx_analysis_completed_at ç´¢å¼•
    return db_manager.execute_query(query, (cutoff_date,))
```

---

## ğŸ” é«˜çº§æŸ¥è¯¢ç¤ºä¾‹

### 1. è”è¡¨æŸ¥è¯¢ - è·å–å®Œæ•´åˆ†ææŠ¥å‘Š

```python
def get_full_analysis_report(db_manager, analysis_id: str) -> Dict:
    """è·å–å®Œæ•´çš„åˆ†ææŠ¥å‘Š(åŒ…å«æ‰€æœ‰å…³è”æ•°æ®)"""
    
    query = """
        SELECT 
            r.title as recording_title,
            r.original_video_path,
            kf.keyframe_video_path,
            kf.keyframe_count,
            kf.compression_ratio,
            a.model_name,
            a.video_analysis_md,
            a.audio_analysis_md,
            a.summary_md,
            a.completed_at
        FROM ai_analysis a
        JOIN keyframe_video kf ON a.keyframe_id = kf.keyframe_id
        JOIN recording r ON kf.recording_id = r.record_id
        WHERE a.analysis_id = ?
    """
    
    result = db_manager.execute_query(query, (analysis_id,))
    
    if not result:
        return None
    
    row = result[0]
    
    # è·å–æ—¶é—´æˆ³äº‹ä»¶
    events_query = """
        SELECT * FROM timestamp_event 
        WHERE analysis_id = ? 
        ORDER BY timestamp_seconds
    """
    events = db_manager.execute_query(events_query, (analysis_id,))
    
    # è·å–å…³é”®è¦ç‚¹
    findings_query = """
        SELECT * FROM key_finding 
        WHERE analysis_id = ? 
        ORDER BY sequence_order
    """
    findings = db_manager.execute_query(findings_query, (analysis_id,))
    
    return {
        "recording": {
            "title": row['recording_title'],
            "path": row['original_video_path']
        },
        "keyframe": {
            "path": row['keyframe_video_path'],
            "count": row['keyframe_count'],
            "compression_ratio": row['compression_ratio']
        },
        "analysis": {
            "model": row['model_name'],
            "video_analysis": row['video_analysis_md'],
            "audio_analysis": row['audio_analysis_md'],
            "summary": row['summary_md'],
            "completed_at": row['completed_at']
        },
        "events": [dict(e) for e in events],
        "findings": [dict(f) for f in findings]
    }
```

### 2. ç»Ÿè®¡æŸ¥è¯¢

```python
def get_statistics(db_manager) -> Dict:
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    
    stats = {}
    
    # æ€»å½•åˆ¶æ•°
    result = db_manager.execute_query("SELECT COUNT(*) as count FROM recording")
    stats['total_recordings'] = result[0]['count']
    
    # æ€»å…³é”®å¸§è§†é¢‘æ•°
    result = db_manager.execute_query("SELECT COUNT(*) as count FROM keyframe_video")
    stats['total_keyframes'] = result[0]['count']
    
    # æ€»åˆ†ææ•°
    result = db_manager.execute_query("SELECT COUNT(*) as count FROM ai_analysis")
    stats['total_analyses'] = result[0]['count']
    
    # å¹³å‡å‹ç¼©ç‡
    result = db_manager.execute_query("""
        SELECT AVG(compression_ratio) as avg_ratio 
        FROM keyframe_video
    """)
    stats['avg_compression_ratio'] = result[0]['avg_ratio']
    
    # æŒ‰çŠ¶æ€ç»Ÿè®¡åˆ†æä»»åŠ¡
    result = db_manager.execute_query("""
        SELECT status, COUNT(*) as count 
        FROM ai_analysis 
        GROUP BY status
    """)
    stats['analysis_by_status'] = {row['status']: row['count'] for row in result}
    
    return stats
```

---

## ğŸ“¦ è¿ç§»ä¸å¤‡ä»½

### æ•°æ®åº“å¤‡ä»½

```python
import shutil
from datetime import datetime

def backup_database(db_path: str, backup_dir: str = "backups"):
    """å¤‡ä»½æ•°æ®åº“"""
    backup_path = Path(backup_dir)
    backup_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backup_path / f"keyframe_db_backup_{timestamp}.db"
    
    shutil.copy2(db_path, backup_file)
    print(f"âœ… æ•°æ®åº“å·²å¤‡ä»½è‡³: {backup_file}")
    
    return str(backup_file)
```

### æ•°æ®å¯¼å‡º

```python
import csv

def export_to_csv(db_manager, table_name: str, output_file: str):
    """å¯¼å‡ºè¡¨æ•°æ®ä¸º CSV"""
    query = f"SELECT * FROM {table_name}"
    results = db_manager.execute_query(query)
    
    if not results:
        print(f"è¡¨ {table_name} æ— æ•°æ®")
        return
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=results[0].keys())
        writer.writeheader()
        
        for row in results:
            writer.writerow(dict(row))
    
    print(f"âœ… æ•°æ®å·²å¯¼å‡ºè‡³: {output_file}")
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç´¢å¼•ä¼˜åŒ–
- âœ… å·²ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºç´¢å¼•
- âœ… å¤åˆç´¢å¼•ç”¨äºå¤šå­—æ®µæ’åºæŸ¥è¯¢
- âš ï¸ é¿å…åœ¨å°è¡¨ä¸Šåˆ›å»ºè¿‡å¤šç´¢å¼•

### 2. æŸ¥è¯¢ä¼˜åŒ–
```python
# âŒ ä¸æ¨è: N+1 æŸ¥è¯¢
for recording in recordings:
    keyframes = get_keyframes_by_recording_id(recording.id)

# âœ… æ¨è: ä½¿ç”¨ JOIN ä¸€æ¬¡æ€§è·å–
query = """
    SELECT r.*, kf.* 
    FROM recording r
    LEFT JOIN keyframe_video kf ON r.record_id = kf.recording_id
"""
```

### 3. æ‰¹é‡æ“ä½œ
```python
# âœ… ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥
cursor.executemany("""
    INSERT INTO timestamp_event (event_id, analysis_id, timestamp_seconds, title)
    VALUES (?, ?, ?, ?)
""", events_data)
```

### 4. è¿æ¥æ± é…ç½®
```python
# è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
connection = sqlite3.connect(db_path, timeout=30.0)

# å¯ç”¨ WAL æ¨¡å¼æå‡å¹¶å‘æ€§èƒ½
connection.execute("PRAGMA journal_mode=WAL")
```

---

## ğŸ“š æ€»ç»“

æœ¬æ¶æ„è®¾è®¡æä¾›äº†:

âœ… **å®Œæ•´çš„æ•°æ®æ¨¡å‹**: 6 å¼ æ ¸å¿ƒè¡¨è¦†ç›–æ‰€æœ‰ä¸šåŠ¡éœ€æ±‚  
âœ… **è§„èŒƒçš„ DAO å±‚**: å°è£…æ•°æ®è®¿é—®é€»è¾‘,æ˜“äºç»´æŠ¤  
âœ… **äº‹åŠ¡æ”¯æŒ**: ä¿è¯æ•°æ®ä¸€è‡´æ€§  
âœ… **ç´¢å¼•ä¼˜åŒ–**: æå‡æŸ¥è¯¢æ€§èƒ½  
âœ… **æ‰©å±•æ€§**: JSON å­—æ®µæ”¯æŒçµæ´»æ‰©å±•  
âœ… **æœ€ä½³å®è·µ**: åŒ…å«å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹å’Œä¼˜åŒ–å»ºè®®  

### ä¸‹ä¸€æ­¥å»ºè®®

1. **é›†æˆåˆ°ç°æœ‰æœåŠ¡**: æ›¿æ¢ [history_service.py](file:///d:/%E7%BC%96%E7%A8%8B/%E9%A1%B9%E7%9B%AE/AiVideoAnalsysSystem/python/services/history_service.py) ä¸­çš„ JSON æ–‡ä»¶å­˜å‚¨
2. **æ·»åŠ ç¼“å­˜å±‚**: ä½¿ç”¨ Redis ç¼“å­˜çƒ­ç‚¹æ•°æ®
3. **å®ç°æ•°æ®è¿ç§»**: å°†ç°æœ‰ JSON æ•°æ®è¿ç§»åˆ° SQLite
4. **ç›‘æ§ä¸æ—¥å¿—**: æ·»åŠ æŸ¥è¯¢æ€§èƒ½ç›‘æ§
5. **å•å…ƒæµ‹è¯•**: ä¸º DAO å±‚ç¼–å†™å®Œæ•´çš„å•å…ƒæµ‹è¯•
