# ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒç»„ä»¶å¼€å‘æ¶æ„è®¾è®¡

## ğŸ“‹ é˜¶æ®µæ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®¾è®¡ç¬¬äºŒé˜¶æ®µçš„å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œä¸º Google Gemini API é›†æˆæä¾›åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

### æ ¸å¿ƒç›®æ ‡
- âœ… å°è£… Gemini API è°ƒç”¨é€»è¾‘
- âœ… å®ç°å¤šçº§ Prompt æ¡†æ¶
- âœ… æä¾›å¯é çš„ JSON è§£ææœºåˆ¶
- âœ… éªŒè¯è§†é¢‘æ–‡ä»¶æ ¼å¼å’Œå…ƒæ•°æ®

---

## ğŸ—ï¸ ç»„ä»¶æ¶æ„å›¾

```mermaid
graph TB
    subgraph "æ ¸å¿ƒç»„ä»¶å±‚"
        A[GeminiService<br/>APIè°ƒç”¨å°è£…]
        B[PromptBuilder<br/>å¤šçº§Promptæ„å»º]
        C[ResponseParser<br/>JSONè§£æéªŒè¯]
        D[VideoPreprocessor<br/>è§†é¢‘é¢„å¤„ç†]
    end
    
    subgraph "æ•°æ®è®¿é—®å±‚"
        E[PromptTemplateDAO<br/>æ¨¡æ¿è¯»å–]
    end
    
    subgraph "å¤–éƒ¨æœåŠ¡"
        F[Google Gemini API]
    end
    
    A --> B
    A --> C
    A --> D
    A --> F
    B --> E
    
    style A fill:#3498DB,stroke:#2980B9,stroke-width:3px,color:#fff
    style B fill:#E74C3C,stroke:#C0392B,stroke-width:3px,color:#fff
    style C fill:#2ECC71,stroke:#27AE60,stroke-width:3px,color:#fff
    style D fill:#F39C12,stroke:#E67E22,stroke-width:3px,color:#fff
```

---

## 1ï¸âƒ£ GeminiService è®¾è®¡

### èŒè´£å®šä¹‰
- ç®¡ç† API å¯†é’¥å’Œæ¨¡å‹é…ç½®
- å¤„ç†è§†é¢‘æ–‡ä»¶ä¸Šä¼ 
- ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
- å‘é€åˆ†æè¯·æ±‚å¹¶è·å–ç»“æœ
- å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### ç±»å›¾è®¾è®¡

```mermaid
classDiagram
    class GeminiService {
        -api_key: str
        -model: GenerativeModel
        -logger: Logger
        +__init__(api_key: str, model_name: str)
        +upload_video(video_path: str) str
        +wait_for_file_active(file_uri: str, timeout: int) bool
        +analyze_video(video_path: str, prompt: str) Dict
        -_retry_with_backoff(func, max_retries: int) Any
    }
    
    class GenerativeModel {
        +generate_content(contents, generation_config)
    }
    
    GeminiService --> GenerativeModel
    GeminiService --> ResponseParser
    GeminiService --> VideoPreprocessor
```

### æ ¸å¿ƒæ–¹æ³•è®¾è®¡

#### 1.1 åˆå§‹åŒ–æ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def __init__(self, api_key: str = None, model_name: str = "gemini-2.0-flash-exp")
```

**å®ç°è¦ç‚¹**ï¼š
- ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è¯»å– API å¯†é’¥
- é…ç½® `google.generativeai` SDK
- åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
- éªŒè¯ API å¯†é’¥æœ‰æ•ˆæ€§

**é”™è¯¯å¤„ç†**ï¼š
- `ValueError`: API å¯†é’¥ç¼ºå¤±
- `AuthenticationError`: API å¯†é’¥æ— æ•ˆ

---

#### 1.2 è§†é¢‘ä¸Šä¼ æ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def upload_video(self, video_path: str) -> str
```

**æµç¨‹å›¾**ï¼š
```mermaid
flowchart TD
    A[å¼€å§‹ä¸Šä¼ ] --> B{æ–‡ä»¶å­˜åœ¨?}
    B -->|å¦| C[æŠ›å‡ºFileNotFoundError]
    B -->|æ˜¯| D[è°ƒç”¨genai.upload_file]
    D --> E{ä¸Šä¼ æˆåŠŸ?}
    E -->|å¦| F[é‡è¯•æœºåˆ¶]
    F --> G{è¾¾åˆ°æœ€å¤§é‡è¯•?}
    G -->|æ˜¯| H[æŠ›å‡ºUploadError]
    G -->|å¦| D
    E -->|æ˜¯| I[è¿”å›file_uri]
```

**è¿”å›å€¼**ï¼š
- æˆåŠŸï¼š`file_uri` (å­—ç¬¦ä¸²)
- å¤±è´¥ï¼šæŠ›å‡ºå¼‚å¸¸

---

#### 1.3 æ–‡ä»¶æ¿€æ´»ç­‰å¾…æ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def wait_for_file_active(self, file_uri: str, timeout: int = 300) -> bool
```

**çŠ¶æ€æœºè®¾è®¡**ï¼š
```mermaid
stateDiagram-v2
    [*] --> PROCESSING
    PROCESSING --> ACTIVE: å¤„ç†å®Œæˆ
    PROCESSING --> FAILED: å¤„ç†å¤±è´¥
    PROCESSING --> TIMEOUT: è¶…æ—¶
    ACTIVE --> [*]
    FAILED --> [*]
    TIMEOUT --> [*]
```

**è½®è¯¢ç­–ç•¥**ï¼š
- åˆå§‹é—´éš”ï¼š2 ç§’
- æœ€å¤§è¶…æ—¶ï¼š300 ç§’ï¼ˆå¯é…ç½®ï¼‰
- çŠ¶æ€æ£€æŸ¥ï¼šè°ƒç”¨ `genai.get_file(file_uri)`

---

#### 1.4 è§†é¢‘åˆ†ææ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def analyze_video(self, video_path: str, prompt: str) -> Optional[Dict[str, Any]]
```

**å®Œæ•´æµç¨‹**ï¼š
```mermaid
sequenceDiagram
    participant GS as GeminiService
    participant VP as VideoPreprocessor
    participant API as Gemini API
    participant RP as ResponseParser
    
    GS->>VP: validate_video(video_path)
    VP-->>GS: éªŒè¯ç»“æœ
    GS->>API: upload_video(video_path)
    API-->>GS: file_uri
    GS->>API: wait_for_file_active(file_uri)
    API-->>GS: ACTIVEçŠ¶æ€
    GS->>API: generate_content(file_uri, prompt)
    API-->>GS: response_text
    GS->>RP: parse(response_text)
    RP-->>GS: parsed_json
    GS-->>GS: è¿”å›ç»“æœ
```

**ç”Ÿæˆé…ç½®**ï¼š
```python
generation_config = {
    "temperature": 0.4,           # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
    "response_mime_type": "application/json",  # å¼ºåˆ¶JSONè¾“å‡º
    "max_output_tokens": 8192     # æœ€å¤§è¾“å‡ºé•¿åº¦
}
```

---

#### 1.5 é‡è¯•æœºåˆ¶è®¾è®¡

**æŒ‡æ•°é€€é¿ç®—æ³•**ï¼š
```python
def _retry_with_backoff(self, func, max_retries: int = 3) -> Any:
    """æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            return func()
        except (NetworkError, TimeoutError) as e:
            if attempt == max_retries - 1:
                raise
            wait_time = 2 ** attempt  # 1s, 2s, 4s
            time.sleep(wait_time)
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ç½‘ç»œè¶…æ—¶
- API é™æµï¼ˆ429 é”™è¯¯ï¼‰
- ä¸´æ—¶æœåŠ¡ä¸å¯ç”¨ï¼ˆ503 é”™è¯¯ï¼‰

---

## 2ï¸âƒ£ PromptBuilder è®¾è®¡

### å¤šçº§ Prompt æ¡†æ¶

```mermaid
graph LR
    A[Level 1<br/>System Prompt<br/>ç³»ç»Ÿè§’è‰²<br/>å›ºå®š] --> B[Level 2<br/>Task Prompt<br/>åœºæ™¯ä»»åŠ¡<br/>ç”¨æˆ·æ§åˆ¶]
    B --> C[Level 3<br/>Context Prompt<br/>è§†é¢‘å…ƒæ•°æ®<br/>è‡ªåŠ¨ç”Ÿæˆ]
    C --> D[Level 4<br/>Output Format<br/>JSONçº¦æŸ<br/>å›ºå®š]
    D --> E[Final Prompt]
    
    style B fill:#3498DB,stroke:#2980B9,stroke-width:3px,color:#fff
```

### å±‚çº§èŒè´£è¡¨

| å±‚çº§ | åç§° | æ§åˆ¶æ–¹å¼ | å­˜å‚¨ä½ç½® | åŠ¨æ€æ€§ |
|-----|------|---------|---------|--------|
| 1 | System Prompt | ç³»ç»Ÿå›ºå®š | ä»£ç å¸¸é‡ | é™æ€ |
| 2 | **Task Prompt** | **ç”¨æˆ·æ§åˆ¶** | **æ•°æ®åº“** | **åŠ¨æ€** |
| 3 | Context Prompt | è‡ªåŠ¨ç”Ÿæˆ | è¿è¡Œæ—¶ | åŠ¨æ€ |
| 4 | Output Format | ç³»ç»Ÿå›ºå®š | ä»£ç å¸¸é‡ | é™æ€ |

### ç±»è®¾è®¡

```mermaid
classDiagram
    class PromptBuilder {
        +SYSTEM_PROMPT: str
        +OUTPUT_FORMAT_PROMPT: str
        -prompt_dao: PromptTemplateDAO
        -logger: Logger
        +__init__(prompt_dao: PromptTemplateDAO)
        +build_prompt(scenario_category, video_context, custom_variables) str
        -_build_context_prompt(video_context) str
    }
    
    class PromptTemplateDAO {
        +get_default(category: str) PromptTemplate
        +render_prompt(template, variables) str
    }
    
    PromptBuilder --> PromptTemplateDAO
```

### æ ¸å¿ƒæ–¹æ³•å®ç°

#### 2.1 æ„å»ºå®Œæ•´ Prompt

**æ–¹æ³•ç­¾å**ï¼š
```python
def build_prompt(
    self, 
    scenario_category: str,
    video_context: Dict[str, Any],
    custom_variables: Dict[str, str] = None
) -> str
```

**å‚æ•°è¯´æ˜**ï¼š
- `scenario_category`: åœºæ™¯ç±»åˆ«ï¼ˆ`coding_algorithm`, `meeting`, `teaching`, `gaming`, `general`ï¼‰
- `video_context`: è§†é¢‘å…ƒæ•°æ®å­—å…¸
  ```python
  {
      "duration": 120.5,        # æ—¶é•¿ï¼ˆç§’ï¼‰
      "keyframe_count": 50,     # å…³é”®å¸§æ•°é‡
      "file_size": 10485760     # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
  }
  ```
- `custom_variables`: è‡ªå®šä¹‰æ¨¡æ¿å˜é‡ï¼ˆå¯é€‰ï¼‰

**æ„å»ºé€»è¾‘**ï¼š
```python
prompt_parts = []

# Level 1: ç³»ç»Ÿæç¤ºè¯
prompt_parts.append(self.SYSTEM_PROMPT)

# Level 2: ä»»åŠ¡æç¤ºè¯ï¼ˆä»æ•°æ®åº“è¯»å–ï¼‰
task_template = self.prompt_dao.get_default(category=scenario_category)
if task_template:
    task_prompt = self.prompt_dao.render_prompt(task_template, custom_variables or {})
    prompt_parts.append(f"**åˆ†æä»»åŠ¡ï¼š**\n{task_prompt}")

# Level 3: ä¸Šä¸‹æ–‡æç¤ºè¯ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
context_prompt = self._build_context_prompt(video_context)
prompt_parts.append(context_prompt)

# Level 4: è¾“å‡ºæ ¼å¼æç¤ºè¯
prompt_parts.append(self.OUTPUT_FORMAT_PROMPT)

return "\n\n---\n\n".join(prompt_parts)
```

---

#### 2.2 ä¸Šä¸‹æ–‡æç¤ºè¯ç”Ÿæˆ

**æ–¹æ³•ç­¾å**ï¼š
```python
def _build_context_prompt(self, video_context: Dict[str, Any]) -> str
```

**ç”Ÿæˆæ¨¡æ¿**ï¼š
```python
context_lines = ["**è§†é¢‘ä¿¡æ¯ï¼š**"]

if "duration" in video_context:
    context_lines.append(f"- æ—¶é•¿: {video_context['duration']:.1f} ç§’")

if "keyframe_count" in video_context:
    context_lines.append(f"- å…³é”®å¸§æ•°é‡: {video_context['keyframe_count']}")

if "file_size" in video_context:
    size_mb = video_context['file_size'] / (1024 * 1024)
    context_lines.append(f"- æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")

return "\n".join(context_lines)
```

---

### åœºæ™¯åˆ†ç±»è®¾è®¡

| åœºæ™¯ID | ä¸­æ–‡åç§° | å›¾æ ‡ | é€‚ç”¨å†…å®¹ |
|--------|---------|------|---------|
| `general` | é€šç”¨åˆ†æ | ğŸ“Š | é»˜è®¤åœºæ™¯ï¼Œé€‚ç”¨äºå„ç±»è§†é¢‘ |
| `coding_algorithm` | ç¼–ç¨‹å¼€å‘ | ğŸ’» | ä»£ç ç¼–å†™ã€ç®—æ³•è®²è§£ã€è°ƒè¯• |
| `meeting` | ä¼šè®®è®¨è®º | ğŸ‘¥ | å›¢é˜Ÿä¼šè®®ã€å¤´è„‘é£æš´ã€è¯„å®¡ |
| `teaching` | æ•™å­¦è®²åº§ | ğŸ“ | è¯¾ç¨‹è®²è§£ã€çŸ¥è¯†åˆ†äº«ã€åŸ¹è®­ |
| `gaming` | æ¸¸æˆå½•åˆ¶ | ğŸ® | æ¸¸æˆå®å†µã€æ”»ç•¥æ¼”ç¤º |

---

## 3ï¸âƒ£ ResponseParser è®¾è®¡

### JSON Schema å®šä¹‰

```python
GEMINI_RESPONSE_SCHEMA = {
    "type": "object",
    "required": ["summary", "key_findings", "timestamp_events"],
    "properties": {
        "summary": {
            "type": "string",
            "minLength": 10,
            "description": "è§†é¢‘å†…å®¹æ‘˜è¦"
        },
        "key_findings": {
            "type": "array",
            "items": {
                "type": "object",
                "required": ["category", "title", "content", "confidence"],
                "properties": {
                    "category": {"type": "string"},
                    "title": {"type": "string"},
                    "content": {"type": "string"},
                    "confidence": {"type": "integer", "minimum": 0, "maximum": 100},
                    "related_timestamps": {"type": "array", "items": {"type": "number"}}
                }
            }
        },
        "timestamp_events": {
            "type": "array",
            "items": {
                "type": "object",
                "required": ["timestamp", "event_type", "title"],
                "properties": {
                    "timestamp": {"type": "number", "minimum": 0},
                    "event_type": {"type": "string", "enum": ["highlight", "scene_change", "action"]},
                    "title": {"type": "string"},
                    "description": {"type": "string"},
                    "importance_score": {"type": "integer", "minimum": 1, "maximum": 10}
                }
            }
        },
        "metadata": {"type": "object"}
    }
}
```

### è§£ææµç¨‹

```mermaid
flowchart TD
    A[æ¥æ”¶å“åº”æ–‡æœ¬] --> B{ç›´æ¥JSONè§£æ}
    B -->|æˆåŠŸ| C[JSONå¯¹è±¡]
    B -->|å¤±è´¥| D[æå–Markdownä»£ç å—]
    D --> E{æå–æˆåŠŸ?}
    E -->|æ˜¯| C
    E -->|å¦| F[è¿”å›None + é”™è¯¯æ—¥å¿—]
    C --> G[JSON SchemaéªŒè¯]
    G --> H{éªŒè¯é€šè¿‡?}
    H -->|æ˜¯| I[è¿”å›è§£æç»“æœ]
    H -->|å¦| J[è®°å½•éªŒè¯é”™è¯¯]
    J --> F
```

### æ ¸å¿ƒæ–¹æ³•

#### 3.1 è§£ææ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def parse(self, response_text: str) -> Optional[Dict[str, Any]]
```

**å®ç°é€»è¾‘**ï¼š
```python
try:
    # å°è¯•ç›´æ¥è§£æ
    data = json.loads(response_text)
except json.JSONDecodeError:
    # æå–Markdownä»£ç å—
    data = self._extract_json_from_markdown(response_text)

if data is None:
    self.logger.error("Failed to extract JSON from response")
    return None

# JSON Schema éªŒè¯
try:
    jsonschema.validate(instance=data, schema=self.schema)
    return data
except jsonschema.ValidationError as e:
    self.logger.error(f"JSON validation failed: {e.message}")
    return None
```

---

#### 3.2 Markdown æå–æ–¹æ³•

**æ–¹æ³•ç­¾å**ï¼š
```python
def _extract_json_from_markdown(self, text: str) -> Optional[Dict]
```

**æ­£åˆ™è¡¨è¾¾å¼**ï¼š
```python
pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
match = re.search(pattern, text, re.DOTALL)
```

**æ”¯æŒæ ¼å¼**ï¼š
- ` ```json {...} ``` `
- ` ``` {...} ``` `

---

## 4ï¸âƒ£ VideoPreprocessor è®¾è®¡

### éªŒè¯è§„åˆ™

| éªŒè¯é¡¹ | è§„åˆ™ | é”™è¯¯å¤„ç† |
|--------|------|---------|
| æ–‡ä»¶å­˜åœ¨æ€§ | `os.path.exists()` | è¿”å› `False` |
| æ–‡ä»¶å¤§å° | â‰¤ 2GB | è®°å½•è­¦å‘Šï¼Œè¿”å› `False` |
| æ–‡ä»¶æ ¼å¼ | æ”¯æŒåˆ—è¡¨å†… | è®°å½•è­¦å‘Šï¼Œè¿”å› `False` |

### æ”¯æŒçš„è§†é¢‘æ ¼å¼

```python
SUPPORTED_FORMATS = [
    '.mp4',   # MPEG-4
    '.mpeg',  # MPEG
    '.mov',   # QuickTime
    '.avi',   # AVI
    '.flv',   # Flash Video
    '.mpg',   # MPEG
    '.webm',  # WebM
    '.wmv',   # Windows Media
    '.3gpp'   # 3GPP
]
```

### æ ¸å¿ƒæ–¹æ³•

#### 4.1 éªŒè¯è§†é¢‘

**æ–¹æ³•ç­¾å**ï¼š
```python
def validate_video(self, video_path: str) -> bool
```

**éªŒè¯æµç¨‹**ï¼š
```python
# 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
if not os.path.exists(video_path):
    return False

# 2. æ£€æŸ¥æ–‡ä»¶å¤§å°
file_size = os.path.getsize(video_path)
if file_size > self.MAX_FILE_SIZE:
    self.logger.warning(f"Video file too large: {file_size} bytes")
    return False

# 3. æ£€æŸ¥æ–‡ä»¶æ ¼å¼
ext = os.path.splitext(video_path)[1].lower()
if ext not in self.SUPPORTED_FORMATS:
    self.logger.warning(f"Unsupported format: {ext}")
    return False

return True
```

---

#### 4.2 æå–å…ƒæ•°æ®

**æ–¹æ³•ç­¾å**ï¼š
```python
def get_video_metadata(self, video_path: str) -> Dict[str, Any]
```

**è¿”å›æ•°æ®ç»“æ„**ï¼š
```python
{
    "duration": 120.5,        # æ—¶é•¿ï¼ˆç§’ï¼‰
    "width": 1920,            # å®½åº¦ï¼ˆåƒç´ ï¼‰
    "height": 1080,           # é«˜åº¦ï¼ˆåƒç´ ï¼‰
    "fps": 30.0,              # å¸§ç‡
    "codec": "h264",          # ç¼–ç æ ¼å¼
    "file_size": 10485760     # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
}
```

**å®ç°æ–¹å¼**ï¼š
- ä½¿ç”¨ `cv2.VideoCapture` (OpenCV)
- æˆ–ä½¿ç”¨ `ffprobe` (FFmpeg)

---

## ğŸ“Š ç»„ä»¶äº¤äº’æµç¨‹

### å®Œæ•´åˆ†ææµç¨‹

```mermaid
sequenceDiagram
    participant AS as AnalyzerService
    participant GS as GeminiService
    participant VP as VideoPreprocessor
    participant PB as PromptBuilder
    participant API as Gemini API
    participant RP as ResponseParser
    
    AS->>VP: validate_video(video_path)
    VP-->>AS: éªŒè¯ç»“æœ
    AS->>VP: get_video_metadata(video_path)
    VP-->>AS: video_context
    AS->>PB: build_prompt(scenario, context)
    PB-->>AS: final_prompt
    AS->>GS: analyze_video(video_path, prompt)
    GS->>API: upload_video()
    API-->>GS: file_uri
    GS->>API: wait_for_file_active()
    GS->>API: generate_content()
    API-->>GS: response_text
    GS->>RP: parse(response_text)
    RP-->>GS: parsed_json
    GS-->>AS: analysis_result
```

---

## ğŸ”§ é…ç½®æ–‡ä»¶è®¾è®¡

### gemini_config.json

```json
{
  "api": {
    "model_name": "gemini-2.0-flash-exp",
    "api_key_env": "GOOGLE_API_KEY"
  },
  "generation": {
    "temperature": 0.4,
    "max_output_tokens": 8192,
    "response_mime_type": "application/json"
  },
  "upload": {
    "max_file_size_bytes": 2147483648,
    "timeout_seconds": 300,
    "retry_max_attempts": 3,
    "retry_backoff_base": 2
  },
  "validation": {
    "supported_formats": [".mp4", ".mpeg", ".mov", ".avi", ".flv", ".mpg", ".webm", ".wmv", ".3gpp"],
    "enable_schema_validation": true
  }
}
```

---

## âœ… å®æ–½æ£€æŸ¥æ¸…å•

### GeminiService
- [ ] å®ç° `__init__` æ–¹æ³•ï¼ˆAPI å¯†é’¥é…ç½®ï¼‰
- [ ] å®ç° `upload_video` æ–¹æ³•
- [ ] å®ç° `wait_for_file_active` æ–¹æ³•
- [ ] å®ç° `analyze_video` æ–¹æ³•
- [ ] å®ç°æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
- [ ] æ·»åŠ å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### PromptBuilder
- [ ] å®šä¹‰ `SYSTEM_PROMPT` å¸¸é‡
- [ ] å®šä¹‰ `OUTPUT_FORMAT_PROMPT` å¸¸é‡
- [ ] å®ç° `build_prompt` æ–¹æ³•
- [ ] å®ç° `_build_context_prompt` æ–¹æ³•
- [ ] é›†æˆ `PromptTemplateDAO`
- [ ] å®ç°æ¨¡æ¿å˜é‡æ›¿æ¢

### ResponseParser
- [ ] å®šä¹‰ `GEMINI_RESPONSE_SCHEMA` å¸¸é‡
- [ ] å®ç° `parse` æ–¹æ³•
- [ ] å®ç° `_extract_json_from_markdown` æ–¹æ³•
- [ ] é›†æˆ `jsonschema` éªŒè¯
- [ ] æ·»åŠ è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

### VideoPreprocessor
- [ ] å®šä¹‰ `SUPPORTED_FORMATS` å¸¸é‡
- [ ] å®šä¹‰ `MAX_FILE_SIZE` å¸¸é‡
- [ ] å®ç° `validate_video` æ–¹æ³•
- [ ] å®ç° `get_video_metadata` æ–¹æ³•

---

## ğŸ“ åç»­é˜¶æ®µé¢„è§ˆ

å®Œæˆæœ¬é˜¶æ®µåï¼Œå°†è¿›å…¥ï¼š
- **é˜¶æ®µä¸‰**ï¼šæœåŠ¡å±‚é›†æˆï¼ˆæ‰©å±• AnalyzerServiceï¼‰
- **é˜¶æ®µå››**ï¼šUI å±‚é›†æˆï¼ˆåœºæ™¯é€‰æ‹©å™¨ã€ç»“æœå±•ç¤ºï¼‰
- **é˜¶æ®µäº”**ï¼šæµ‹è¯•ä¸éªŒè¯

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**åˆ›å»ºæ—¶é—´**ï¼š2026-01-15  
**é€‚ç”¨é˜¶æ®µ**ï¼šç¬¬äºŒé˜¶æ®µ - æ ¸å¿ƒç»„ä»¶å¼€å‘
